A Survey on Data-driven Network Intrusion Detection

Data-driven network intrusion detection (NID) has a tendency towards minority attack classes compared to normal traffic. Many datasets are collected in simulated environments rather than real-world networks. These challenges undermine the performance of intrusion detection machine learning models by fitting machine learning models to unrepresentative "sandbox" datasets. This survey presents a taxonomy with eight main challenges and explores common datasets from 1999 to 2020. Trends are analyzed on the challenges in the past decade and future directions are proposed on expanding NID into cloud-based environments, devising scalable models for large network data, and creating labeled datasets collected in real-world networks.

INTRODUCTION

Network intrusion detection (NID) monitors a network for malicious activity or policy violations . During the past two decades, data-driven methods have been developed and deployed for NID systems , most of which are machine learning models such as Naïve Bayes , Random Forests , Adaboost , and Deep Neural Networks . A review paper in 2009 summarized the NID systems that were supported by anomaly detection algorithms . In this survey, we present a broader view of data-driven NID, which includes related work from the past 10 years, and present a taxonomy of challenges and methods in data-driven NID research.

Background

Since the advent of computer networks, e-commerce, and web services, there has been a greater need for cyber-security and countermeasures toward network attacks. There was an interest in 182:2 D. Chou and M. Jiang intrusion detection in 1994, where intrusion detection was known to be a retrofit way to provide a sense of security when identifying unauthorized use, misuse, or abuse of computer systems . The concept of intrusion detection later became contextualized in cyber-security systems. The term "intrusion detection systems" describes the extraction of information from one or multiple computers in a network that identifies attacks from external sources, but also misuse of resources in the network from internal sources .

Intrusion detection systems can be broadly categorized as either being host-based intrusion detection or network intrusion detection. Host-based intrusion detection monitors host-specific actions such as system files being accessed or applications in use. A network intrusion detection system is focused on monitoring data flow between computers and "sniffs" for anomalous network traffic between different computers in the network .

There are two general behaviors in a network: normal and anomalous. Normal network behavior follows a specific criteria in terms of the traffic volume, applications on the network, and types of data exchanged. Network anomalies fall into two general categories of network failures such as network congestion or file servers being down and network security attacks such as DDoS and other attacks that are conducted by a malicious agent .

Network intrusion detection systems aim to distinguish the norm from security-related anomalies and detect attacks on computer networks. Network intrusion detection methods can be anomaly-based that identify malicious activity that departs from normal-defined behavior on a network or signature-based that identifies known attacks based on pattern matching. Because signature-based detection relies on seen patterns, it is not as effective in detecting novel attacks, or zero-day attacks, so anomaly detection is often used to detect novel attacks.

Past Surveys

Among the network intrusion detection surveys gleaned from the past decade, as presented in Table , many have constructed taxonomies along with problem-solution frameworks for cloudcomputing platforms. Jeong et al. addressed the anomaly teletraffic intrusion detection systems in Hadoop-based platforms where there is a heavy focus on the methodology of statistical, machine learning, and knowledge-based models. Different attributes of big data-storage volume, velocity, variety, intrusion detection system, and cost-are associated with problems and technical solutions specific to Hadoop-based platforms. A new platform was proposed for anomaly teletraffic intrusion detection systems on Hadoop. Modi et al. followed a high-level introduction of intrusion detection to cloud-based systems-a common solution to these intrusions being firewalls-and identified differences between signature and anomaly-based detection. Keegan et al. inspected network intrusion detection datasets, approaches, cloud environments, algorithms, and advantages and disadvantages among the literature.

Other authors primarily heeded the network intrusion detection datasets rather than its methods. Ring et al. examined packet-based, flow-based data along with host log files. Data recording environments were compared from the literature and a multitude of datasets, including some data repositories found on the Internet, were discussed along with their drawbacks. Ring presented a comprehensive overview of 34 datasets, their drawbacks, and how they may be related if one dataset was built off of another. Davis and Clark studied intrusion detection features derived from network traffic along with data preprocessing methods including clustering, filtering packets by high anomaly score or extracting subsets during traffic payload analysis, tracing TCP sessions, statistical features per connection, and create separate dataset. Some papers were method-specific, as Resende and Drummond provided a comprehensive review of random forest-based network intrusion detection. Resende and Drummond presented both a high-level overview of random trees and its components: decision trees. Datasets and 2011. Data preprocessing for anomaly based network intrusion detection: A review Data preprocessing Relevant features construction using targeted content parsing and deeper network packet inspection . Anomaly teletraffic intrusion detection systems on Hadoop-based Platforms: A survey of problems and solutions

Framework

Hadoop and big data platforms for speed, storage volume, and cost-efficiency 2012. A brief taxonomy of intrusion detection strategies

Strategies

Taxonomy of traditional network intrusion detection . A survey of intrusion detection techniques in Cloud

Framework

Incorporating IDS on host system and virtual machines . A survey of cloud-based network intrusion detection analysis

Framework

Integrating machine learning algorithms and MapReduce to cloud computing environments Resende and Drummond. 2018. A survey of random forest-based methods for intrusion detection systems Machine learning strategy Application of random forest methods over time . A survey of network-based intrusion detection data sets

Data collection

Categorization of 34 public datasets common evaluation metrics were reviewed and the authors concluded that, in future work, random forests will be used more on unbalanced data and on dynamic data due to its ability to adapt to incremental learning problems.

General overviews of network intrusion detection definitions and infrastructures along with taxonomies to classify different types of intrusion detection systems were also made. Poston's taxonomy covered high-level definitions of the types of intrusion detection and the types of analysis that can be done on host-based and network-based intrusion detection. However, the taxonomy is fairly general and the paper does not address future directions to intrusion detection research. Other papers looked to a specific result after observing the challenges in each paper and comparing their machine learning methods, as Buczak and Guven organized their review based on a machine learning method, presented the papers that use that method, the data it used, the cyber approach (misuse or anomaly), and the number of times the paper was cited. Mitchell and Chen broke down the classification of intrusion detection by system, collection process, techniques, models, analysis, and response. Many visuals are dedicated to their four defined types of intrusion detection: anomaly-based, signature-based, specification-based, and reputation-based. Most and least studied IDS techniques are analyzed and future direction of research in repurposing existing work on wireless intrusion detection applications, multitrust with intrusion detection, specificationbased detection for cyber-physical systems, and others. Ahmed et al. analyzed four main categories of anomaly-based detection: clustering, classification, statistical, and information theory. Each category was evaluated based on the computational complexity among approaches of that type, the most significant network attacks, and what the output is in each technique.

Our Contributions

There have been survey papers as broad as scanning over all network anomaly detection methods and as specific as cloud-based intrusion systems. Past surveys focused on the foundational knowledge of network intrusion detection frameworks such as TCP connection features or virtual machine layers in hypervisor/host systems. Surveys have looked into overviews of datasets, or comparisons between specific machine learning methods, all while reflecting on past literature. Many authors present previous work with charts comparing different papers and discussing challenges with cloud computing, growing data, and other open issues. Challenges have been addressed in many of these surveys, but there is a lack of solutions presented under future direction. Mitchell and Chen examined the most and least studied areas in wireless network intrusion detection to propose future research areas. Past surveys focus less on the most researched areas in data-driven NIDS over a long span of time, so we summarize trending data-driven NIDS research topics in a stacked bar chart over the past decade (see . In turn, we draw conclusions on plausible future directions in areas that researchers have not thoroughly investigated recently or research areas that they have abandoned.

Overview

In Section 2, the history of data processing, cloud computing, the lack of specific network attack types, and general big data processing techniques are examined. Section 3 covers common datasets from DARPA 1998 to as recent as LITNET 2020 along with their statistics in terms of how network attacks are distributed and how unbalanced the datasets are based on entropy. Section 4 addresses the high-level organization of the taxonomy and the details of each challenge and corresponding solutions/methods. Section 5 discusses the trends based on the articles collected that form the taxonomy and areas to look further into. Section 6 presents conclusions from the literature survey and taxonomy of data-driven network intrusion detection and reinforces future directions that researchers can look into.

DATA PROCESSING

The key purpose of anomaly detection systems is to separate anomalies from normal behavior. In computer networks, a network anomaly refers to circumstances where network operations deviate from normal network behavior . Anomaly-based network intrusion detection methods are important to identify novel intrusion attacks.

Data reduction is done to remove large amounts of data to improve efficiency and reduce computational overhead. In network traffic, packets are exchanged and TCP connections are open for the exchanges to be carried out. Because so many packets are sent and received in a typical network, extracting only the first few packets of a TCP connection was done by Chen et al. to mitigate effects of large packet data. Beyond extraction of data during its collection, other authors selected specific network features based on their importance. Tan et al. aimed to address the challenge of the heavy computation associated with anomaly intrusion detection systems using linear discrimination analysis (LDA) and distance difference maps to select the most significant features. LDA finds an optimal projection matrix to project higher dimensional features to lower dimensions. This feature reduction method was done on payload-based anomaly intrusion detection. In 2013, Zhang and Wang applied a simpler feature selection method that underwent a sequential search and sifted through the features in the feature domain, where a feature was added if the accuracy from the Bayesian network detection model lowered after removing a feature.

Most recently, attention has been directed towards new technologies in the cloud and newer optimizations with computation aside from parallelism. Cloud computing services allow for processing of large datasets, and a popular engine for big data processing is Apache Spark. Gupta and Kulariya presented a framework where correlation-based and chi-square feature selection were applied to obtain the most important feature set and Logistic regression, Support Vector Machines (SVMs), Random forest, Gradient Boosted Decision trees, and Naive Bayes were used for network intrusion classification from the MLlib library in Apache Spark. In 2019, Hajimirzaei

COMMON PUBLIC DATASETS AND REPRODUCIBILITY

Table compares common datasets which are open-source and improvements of past datasets such as being one of the first publicly available intrusion detection system (IDS) datasets or being updated with newer attacks that are commonly used. Dataset inclusion was based off those that were most common among highly cited data-driven NID papers. Other datasets were not included, as some were not publicly available or did not make notable improvements on past datasets.

Table presents the papers that used each dataset and the reproducibility of the methods that were applied to the datasets. These papers were included on the basis of the most cited papers over the past decade that used these datasets. The overarching criteria was that these papers had to be relevant to network intrusion detection.

Dataset Description

3.1.1 KDD Cup 1999. The KDD Cup 1999 was a version of the 1998 DARPA Intrusion Detection Evaluation Program that was collected by MIT Lincoln Labs in their packet traces and is one of the most widely used datasets for network intrusion detection . Lincoln Labs acquired roughly nine weeks of raw tcp dump data from a local area network (LAN), that simulates a similar environment as an air force LAN. The attacks fall into the four main categories: denial-of-service such as a syn-flood, unauthorized access to a remote machine (R2L), unauthorized access to a local superuser (U2R), and probing such as port scanning . Although the KDD Cup 1999 dataset is considered relatively large in that it contains 41 features and over 4.8 million rows of data, it runs into the issue of duplicates between training and testing data . The data is missing some important features such as IP addresses although there are basic TCP attributes provided such as the source and destination bytes. Although the KDD Cup 1999 dataset does capture a good number of attacks, the data was collected on a synthetic network. In general, the data collected is outdated, because it was made nearly two decades ago and has bias due to synthetic generation .

Table 3. Datasets and Papers That Used the Datasets for Evaluation Dataset Research works that used the dataset for evaluation KDDCup1999 • [26, 27, 31, 34, 50, 57, 65, 72, 91, 92, 103, 112, 114, 148, 152, 158, 173, 176, 179, 181, 183, 187-189] [7, 33, 44, 49, 64, 70, 89, 90, 98, 100, 101, 117, 120, 122, 141, 159, 164, 172, 182, 185] NSL-KDD 2009 • [36, 45, 59, 73, 80, 81, 102, 105, 133, 134, 137, 150, 158, 170, 176, 181, 202] [60, 75, 93, 125, 142, 149, 163, 174, 184, 190, 197, 198] [69] UNSW NB15 IDS • [16, 20, 73, 161] [81, 89, 90, 122, 154, 174, 182, 184, 191] [69] UGR'16 • [109] [110] CIDDS-001 • [2, 144, 148] CICIDS'17 • [6, 11, 29, 45, 157] [63, 140, 191] [46, 69, 180, 194, 195, 201] CSE-CIC-IDS2018 • [91] LITNET-2020 • [38] MAWILab "•" for those that are general methods or frameworks. " " for those that pseudo code and implementation details are available. " " for those that have documented code associated with the paper.

NSL-KDD 2009.

The NSL-KDD 2009 dataset was made to resolve issues of possible biases in duplicate data between training and testing datasets from the KDD Cup 1999 . The Canadian Institute for Cybersecurity and University of New Brunswick were involved in collecting the dataset. However, NSL-KDD removed some redundant, more frequent records in the training set that were from the KDD Cup 1999 dataset, which can still be important. In turn, this may lead to further biases given that the data from the raw TCP dump should still be kept. An underlying issue with the NSL-KDD dataset is that it still contains data from a network dating back as early as 1998's DARPA dataset.

UNSW NB15 IDS.

The UNSW NB15 Intrusion Detection System dataset contains source files in the formats of pcap, BRO, Argus, and CSV along with reports by Dr. Nour Moustafa . The dataset was created with an IXIA traffic generator that had TCP connections to a total of three servers. Two of these servers were connected to a router that had a TCP dump and three clients, where the TCP dump resulted in pcap files. The third server was connected to a router with three clients as well. The two routers that the first two servers and the third server were connected to were separated by a firewall. An issue with the UNSW NB15 dataset is again with the realness in its data, because the dataset was created from a traffic generator. . The UGR'16 dataset was collected from several netflow v9 collectors in the network of a Spanish ISP by researchers from University of Granada in Spain . The data is split into a calibration and training set, where long-term evolution and periodicity in data is a major advantage over previous datasets. However, a major issue is that most of the network traffic is labeled as "background, " which may either be anomalous or benign. Also, there is a mix of synthetically generated network attacks along with real-world network traffic, which is not of the same quality if none of the traffic was simulated. The dataset was labeled based on the logs from their honeypot system in their setup.

UGR

3.1.5 CIDDS-001. The CIDDS-001 dataset was collected in 2017 by four researchers , two PhD students, and two professors, who are affiliated with the Coburg University of Applied Sciences in Germany . The data was part of the project WISENT, funded by the Bavarian Ministry for Economic affairs. The intention of the dataset was to be used as an evaluation dataset for anomaly-based intrusion detection systems. The dataset is labelled and flow-based, where a small business environment was emulated on OpenStack. For the infrastructure, on the Internet, there are three attackers and an external server that has a firewall separating it from a server, where there are three layers: developer, office, and management. There are four servers that are in the OpenStack environment containing the three subnet layers. Generation of DoS, Brute Force, and Port Scanning occurred in the network. The first label attribute is traffic class: normal, attacker, victim, suspicious, and unknown. The second label attribute is attack type and the third being an attack ID. Because the external server emulates a real network environment, the CIDDS-001 dataset is primarily used for benchmarking. There are only three types of attacks, which unveils a lack of diversity in the data .

CICIDS'17.

The CICIDS dataset was collected under the Canadian Institute of Cybersecurity as well and University of New Brunswick . The generation of network traffic came from a proposed B-profile system where abstract behaviors were derived for 25 users based on HTTP, HTTPS, FTP, SSH, and email protocols. With regards to the victim and attacker network information, there was a firewall against the IPs 205. .165.80 and 172.16.0.1 and a DNS server at 192.168.10.3. The attackers network comprises two IPs: Kali: 205.174.165.73, Win: 205.174.165.69. The victim network is composed of 2 Web servers 16 Public, 6 Ubuntu servers, 5 Windows servers, and a MAC server. The data collection occurred over the course of five days where Monday was benign activity, Tuesday was brute force, Wednesday was DoS, and Thursday was web attacks where the afternoon saw Botnet, Port Scan, and a DDoS LOIT.

CSE-CIC-IDS2018.

The CSE-CIC-IDS2018 dataset is a collaborative project between the Communications Security Establishment (CSE) and the Canadian Institute of Cybersecurity (CIC) . A notion of profiles is adopted to generate data systematically. First is the B profile that captures behavior in users using machine and statistical learning techniques. M-profiles are human users or automated agents who may examine network scenarios. With the environment supported in AWS, the network topology includes an attack network of 50 machines, 5 departments holding 100 machines each and a server with 30 machines.

LITNET-2020.

LITNET is a new annotated benchmark dataset where data was collected by four professors, a PhD student, and two students at the Kaunas University of Technology (KTU) . The infrastructure of the network is composed of nodes with communication lines connecting them. The LITNET topology consists of senders and receivers, netflow senders (Cisco routers), and a netflow server. The netflow exporters were in four cities in Lithuania, Vilnius Gediminas Technical University, and two KTU university nodes. The dataset contains real network attacks in Lithuanian-wide network with servers in four geographic locations within the country.

3.1.9 MAWILab. MAWILab is a database containing the dataset from the MAWI archive that records network traffic data between two endpoints [95]: one in Japan and another in the U.S. MAWILab's dataset has been contributed to since 2010 and records 15 minutes of network traces each day. Labels of network traffic are generated from anomaly classifiers based on port numbers, TCP flags, and ICMP codes along with a taxonomy of traffic anomalies based on packets headers and connection patterns . The graph on MAWILab's website divides the type of traffic over the course of 13 years based on byte and packet ratios. HTTP traffic used to be very common from 2007 to 2017, but sharply decreased at the end of 2017. Port Scanning is uncommon, where "multiple points" was the second most dominant traffic type from 2007 to 2017. A spike in denial of service (DoS) data was collected between 2011 and 2012. Currently, the most common type of traffic is multi points, then http, then IPV6 tunneling and alpha flow by byte and packet ratio. The number of anomalies from 2007 to 2020 ranged roughly between 100 to 200 at any time. Outliers are as low as 50 anomalies and as high as 500 anomalies daily. Since the network traffic has been between over the same link and two endpoints since 2007, MAWILab's network may not be as similar to most other networks used now. In addition, the labels fall into four broad categories: anomalous, suspicious, notice, and benign. The labels are dependent on the anomaly classifiers, so there may be misclassified traffic.

Reproducibility on Datasets

The code repository by He and others implemented a LSTM neural network, Multimodal Deep Auto Encoder (MDAE), Autoencoder (AE), Gaussian Restricted Boltzmann Machine (RBM), and Multimodal-sequential approach with deep hierarchical progressive network (MS-DHPN) in Python that were trained on the network intrusion datasets NSL-KDD 2009, UNSW NB15 IDS, and CICIDS 2017. The repository contains separate files to load data and run the different models to reproduce results. However, the train and test dataset paths are defined specific to the author's environment along with the naming schemes that they chose. The paper does not specify how their renamed CSV file paths were derived from the original CSVS in each of the datasets. The code is present, but not reproducible without consultation from the authors.

The repository by Roberto and others implemented logistic regression (LR), random forest (RF), and SVM in Python on the UGR 2016 dataset. The AUC, precision, recall, F1-score, and support metrics are reproducible for these models, where the model, number of iterations, number of cross-validation folds, and configuration file path are specified. However, only the SVM model results were included in the code repository. There was scaling of the data prior to training and testing the models when running the main Python file, but their implementations of the partial least squares regressions described in the paper were not provided in the code. The code is partially reproducible for some of the models' performances, but not all.

The code repository made public by Faker and others implemented all their preprocessing and machine learning models in IPython on the CICIDS 2017 network intrusion dataset. However, no details in the README file points to Python package versions, resulting in the user inferring what versions were used at the time the code was run by the authors. The tensorflow package should not be version 2 for the code to run, which restricts the versions of Python to 3.7 or earlier. The package distkeras contains missing methods in its SequentialWorker class such as add_history and training_history, so a follow-up on package versions and fixes with the authors is needed.

The repository common to Zhang and others' 2019 papers on hierarchical clustering and parallel cross convolutional neural network download process can be time-consuming. Also, there may be version issues, depending on the Python version, but python3.6 -m venv env can create a Python 3.6 virtual environment that supports tensorflow before version 2: pip install tensorflow==1.5. The data used in the paper is online and models are reproducible.

The code repository released by Zhong and others contains a demo that consolidates the code for parsing the network flow packets, extracting features, training the deep belief network autoencoder and LSTM, and plotting the anomaly scores for the indices of the network packets. The model was tested on the MAWILab and CICIDS 2017 intrusion datasets. The code is able to completely recreate the results from the paper.

The code repository provided by Xu and others is not reproducible, as the code and datasets link in the paper leads to a site with an insecure connection and a privacy error. Further consultation with the authors would need to take place.

A TAXONOMY: CHALLENGES AND METHODS

Figure presents a hierarchical chart of categorized high-level challenges and recent methods to resolve them. This section will discuss the challenges and introduce the methods in details. The papers in the taxonomy were included because they are relatively highly cited by other researchers and can highlight a moment in the progression of a research area, such as big data or dynamic data.

Lack of Real-world Network Data

Challenge. When network traffic data was initially being collected, even as early as the KDD Cup dataset from 1999, attacks were outdated and not compatible to attacks done in the real-world. Because using real-world networks to collect network traffic was costly, researchers looked to simulating realistic networks with synthetic data generation or a simulated virtual network as an alternative. Initially, honeypots were used as a means of simulating a virtual network environment to attract attackers and gather traffic data. Honeypots are security resources that are meant to be misused by malicious attackers, where such attacks would be recorded in databases. They consist of a decoy, or an information source, and a security program that provides attack monitoring and detection . These mechanisms can be used to collect network intrusion data with simulated realism that run in a virtual machine , containing possibly more than one honeypot to resemble a distributed honeypot system to simulate a distributed network more accurately . The main drawback with honeypots is their limited vision on network attacks. A honeypot is only aware of an attack if it is attacked, but would not be able to detect attacks directed at other systems. The use of TCP dumps in IXIA traffic generation also plays a large role in simulating realistic network intrusion data by synthetically generating data, which Moustafa and Slay have done to create the UNSW-NB15 dataset. They generated data with an IXIA traffic generator, then collected pcap files extracted from a tcpdump. This synthetic data generation was improved upon in 2017 by Haider et al. with the generation of network traffic via IXIA Perfect Storm and collection of the host's network logs during the simulation. This was better than the UNSW-NB15 dataset, because UNSW-NB15 lacked the information of normal and synthetic data that came from the operating system's log files. Haider et al. also verified the realism of their dataset through the Sugeno fuzzy inference engine . Architectures of main approaches to the creation of real-world network data are illustrated in Figure .

Collection in public network infrastructure. In the past couple of years, researchers have looked to collect network traffic data in a cloud environment due to the growing usage of cloud computing platforms such as Amazon Web Services and Google Cloud. A mixture of virtualization and cloud intrusion detection using hypervisors have been implemented as well, which can resolve the issue of small datasets by aggrandizing network traffic data. In 2018, Hongda et al. combined network virtualization with software-defined networks to handle attack traffic. Their virtual network intrusion detection system (vNIDS) employed static program analysis to determine the detection states to share. The prototype of vNIDS was done in CloudLab for flexibility with processing capacity and placement location. In the past year, Aldribi et al. acknowledged the new challenging terrain that cloud computing provides for attackers. In turn, they implemented a new hypervisor-based cloud network intrusion detection system using multivariate statistical change analytics to detect anomalies. Alongside further research into generating network traffic data in the cloud, the realism in past datasets was called into question because of their outdated attacks and synthetic traffic generation. A proposed solution involved generating real-world network through gathering network traffic from a university network such as the Lithuanian Research and Education Network or a real virtual network of a tier-3 ISP done in the UGR'16 dataset .

Ability to Transfer.

Challenge. There are no guarantees on how well network anomaly detection systems can perform in networks that consumers or corporations actively use. In fact, Allix and others state that it is impossible of obtain a dataset that reflects current real-world networks due to the rarity and secrecy of network intrusions. And it would not be practical to train a network anomaly detection system in a real-network setting due to the consequences of undetected intrusions on the security of the network. However, researchers can transfer what an intrusion detection system has learned in a simulated environment to an in-use network if the environment mimics traffic patterns of networks currently in use.

IDS Methods.

There are a few recent paradigms for simulating a real in-use network environment, which are intended to be more efficient or scalable than past architectures: controllermicroservices virtualization or container-based traffic collection. A network simulation approach can vary based on whether the traffic is being delivered entirely from a commercial generator (e.g., IXIA PerfectStorm Tool) or at least partially derived from an enterprise tracing project. Enterprise tracing projects collect typical traffic in a enterprise network.

The controller-microservices virtualization architecture introduced in Hongda et al. distributes network traffic to different detection logic program instances based on the network header information. The decomposition of the network intrusion detection system into three microservices allows for independent detection for different network traffic, reflecting a "divide and conquer" approach that can reduce resource consumption in the virtualization of NIDS. They generated background network traffic by delivering typical campus, internet, or enterprise traces of network traffic and labeled attack traffic from penetration tests in an isolated environment. Using typical in-use background network traffic in a simulated environment while introducing malicious attacks during penetration testing can provide estimates of an intrusion detection model's performance in a real-world network.

Expanding from traffic collection in virtual machines, Clausen and others examine containerized networks to address the lack of ground truth traffic origin labels due to traffic originating from multiple background processes and a static design in virtualizations. Virtual machines require the use of hypervisors, which share the host's operating system resources. Containerized networks do not rely on hypervisors and instead share resources simultaneously across containers. Because containers isolate specific running applications, labels on the ground truth of traffic origin can be gathered. Containers are also lightweight and easily clonable, making containerized networks scalable and dynamic to changes in network environments. Attack traffic is produced by a select group of machines in the containerized environment, while benign traffic is generated using commercial traffic generators such as IXIA PerfectStorm Tool. The authors also mimicked network congestion by writing scripts in NetEm to artificially create packet delays, loss, and corruption.

Optimal network generation can occur when benign traffic data is generated using typical traffic recorded in an in-use network most similar to the network that will implement the NIDS technology. Malicious traffic can be implemented by other machines in the environment that deploy current attacks such as Denial of Service. This traffic can be relayed in a virtual machine or containerized environment with Hongda and Clausen's architectures being two specific examples, respectively, and can be accompanied with artificial packet loss or delays to mimic real-world network congestion. Although an IDS trained in the artificial network may not perform well in a real network setting, the more similar a simulated training environment is to the network integrating the IDS, the better the IDS will perform. Challenge. Some traffic data in datasets may contain outliers that can come in the form of lessfrequent traffic classes. To combat noisy data or data with outliers, feature normalization methods have been applied to scale features and allow them to have similar effects in the model so noise would not weigh differently than the rest of the data. In other instances, density-based feature selection was used to identify the most important features by finding overlaps between feature probability distributions as well as non-overlapping regions.

Feature normalization. Feature normalization methods can be applied to scale features and allow them to have similar effects in the model so noise will not be weighed differently than the rest of the data. Statistical methods have been used to facilitate network anomaly classification. In 2015, Delahoz et al. studied a probabilistic Bayesian self-organizing map model to perform unsupervised learning. To overcome the challenge of noise in the network data, they normalized continuous variables to have a mean of 0 and variance of 1, a standard normal distribution. For categorical variables, they are encoded before normalized. Categorical encodings are 1 if a feature is "activated" and 0 if not. Although normalization to a standard normal distribution via x -x σ is one method, rescaling logarithmically is another option. Hsu et al. developed an online intrusion detection system based on an autoencoder, SVM, and Random Forest ensemble where noise was dealt with feature normalization, where they used the two normalization functions:

The functions were meant to rescale feature values to the proper range, where a is the original raw data value, a max being the max value among all values under the same feature as a, and (loд(a + 1)) max being the maximum loд(raw value + 1) for all logarithmic values under the same feature as a. Packets sent and received were two features that were extremely variable, because certain attacks (DDoS) entail much larger amounts of traffic in the network, so those feature values are normalized by its logarithm divided by its max value (first normalization equation). For features with lower variance, they are normalized by division of their max value (second equation). Specific to the sensitivity to noise innate in SVMs, Liu et al. worked towards mitigating the sensitivity that SVMs have for noise samples by applying a fuzzy membership to measure the distance between a sample and the hyperplane, as in SVM. The larger the distance, the smaller the weight coefficient for the sample. Each sample will have a distinct effect on the optimized classification hyperplane so outliers and noise (values with larger distance) will not impact the classifier plane as much as they are assigned lower weights.

Density-based clustering. In other instances, density-based clustering is used to group together data from the same class and identify outliers that are unusually distant from the clusters observed. Because of the scattered nature of DoS attacks in wireless sensor networks (WSNs), Shamshirband et al. introduced an imperialist competitive algorithm (ICA) with density-based algorithms and fuzzy logic. Dense areas in data space are clusters and low-density areas (noise) surround them. Density-based clustering can detect shape clusters and handle noise. As network intrusion detection involves outlier detection, one may broaden the density-based approach to outlier detection. Tang and He presented an effective density-based outlier detection method where a relative density-based outlier score is assigned to observations as a means of distinguishing major clusters in a dataset from outliers. Similarly, Gu et al. applied a density-based initial cluster center selection algorithm to a Hadoop-based hybrid feature selection method for the mitigation of outlier effects.

Handling Redundant Data.

Challenge. Some features in a network intrusion feature set may not contribute significantly to the predictive power of a model, so they may be removed based on feature importance. To handle redundant data, frameworks have been made to remove redundancies. Significant methods to handle redundant features in data are illustrated in Figure .

Feature removal frameworks. The presence of data redundancies is a prevalent issue among network intrusion datasets, so researchers have developed frameworks where specific data removal techniques are recommended. Initial feature removal methods were integrated into computational intelligence approaches over the course of the 2000s and into the 2010s. In 2013, Ganapathy et al. wrote a review detailing a gradual feature removal method and modified mutual information method that selects features to maximize information for outputs (maximize relevance between inputs and outputs), conditional random field (CRF) as a layered method (each layer representing an attack type), and genetic feature selection where a set of trees are generated and the best set of features are extracted. Recent research appears to be reflective on integrating feature removal methods into a more streamlined model creation process. Bamakan et al. proposed an effective intrusion detection framework where feature selection is embedded in their objective Fig. . Methods for dealing with redundant features: Besides the above two methods, Autoencoder and Fuzzy Rough Set have also been used for reducing redundant features.

function combined with time-varying chaos particle swarm optimization (TVCPSO). They streamlined their weighted objective function approach in a flow chart where, with each iteration, the fitness of the particles is updated in particle swarm optimization and chaotic search is done to find the global optima. Carrion et al. addressed the lack of the evaluation in network intrusion detection methods by providing a structured methodology that involved more rigorous feature selection or removal techniques. Including steps on how feature selection or removal took place to arrive at a final accuracy, as they stated, can allow for easier replication and more reliable evaluation in network intrusion detection literature.

Feature selection. Feature selection can rule out redundant features and select a subset of the features in the data without significantly degrading the performance of the model . Early 2010's saw an interest in filtering-based feature selection methods as Koc et al. applied the hidden naïve Bayes (HNB) model to data with highly correlated features. Accompanying their HNB model was a filter-based feature selection model that is both correlation and consistency-based and relies only on the statistical properties in the data. Correlation feature-selection picks features that are biased towards highly correlated classes. The consistency-based filter has an inconsistency criterion that specifies when to stop reducing the dimensionality of the data. After filter-based methods, there was interest in using forward selection for feature ranking via Random Forest by Aljarrah et al. . But rather than finding the most optimal feature set, recently, Elmasry et al. claimed that feature selection can be time-consuming due to its exhaustive search, and that evolutionary computation techniques may be applied to find near-optimal solutions in a shorter amount of time.

Automatic feature extraction. In the realm of automatic feature extraction, rough set theory and autoencoders are two important automation methods. Rough set ranks extracted features from network intrusion data and generalizes an information system by replacing the original attribute values with some discrete ranges , and autoencoders are considered to be nonlinear generalizations of principal component analysis that use an adaptive, multilayer "encoder" network to reduce data dimensionality . The early 2010's saw research interest in rough set theory for feature selection. Because simplified swarm optimization (SSO) may find premature solutions, Chung and Wahid went about improving the performance of it by conducting a local weighted search after SSO to produce more satisfactory solutions. They applied k-means clustering to continuous network data values and rough set theory to minimally sized subsets of the feature. The goodness in selected features is evaluated using the fitness function given input data D, |C | being the number of features, |R| being the length of a feature subset where R is a feature subset, and γ R as the classification quality of feature set R:

Data is changing rapidly and with the increasing presence of irrelevant features, Liu et al. introduced a Gaussian mixture model to extract structural features in a network and identify anomalous and normal patterns where redundant features were removed and important features were optimally selected using fuzzy rough set theory. Alongside irrelevant features and the age of big data, the speed in which a model's objective function converges slows down. Both fuzzy rough set methods and autoencoders have been devised to tackle the large volume of data. With uncertainty surrounding whether network traffic is normal or anomalous, Selvakumar et al. presented a fuzzy rough set attribute selection method where the fuzzy-oriented rough degree on dependency of γ P (D) to subset P is defined as γ P (D), where a subset of features is evaluated on its relevance to the data. To handle growing data, as well as irrelevant data, Alqatf et al. proposed the use of an autoencoder for feature learning and dimensionality reduction to extract the most important features and filter out those that are redundant. Then they pass the reduced data into an SVM model for network traffic classification.

Handling Weakly Correlated Data.

Challenge. The lack of strong correlation between features in data may make the construction of a model more challenging. Correlation can be artificially made through increasing the dimensionality of the data by data fusion or the introduction of new features.

Increase dimensionality. Given one-dimensional feature data, Li et al. augmented the data to two dimensions and performed data segmentation where split data was later fused back together for network intrusion classification. They split feature data into four separate parts based on features that are correlated with one another. The one-dimensional feature space is converted to grayscale, then the data output from the four data components are merged and passed to the output layer of the multi-fusion CNN.

Discussion on Model Robustness.

Challenge. A model is robust if the accuracy in its predictions is not impacted by changes in the input data such as from distribution shifts or outliers . For intrusion detection, changes in network flow data can also come from an "adversary" that may "obfuscate" attack payloads to mimic its benign counterparts. To mitigate loss in intrusion detection accuracy due to noise or adversaries, different robust methods have been developed.

Robust Methods. Gornitz and others reframed network anomaly detection as an active learning task and tested the robustness of a one-class SVM. They first viewed a network payload as a vector x containing data of the network packet and mapping it to a vector space using string s and embedding function ϕ. For each string s, ϕ (x) returns 1 if s is in the payload x and 0 otherwise. Using this vector space representation, the support vector domain description (SVDD) was designed so normal data could be separated from anomalous data, where anomalies could easily be distinguished as outliers. They guided a security expert to low-confidence regions of the feature or vector space to administer active learning, where more attention was directed towards network data that had less accurate predictions. Their SVM was not designed to be robust against adversaries or noise in the network data, because model robustness was not factored into the construction of the SVM. It was during the empirical evaluation of their approach when they analyzed the effects of an adversary on their model's performance.

Recent work focused on designing methods robust to distributional changes or the presence of outliers in network data. Papers either tackle method-specific limitations in robustness such as the sensitivity of SVMs to noise or general limitations that result in high false positive rates or undetected false negative outliers. Bamakan and others use ramp loss to remedy support vector's sensitivity to outliers. The ramp loss replaces hinge loss, which is a non-convex loss function that "depresses" the pressure of these outliers to make support vector models more robust and reliable. Armed with a new loss function, the authors apply the "concave-convex" procedure to minimize ramp loss by selecting the optimal s for the ramp loss R s (z) given the input vector z. Then for each pair of ∀i, j ∈ {1, . . . ,p} (i, j) for p output labels, the training dataset is partitioned into a positive, negative, and zero class. Variables δ 1 , k = 1 are initialized and an iterative update to δ i for the ith iteration is applied to construct a decision function of the form д

work packet observation x has its label predicted based on the constructed decision functions. The ramp loss results in more sparsity, or more zero quantities, in the support vector model, because misclassified training examples do not simply become support vectors.

To tackle the general problem of being unable to capture an intrusion signal occurring on a network, Ahsan and others applied kernel density estimation to Hotelling's T 2 control chart to design robust estimators. The Hotelling's T 2 chart can track the mean of a process where we observe independent and random vectors x i . The procedure is designed so, first, a matrix X normal is constructed, which is the representation of the benign training data in the network. Then fast minimum covariance determinant (MCD) is then run where Manhalanobis distances are computed per i ∈ {1, . . . , n} and the distances are sorted to form some permutation of the original set {1, . . . , n}. T and S are the mean and covariance of the new permutation set. The T 2 statistic in the Hotelling control chart using the mean vector and covariance matrix is computed for normal network connection data:T 2 F ast -MCD,i = (x i -T) T S -1 (x i -T). The distribution of theT 2 statistic is computed with kernel density estimation (KDE) using the Gaussian kernel. Then the control limit is calculated using the CDF of the empirical density of the T 2 F MCD,i statistic:

The design of the robust method is centered around the computation of robust estimators for the Hotelling T 2 control chart, which can result in more accurate control limits, or horizontal lines denoting the boundaries between normal and anomalous data, in Hotelling T 2 charts.

Discussion on Tolerance to Adversarial Attacks.

Challenge. An "adversary" can be a data generator or a network security expert that can mask network payloads to appear benign when they are in fact malicious. They have the intention of deceiving an intrusion detection system and leaving attacks on a computer network undetected. It is challenging to determine how an adversary will behave and ways to mitigate false positives or false negatives when detecting network intrusions, but methods using data generation have been devised to help models handle adversarial situations.

Against Adversarial Attacks. Marino and others implemented an adversarial approach that sought to enable a machine learning model to correctly classify misclassified examples given they are modified by adversarial sample generation. Rather than deceiving their classifiers that have a linear model and a multi-layer perceptron model, the authors intend to understand why their network data is being misclassified. They find an adversarial example x that is classified as y while minimizing the distance between x and the original data x 0 : min x H ( y, p(y, x, w ))αI ( x, y) + ( xx 0 ) T Q ( xx 0 ) with the constraint that x min x x max , where Q is a positive semidefinite matrix that can be adjusted using specific weights. Note that y is not the same as the true label of the network data observation x 0 . x 0 , y is a sample from the dataset. H ( y, p(y, x, w )) is the cross-entropy between the estimated label of the adversarial example, p(y| x, w ), and the target label y. α weighs the contribution of the cross-entropy in the objective function and I ( x, y) is the indicator function that returns 0 if x is classified is y and 1 otherwise. The quadratic program optimization above is run and minimum changes are applied to correctly classify only misclassified samples x 0 , where we intend to construct x such that y is the predicted label. Explainability in misclassifications can be derived from adversarial sample generation, as the average of the deviations x 0x can be used to explain how far off the misclassified samples are from samples that would be classified correctly.

Instead of using one adversarial attack generation method, Pawlicki and others constructed a pipeline for artificial neural networks that uses four different approaches, each minimizing the distance between the produced adversarial and real samples. The input network traffic dataset is partitioned into four subsets A, B, C, D. Portion A is used to train the intrusion detection system. Portion B is split between testing the detection system and training the adversary detector by performing four adversarial attacks-Carlini and Wagner attack, fast gradient sign method, basic iterative method, projected gradient descent-on 1397 "Attack" samples that are labeled as "adversarial. " The remaining data labeled as "non-adversarial" are added to the "adversarial" examples and form the adversarial detector training dataset. C, D are used to test the adversarial detector.

Methods for Label-based Challenges: Lack of Labels and Label Imbalance.

Handling Too Few Labels.

Challenge. Data may have a lack of labels, particularly when network traffic is ambiguous or unlabeled. This poses another challenge between the stages of data preprocessing and model creation. Figure illustrates transfer learning, adversarial sample generation, and deep learning paradigms used to resolve the issue of unlabeled data.

Unsupervised/Supervised Learning. Initially with a completely unsupervised learning approach, Casas et al. used an unsupervised sub-space clustering method to detect network intrusions by aggregated traffic packets into multi-resolution traffic flows. With too few labeled data, researchers may look to semi-supervised learning: First perform unsupervised learning on unlabeled data to label it, then pass the labeled data to a supervised learning model. More recently, there has been more research on semi-supervised network intrusion detection methods. Khan et al. proposed a semi-supervised model that initially classified unlabeled traffic as normal or anomalous with a probability score that was used as input for an unsupervised autoencoder to train on, then the data was passed into stacked pretrained neural layers with a soft-max layer for classification. Through a more randomized approach, Ravi and Shalinie proposed a semi-supervised learning model that employed repeated random sampling and k-means to label data as different traffic types, then passed it through classifiers developed in related work.

Transfer learning. Transfer learning can compensate for the lack of labeled data via transfer of knowledge from other labeled data sources . Singla et al. examined the viability in transfer learning for imbalanced datasets; namely, the UNSW-NB15 dataset was split into labeled sub-datasets. Each sub-dataset is split into a source dataset and a target dataset, where the classifier was pretrained on the source dataset, then retrained on the target dataset to combat the lack of labeled data. Beyond the synthetic dataset UNSW-NB15, a network type that has recently been explored was the consumer network, which does not have the firewall or switches to deter network intrusion attacks. Patel et al. proposed normalized entropy from features in payload, packet and frame statistics to be funneled into a training and testing dataset and passed into a one-class SVM for classification of traffic in consumer networks. Through the collection of packet capture data sent from programs on devices in a consumer network, a consumer network dataset was constructed to combat the lack of consumer network datasets. Patel and other researchers exhibited that exhaustively labeled datasets are not necessary for accurate intrusion detection models.

Adversarial sample generation.

Adversarial sample generation is done to fool a machine learning model, especially a neural network, with adversarial samples, so correctly classified data can be mistakenly identified for another class . Using a random forest, Apruzzese et al. used network flows to identify normal and botnet activity. The adversary is assumed to have already compromised at least one machine in the network and deployed a bot to communicate with other machines through limited "Command and Control infrastructure. " The attacker intends to trick the classifier by slightly increasing flow duration and exchanged bytes and packets. Instead of a base adversary that changed feature attributes in adversarial samples, Cheng used a generative adversarial network (GAN) where a generator aims to refine the generation of fake data while a discriminator determines which network traffic flows are legitimate or anomalous, which was what Usama et al. did as well . Similar to Apruzzese's adversarial sample generation, but in a more controlled environment, Aiken and Scott-Hayward developed an adversarial testing tool called Hydra that behaves as an emulator for a system that launches attacks in a software-defined network where a test manager sends traffic, evading the classifier by changing payload size and rate. In all such cases, adversarial sample generation not only offers more data to combat unlabeled data, but can develop defensive mechanisms for more robust NID systems.

Handling Unbalanced Labels.

Challenge. The data may also be imbalanced where network intrusion attacks are disproportionately smaller than that of normal network activity. As discussed in Section 3 on common public datasets, most network intrusion datasets face considerable imbalance between normal and anomalous traffic, but especially among attack types. Figure highlights the random oversampling and undersampling techniques used to handle minority and majority classes in network intrusion datasets and main machine learning models implemented to handle unbalanced classes.

Over/under-sampling. Oversampling is meant to increase samples from the minority class and balance the distribution of data among attacks and normal activity in a network. Undersampling removes samples from the majority class to allow minority and majority classes to become similar in size, disallowing misclassifications of underrepresented network attacks . A collection of work has been written last year on the use of over or under sampling to balance network intrusion datasets. Mikhail et al. resolved the issue of minority attack classes by training an ensemble classifier with undersampling data and training each sub-ensemble. Gao et al. noticed that the KDD Cup dataset they used had a large amount of user to root (U2R) attacks, so they changed the proportion of classes in samples passed as input into the models. They used classification and regression trees (CARTs) where multiple trees were trained on adjusted samples by random undersampling-similar to Mikhail and others' work-where 1 16 of normal traffic (a majority class) was sampled to solve imbalances. Although minority sampling can allow for more evenly proportioned classes for network intrusion detection, there is the potential for majority classes to be predicted with lower accuracy due to undersampling of majority classes or oversampling of minority classes. Zhang et al. resolved this issue by combining weighted oversampling with a boosting method. The weighted oversampling technique updates weights associated with minority classes and the misclassified majority class observations are forced on the classifier to learn.

Optimal feature extraction. Ranking features based on their importance can be done to reduce a feature set to an optimal feature subset. Thaseen et al. used a consistency-based feature selection method that determines whether the value and class label of two observations match. Zhang et al. aggregated time intervals of network traffic into subgroups to find information from the five features: address count, packet count, port count, byte count, and the bytes per packet.

Siamese neural network. To combat the challenge of minority and majority classes in imbalanced datasets, Bedi et al. employed a few-shot learning method called a Siamese Neural Network that was first introduced by Bromley et al. . Siamese neural networks compute the similarity between two input samples to determine how similar or dissimilar they are, so pairs of samples belonging to the same class such as DoS-DoS, Normal-Normal, U2R-U2R were considered most similar and labeled with a 1, whereas distinct pairs were labeled with a 0. Traditional methods of oversampling and undersampling were bypassed with the use of siamese neural networks paired with sampling equal number of observations per network traffic class.

Feature fusion. Feature fusion can combine different data that will, together, result in balanced attention to features. Zhang et al. a parallel cross convolutional neural network that fused traffic flow features learned by two separate convolutional neural networks to make the network pay more attention to minority attack classes. After downsampling the two neural networks, the number of channels was doubled in the output feature map, then a pooling layer was applied to reduce the dimensionality of the data by combining outputs of clusters in one layer into one neuron in the next layer.

Genetic programming. Genetic programming uses an agent to learn an optimal or near-optimal solution to a problem and can be used in conjunction with machine learning models to evolve the model until its fitness is optimized for network intrusion detection. Le et al. found genetic programming to perform well on imbalanced datasets when using accuracy as the fitness function: the number of true positives and true negatives over all classified observations.

Discussion on Explainability.

Challenge. Model explainability is being able to understand the behavior of a machine learning model and why it presents specific solutions or predictions for given tasks . Explainability in network intrusion detection models is important due to the side effects of a wrong prediction. If a model predicts a false negative, or presumes that a network packet is not anomalous or malicious when it is responsible for intrusion of a computer network, then the entire network could be in jeopardy, leading to possible breaches in private information. And if one cannot explain why a model made this poor and costly decision, then individuals will be less accepting of novel intrusion detection systems powered by machine learning models. Thereby, research into more explainable intrusion detection models can heighten the chances of integrating the model into a corporate or public network.

Explainable Methods. Explainable network intrusion detection models have been gaining traction such as in References , but there are a few representative papers that portray the changes of explainable IDS methodologies. Adetunmbi and others explored seeking model explainabillity using a rule system. Their rule system is based off of rough set theory, where rules are denoted by logical implications. Based on the values of a set of features, or attributes A 1 , . . . , A k , the rules (A 1 = a 1 ) ∧ . . . ∧ (A k = a k ) will decide the outcome of whether or not a network connection record is anomalous. Although rough sets can generate simple decision rules that are explainable to practitioners and indeed three times faster than a traditional k-nearest neighbors approach that they implemented, the approach did not perform well on remote to user (R2L) or U2R attacks in the KDD Cup 1999 dataset. To improve detection accuracy while maintaining model explainability, Amarasinghe and colleagues present a post hoc framework of explanations for their deep neural network (DNN) predictions. They provide the relevance of input features for the prediction, the prediction confidence, and a textual summary of why the prediction was made such as "DoS attack WITH high confidence BECAUSE connections to the same host in the last 2 seconds is high. " The textual summary and feature relevancy are similar to rough set's decision rules that are based off relevant features. Nguyen and others combat the limitations of excessive amounts of labeled data needed to train supervised learning models such as DNNs. They examine an unsupervised method called a variational autoencoder and use gradients generated by the autoencoder to form "gradient-based fingerprinting" and explain anomaly predictions. A fingerprint is formed from the feature and corresponding gradient of it.

Methods for Instance-based

Challenges: Dynamics and Large or Too Small Volume.

Handling Dynamic Data.

Challenge. Due to the changing landscape of new data being generated daily, adaptive models have been ever more important to dynamic data, especially as data has been growing exponentially for the past decade and now the digital world contains roughly 2.7 zetabytes . Figure summarizes the significant and novel dynamic network intrusion models developed recently.

Stream-based models. Since dynamic data may come in the form of a stream, researchers have looked at specializing model for stream data. To resolve the issue of irrelevant data in dynamic streaming data, Thakran et al. employed density and partition-based clustering methods along with weighted attributes to handle noisy data in streaming data, which was used for outlier detection. For better real-time responsiveness from intrusion detection models, HewaNadungodage et al. accelerated outlier detection with parallelized processing power from a graphics computing unit (GPU). Instead of improving upon the real-time speed in which outliers are detected, Noorbehbahani et al. looked towards a more adaptive model that uses incremental learning, which still performs well with limited labels in streaming data. They implemented a mixed self-organizing map incremental neural network (MSOINN) and "within and between" clustering for offline and online learning. An initial cluster set from the network training data and initial classification model are generated during the offline phase. Clusters are updated Reinforcement learning. Reinforcement learning is one type of machine learning that learns a mapping, or a policy, between the states of a system and the actions it can execute given a reward and punishment notion . Through an adaptive approach, Bensefia and Ghoualmi proposed the integration of an adaptive artificial neural network and a learning classifier system that uses a reactive learning base to learn new attack patterns. There has recently been research on cloud environments and applying reinforcement learning to changing data in the cloud by Sethi et al. , who applied reinforcement learning to the cloud where a host network communicates with an agent network through VPN. Log generation from the virtual machine was provided to an agent that applied a deep Q-network and compared the model's result with the actual result from the administrator network, calculating the reward and iterating until the reward was maximized. Incremental learning. With data in dynamic environments, it is necessary that pretrained models are updated with new data in an incremental fashion without compromising classification performance on preceding data . Addressing botnet intrusion attacks, Feilong Chen et al. argued that botnet detection starts with the set of server IP-addresses visited by past client machines, so an incremental least-squares SVM was implemented to be adaptive to feature and data evolution. Meng-Hui Chen et al. made a population-based incremental learning method that learned from evolved data through past experiences and applied collaborative filtering to automate classification, adapting to key features in the data. A shift towards more scalable applications came with an online neural network accompanied by an SVM in Reference .

Handling Big Data.

Challenge. For big data, processing such large amounts of data is overwhelming, so optimization methods were devised to speed up preprocessing, such as reduction methods that remove redundant features and reduce the size of the data. Figure depicts the paradigms from three pivotal methods handling large amounts of data using incremental learning, parallel processes, and Apache Spark for Cloud Computing.

Incremental learning. To handle such large amounts of data, incremental learning may be applied to process it in increments. Chen et al. implemented an incremental training method that 8. Novel small data transfer meta learning.

repeatedly trained one convolutional layer then added another layer to a convolutional neural network (CNN) as new data came in until the target structure was achieved for the final CNN to optimize training time.

Cloud computing. With the advent of cloud computing platforms such as Amazon Web Services (AWS) and the Apache software foundation, using virtual services is not only available, but fast. The current research interests appear to lie in implementing machine learning with the Apache services. Manzoor and Morgan used Apache Storm to accelerate intrusion detection and employ a real-time support vector machine-based intrusion detection system; Faker and Dogdu used Apache Spark to implement deep feed-forward neural network, random forest and gradient boosting tree methods; most recently, Morfino and Rampone used the MLlib library of Apache Spark to reduce training time for their highest performing model-a decision tree-so they can fit the model to over 2 million rows of data and tackle SYN-DOS attacks.

Handling Small Data.

Challenge. The concomitant challenge with a growing network intrusion data repository is the continued lack of data on more current, diverse network attack types. As seen from Section 3, datasets have been riddled with a lack of evenly represented attack classes. Some datasets are dominated by specific attacks, while other types of attacks are underrepresented. Some datasets are dominated by non-attack (benign) class and all the attack types are minority classes. To resolve the issue of small amounts of data, specifically a lack of attack types, meta-and transfer-learning techniques have been explored. Novel machine learning models implementing the two techniques are highlighted in Figure .

Meta learning. Meta-learning uses automated learning to improve the way in which a model learns from data. Typically data is split into learning and prediction sets. The support set is in the learning set, and training and testing sets are in the prediction set. In "few-shot" learning, prediction error on unlabeled data is intended to be reduced given only a meager support set. Panda et al. conducted learning with multiple classifiers where ensembles of balanced nested dichotomies for multi-class problems were employed to handle multi-class datasets and make intelligent decisions in identifying network intrusions. A similar ensemble-based method using bagging and Adaboost was proposed by Abdelrahman and Abraham . They implemented the meta-learning technique of Error correcting output code (ECOC), where, per attack class, a binary string of length k is made so each bit is a classifier output and the class with closest string of outputs are returned and used for classification. As a direct response to handling the limited number of malicious samples in network data, Xu et al. devised a few-shot meta-learning method that used a deep neural network and a feature extraction network. The few-shot detection begins with a comparison between feature sets extracted from two data flows and a delta score indicating how different the two input data flows are. During the meta-training phase, samples from query and sample sets are compared and average delta scores are calculated. During meta-testing, samples from the test set and support set are compared and predicted labels for samples are the ones with the minimum average delta score in the support set.

Transfer learning. Just as with the lack of labeled data, transferring knowledge from other data sources through transfer learning can resolve issues of a lack of data, specifically on attack types. Because generating labels for data can be time-consuming, Zhao et al. employed a heterogeneous feature-based transfer learning method to detect network anomalies that was compared to other feature-based approaches such as HeMap and Correlation Alignment (CORAL). Rather than feature-based methods, mimic learning has been applied as a means of transfer learning by retraining a parent model-pretrained on private data-on public data to protect privately collected data and improve accuracy in the final model. Shafee et al. transferred the knowledge from a privately trained model-a random forest that performed best during experimentation of the teacher model-to a public training setting, producing a shareable student model. More niche to robust vehicles, Controller Area Networks (CANs) were revealed to be easily exploited and that there was a lack of intrusion data on CANs. Thereby, Tariq et al. recently collected CAN traffic data using two CAN buses and applied transfer learning to train a convolutional long-short term memory network on the new intrusion data.

RESEARCH TRENDS AND FUTURE DIRECTIONS

Figure displays the trends of research interests from 2010 to 2020 on data-driven NID methods.

Research Trends

Upon examining literature from the past decade on NID, there was already a pre-existing interest in big data research since 2010. This interest can be attributed to the large amounts of data on the Internet since 2010, as mentioned in Section 2 of the article, which continued growing through the past decade. 2019 saw the largest number of articles on big data where researchers continued to study parallel processing techniques and incremental learning methods to handle processing large amounts of data. In 2010, there was also effort put into resolving the challenge of small data.

Although there were large amounts of data, data on different attack types were lacking, as exhibited in the datasets attack type breakdown and entropy analysis in Section 3 of the article. In general, the lack of network intrusion attack types, pertinent to the challenge of small data, comes from the typically short time frame that intrusions take place. Small data issues were first researched in the early 2010s, particularly with meta-learning.

With noisy data challenges, authors have done more extensive research into methods that weigh noisy observations over others in network intrusion datasets since 2017. Although there have not been many papers on handling noisy data, solutions to noisy data have been well established, such as rescaling features or using density-based feature selection. The majority of the research between 2010 and 2015 studied ways to work around big data and too few data. Since then, big data processing has remained a popular research topic in the field of network intrusion detection. However, due to the changing environment of the present-day databases, research addressing dynamic data issues has gone up. The lack of labeled data has seen more research proposing semi-supervised learning models. However, one area of research that has not seen much attention is real-world network data. 2010 and 2011 saw some honeypot emulation of networks for data collection, and it was only recently in 2020 when the LITNET dataset was made and released as one of the first real-world network intrusion datasets.

Discussion on Future Directions

Real-world Data Collection.

There was initially a step towards real-world network intrusion data by emulating a realistic network environment with honeypots that would attract attackers with synthetic (IXIA) data generation. However, simulated data may not be as valuable to fit and test a model on as data collected on a real-world network due to possibly incorrect network attack models and behaviors in sandbox network environments. The issue with the current research on applying models to network intrusion is that 46 of the papers in the taxonomy used the KDD Cup 1999 as an evaluation dataset for their models. Because it is synthetically generated, there is bias in the traffic patterns that real-world traffic would not have. A step towards more modern network attacks on a real-world network came with the LITNET dataset collected in 2020 on a Lithuanian network covering nodes in four major Lithuanian cities as being one of the first long-term (10 months) and real-world network intrusion datasets produced and made available for researchers. Realism and availability are the two significant areas that current network intrusion datasets should be striving to have, which will be a future goal for researchers interested in creating new real-world datasets. Currency and realism in normal network traffic and attacks are problems confirmed through word vector analyses in the figure referenced earlier. In turn, network intrusion research requires further data collection of realistic attacks in real-world networks.

Labeling Real-world Traffic.

Although traffic flows may be labelled manually by network security experts, real-world network traffic flow can easily grow into the millions. The UGR dataset from 2016 was labeled using log files from the honeypot system used for data collection. Often experts may be the ones responsible for labeling traffic data, while other datasets such as LITNET in 2020 are less clear on how labeling took place. Labelling training data has been a roadblock for anomaly-based intrusion detection since the late 2000s . Labeling traffic too scrupulously may go against privacy policies, so detection models tend be updated whenever data becomes labeled and manual labeling still occurs with offline learning . To handle newly labeled data being fed into intrusion detection models, there should be further development in adaptive models or incremental models such as an online incremental neural network with SVM by Constantinides et al. . Future research in labeling network data lies in devising more adaptive detection models and developing paradigms and techniques for efficient traffic data labeling .

Consumer Network

Intrusion. Specific to collecting data in a real-world network, the collection of data on consumer networks such as those at home, which are not armed with the same security resources as enterprise networks, lack datasets. Recently, Patel et al. handled the natural entropy with detecting anomalies in a home network by collecting basic traffic features such as packet size, source, and destination ports and analyzing feature entropy. Further data collection in consumer networks has yet to be seen but is a viable route for research in the future.

Extending Anomaly Detection to Cloud Environments.

Aside from speedup in model convergence or reducing anomaly detection time with cloud computing, exploring network intrusion in cloud environments has yet to be exhaustively researched. A hypervisor-based cloud network intrusion detection system based on statistical analytics was devised by Aldribi et al. , but more sophisticated attack methods have yet to be implemented, as Aldribi and others have noted the overtly regular pattern in the traffic data that was collected. Another trait of cloud environments now is that there is constantly changing data. Because a tremendous amount of data is stored on the cloud, looking to develop machine learning for dynamic data in the cloud should be a future step in research. Sethi et al. applied a deep Q-learning reinforcement model to the cloud that is adaptable to changing data. Although there has been some work towards incorporating machine learning on dynamic data in the cloud, this is still nascent in terms of research and has potential to be studied further. Applying edge computing to cloud computing environments housing large amounts of network data is a potential route of research in the upcoming years to speed up detection time by bringing data storage and computation closer to the location where it is needed .

Machine Learning Scalability and Performance

Improvements. Parallelism in big data machine learning models could help researchers improve anomaly-based intrusion detection methods as currently , an emphasis is made instead on signature-based techniques using CUDA. NID data and traffic is rapidly changing, and a natural approach to handling dynamic data is processing data in increments using incremental learning. Recently, Constantinides et al. focused on scalability with incremental machine learning models. To handle the growth of their incremental self-organizing neural network commensurate with the growth of new data, a parameter n is used so any node that is nearest in Euclidean distance to more than n input vectors (more than n "wins") passes a "win" to the node with more than n "wins. " The aging parameter in the network also removes nodes that are not updated to maintain a manageable size. With the dearth of scalability research, in the future, researchers should continue to study methods that enable incremental machine learning models to be more scalable in light of tremendous data growth.

CONCLUSIONS

Network intrusion detection has existed for a little over two decades when network resources were misused. Although most data-driven network intrusion systems have not been integrated with an anomaly-based intrusion detection system on a large scale due to high false positive rates, researchers continue to improve anomaly detection accuracy and performance in the literature because of anomaly detection's ability to detect novel network attacks. This article introduces a general taxonomy on data-driven network intrusion detection methods based on a challengemethod heuristic and examines common public datasets used by papers in the taxonomy. Our focus is on the research trends gathered from the survey on network intrusion detection methods in the past decade. We conclude that, given the research trends over time, areas requiring future research are in big network data, streaming and changing data, and real-world network data collection and availability. Based on Table , only two of the papers that we investigated have fully reproducible code, so prospective papers can fill this gap in the research. Many solutions have been implemented for the other challenges specified in the taxonomy, but there remains a dearth of real-world network data, especially data on consumer networks, that could limit the accuracy of model performance in simulated network environments using real in-use network traffic data. This survey provides a high-level overview of the background on network intrusion detection, common datasets, a taxonomy of important research areas, and future directions.

INTRODUCTION Network intrusion detection (NID) monitors a network for malicious activity or policy violations . During the past two decades, data-driven methods have been developed and deployed for NID systems , most of which are machine learning models such as Naïve Bayes , Random Forests , Adaboost , and Deep Neural Networks . A review paper in 2009 summarized the NID systems that were supported by anomaly detection algorithms . In this survey, we present a broader view of data-driven NID, which includes related work from the past 10 years, and present a taxonomy of challenges and methods in data-driven NID research.

Background Since the advent of computer networks, e-commerce, and web services, there has been a greater need for cyber-security and countermeasures toward network attacks. There was an interest in 182:2 D. Chou and M. Jiang intrusion detection in 1994, where intrusion detection was known to be a retrofit way to provide a sense of security when identifying unauthorized use, misuse, or abuse of computer systems . The concept of intrusion detection later became contextualized in cyber-security systems. The term "intrusion detection systems" describes the extraction of information from one or multiple computers in a network that identifies attacks from external sources, but also misuse of resources in the network from internal sources . Intrusion detection systems can be broadly categorized as either being host-based intrusion detection or network intrusion detection. Host-based intrusion detection monitors host-specific actions such as system files being accessed or applications in use. A network intrusion detection system is focused on monitoring data flow between computers and "sniffs" for anomalous network traffic between different computers in the network . There are two general behaviors in a network: normal and anomalous. Normal network behavior follows a specific criteria in terms of the traffic volume, applications on the network, and types of data exchanged. Network anomalies fall into two general categories of network failures such as network congestion or file servers being down and network security attacks such as DDoS and other attacks that are conducted by a malicious agent . Network intrusion detection systems aim to distinguish the norm from security-related anomalies and detect attacks on computer networks. Network intrusion detection methods can be anomaly-based that identify malicious activity that departs from normal-defined behavior on a network or signature-based that identifies known attacks based on pattern matching. Because signature-based detection relies on seen patterns, it is not as effective in detecting novel attacks, or zero-day attacks, so anomaly detection is often used to detect novel attacks.

Past Surveys Among the network intrusion detection surveys gleaned from the past decade, as presented in Table , many have constructed taxonomies along with problem-solution frameworks for cloudcomputing platforms. Jeong et al. addressed the anomaly teletraffic intrusion detection systems in Hadoop-based platforms where there is a heavy focus on the methodology of statistical, machine learning, and knowledge-based models. Different attributes of big data-storage volume, velocity, variety, intrusion detection system, and cost-are associated with problems and technical solutions specific to Hadoop-based platforms. A new platform was proposed for anomaly teletraffic intrusion detection systems on Hadoop. Modi et al. followed a high-level introduction of intrusion detection to cloud-based systems-a common solution to these intrusions being firewalls-and identified differences between signature and anomaly-based detection. Keegan et al. inspected network intrusion detection datasets, approaches, cloud environments, algorithms, and advantages and disadvantages among the literature. Other authors primarily heeded the network intrusion detection datasets rather than its methods. Ring et al. examined packet-based, flow-based data along with host log files. Data recording environments were compared from the literature and a multitude of datasets, including some data repositories found on the Internet, were discussed along with their drawbacks. Ring presented a comprehensive overview of 34 datasets, their drawbacks, and how they may be related if one dataset was built off of another. Davis and Clark studied intrusion detection features derived from network traffic along with data preprocessing methods including clustering, filtering packets by high anomaly score or extracting subsets during traffic payload analysis, tracing TCP sessions, statistical features per connection, and create separate dataset. Some papers were method-specific, as Resende and Drummond provided a comprehensive review of random forest-based network intrusion detection. Resende and Drummond presented both a high-level overview of random trees and its components: decision trees. Datasets and 2011. Data preprocessing for anomaly based network intrusion detection: A review Data preprocessing Relevant features construction using targeted content parsing and deeper network packet inspection . Anomaly teletraffic intrusion detection systems on Hadoop-based Platforms: A survey of problems and solutions

Framework Hadoop and big data platforms for speed, storage volume, and cost-efficiency 2012. A brief taxonomy of intrusion detection strategies

Strategies Taxonomy of traditional network intrusion detection . A survey of intrusion detection techniques in Cloud

Framework Incorporating IDS on host system and virtual machines . A survey of cloud-based network intrusion detection analysis

Framework Integrating machine learning algorithms and MapReduce to cloud computing environments Resende and Drummond. 2018. A survey of random forest-based methods for intrusion detection systems Machine learning strategy Application of random forest methods over time . A survey of network-based intrusion detection data sets

Data collection Categorization of 34 public datasets common evaluation metrics were reviewed and the authors concluded that, in future work, random forests will be used more on unbalanced data and on dynamic data due to its ability to adapt to incremental learning problems. General overviews of network intrusion detection definitions and infrastructures along with taxonomies to classify different types of intrusion detection systems were also made. Poston's taxonomy covered high-level definitions of the types of intrusion detection and the types of analysis that can be done on host-based and network-based intrusion detection. However, the taxonomy is fairly general and the paper does not address future directions to intrusion detection research. Other papers looked to a specific result after observing the challenges in each paper and comparing their machine learning methods, as Buczak and Guven organized their review based on a machine learning method, presented the papers that use that method, the data it used, the cyber approach (misuse or anomaly), and the number of times the paper was cited. Mitchell and Chen broke down the classification of intrusion detection by system, collection process, techniques, models, analysis, and response. Many visuals are dedicated to their four defined types of intrusion detection: anomaly-based, signature-based, specification-based, and reputation-based. Most and least studied IDS techniques are analyzed and future direction of research in repurposing existing work on wireless intrusion detection applications, multitrust with intrusion detection, specificationbased detection for cyber-physical systems, and others. Ahmed et al. analyzed four main categories of anomaly-based detection: clustering, classification, statistical, and information theory. Each category was evaluated based on the computational complexity among approaches of that type, the most significant network attacks, and what the output is in each technique.

Our Contributions There have been survey papers as broad as scanning over all network anomaly detection methods and as specific as cloud-based intrusion systems. Past surveys focused on the foundational knowledge of network intrusion detection frameworks such as TCP connection features or virtual machine layers in hypervisor/host systems. Surveys have looked into overviews of datasets, or comparisons between specific machine learning methods, all while reflecting on past literature. Many authors present previous work with charts comparing different papers and discussing challenges with cloud computing, growing data, and other open issues. Challenges have been addressed in many of these surveys, but there is a lack of solutions presented under future direction. Mitchell and Chen examined the most and least studied areas in wireless network intrusion detection to propose future research areas. Past surveys focus less on the most researched areas in data-driven NIDS over a long span of time, so we summarize trending data-driven NIDS research topics in a stacked bar chart over the past decade (see . In turn, we draw conclusions on plausible future directions in areas that researchers have not thoroughly investigated recently or research areas that they have abandoned.

Overview In Section 2, the history of data processing, cloud computing, the lack of specific network attack types, and general big data processing techniques are examined. Section 3 covers common datasets from DARPA 1998 to as recent as LITNET 2020 along with their statistics in terms of how network attacks are distributed and how unbalanced the datasets are based on entropy. Section 4 addresses the high-level organization of the taxonomy and the details of each challenge and corresponding solutions/methods. Section 5 discusses the trends based on the articles collected that form the taxonomy and areas to look further into. Section 6 presents conclusions from the literature survey and taxonomy of data-driven network intrusion detection and reinforces future directions that researchers can look into.

DATA PROCESSING The key purpose of anomaly detection systems is to separate anomalies from normal behavior. In computer networks, a network anomaly refers to circumstances where network operations deviate from normal network behavior . Anomaly-based network intrusion detection methods are important to identify novel intrusion attacks. Data reduction is done to remove large amounts of data to improve efficiency and reduce computational overhead. In network traffic, packets are exchanged and TCP connections are open for the exchanges to be carried out. Because so many packets are sent and received in a typical network, extracting only the first few packets of a TCP connection was done by Chen et al. to mitigate effects of large packet data. Beyond extraction of data during its collection, other authors selected specific network features based on their importance. Tan et al. aimed to address the challenge of the heavy computation associated with anomaly intrusion detection systems using linear discrimination analysis (LDA) and distance difference maps to select the most significant features. LDA finds an optimal projection matrix to project higher dimensional features to lower dimensions. This feature reduction method was done on payload-based anomaly intrusion detection. In 2013, Zhang and Wang applied a simpler feature selection method that underwent a sequential search and sifted through the features in the feature domain, where a feature was added if the accuracy from the Bayesian network detection model lowered after removing a feature. Most recently, attention has been directed towards new technologies in the cloud and newer optimizations with computation aside from parallelism. Cloud computing services allow for processing of large datasets, and a popular engine for big data processing is Apache Spark. Gupta and Kulariya presented a framework where correlation-based and chi-square feature selection were applied to obtain the most important feature set and Logistic regression, Support Vector Machines (SVMs), Random forest, Gradient Boosted Decision trees, and Naive Bayes were used for network intrusion classification from the MLlib library in Apache Spark. In 2019, Hajimirzaei

COMMON PUBLIC DATASETS AND REPRODUCIBILITY Table compares common datasets which are open-source and improvements of past datasets such as being one of the first publicly available intrusion detection system (IDS) datasets or being updated with newer attacks that are commonly used. Dataset inclusion was based off those that were most common among highly cited data-driven NID papers. Other datasets were not included, as some were not publicly available or did not make notable improvements on past datasets. Table presents the papers that used each dataset and the reproducibility of the methods that were applied to the datasets. These papers were included on the basis of the most cited papers over the past decade that used these datasets. The overarching criteria was that these papers had to be relevant to network intrusion detection.

Dataset Description 3.1.1 KDD Cup 1999. The KDD Cup 1999 was a version of the 1998 DARPA Intrusion Detection Evaluation Program that was collected by MIT Lincoln Labs in their packet traces and is one of the most widely used datasets for network intrusion detection . Lincoln Labs acquired roughly nine weeks of raw tcp dump data from a local area network (LAN), that simulates a similar environment as an air force LAN. The attacks fall into the four main categories: denial-of-service such as a syn-flood, unauthorized access to a remote machine (R2L), unauthorized access to a local superuser (U2R), and probing such as port scanning . Although the KDD Cup 1999 dataset is considered relatively large in that it contains 41 features and over 4.8 million rows of data, it runs into the issue of duplicates between training and testing data . The data is missing some important features such as IP addresses although there are basic TCP attributes provided such as the source and destination bytes. Although the KDD Cup 1999 dataset does capture a good number of attacks, the data was collected on a synthetic network. In general, the data collected is outdated, because it was made nearly two decades ago and has bias due to synthetic generation . Table 3. Datasets and Papers That Used the Datasets for Evaluation Dataset Research works that used the dataset for evaluation KDDCup1999 • [26, 27, 31, 34, 50, 57, 65, 72, 91, 92, 103, 112, 114, 148, 152, 158, 173, 176, 179, 181, 183, 187-189] [7, 33, 44, 49, 64, 70, 89, 90, 98, 100, 101, 117, 120, 122, 141, 159, 164, 172, 182, 185] NSL-KDD 2009 • [36, 45, 59, 73, 80, 81, 102, 105, 133, 134, 137, 150, 158, 170, 176, 181, 202] [60, 75, 93, 125, 142, 149, 163, 174, 184, 190, 197, 198] [69] UNSW NB15 IDS • [16, 20, 73, 161] [81, 89, 90, 122, 154, 174, 182, 184, 191] [69] UGR'16 • [109] [110] CIDDS-001 • [2, 144, 148] CICIDS'17 • [6, 11, 29, 45, 157] [63, 140, 191] [46, 69, 180, 194, 195, 201] CSE-CIC-IDS2018 • [91] LITNET-2020 • [38] MAWILab "•" for those that are general methods or frameworks. " " for those that pseudo code and implementation details are available. " " for those that have documented code associated with the paper.

NSL-KDD 2009. The NSL-KDD 2009 dataset was made to resolve issues of possible biases in duplicate data between training and testing datasets from the KDD Cup 1999 . The Canadian Institute for Cybersecurity and University of New Brunswick were involved in collecting the dataset. However, NSL-KDD removed some redundant, more frequent records in the training set that were from the KDD Cup 1999 dataset, which can still be important. In turn, this may lead to further biases given that the data from the raw TCP dump should still be kept. An underlying issue with the NSL-KDD dataset is that it still contains data from a network dating back as early as 1998's DARPA dataset.

UNSW NB15 IDS. The UNSW NB15 Intrusion Detection System dataset contains source files in the formats of pcap, BRO, Argus, and CSV along with reports by Dr. Nour Moustafa . The dataset was created with an IXIA traffic generator that had TCP connections to a total of three servers. Two of these servers were connected to a router that had a TCP dump and three clients, where the TCP dump resulted in pcap files. The third server was connected to a router with three clients as well. The two routers that the first two servers and the third server were connected to were separated by a firewall. An issue with the UNSW NB15 dataset is again with the realness in its data, because the dataset was created from a traffic generator. . The UGR'16 dataset was collected from several netflow v9 collectors in the network of a Spanish ISP by researchers from University of Granada in Spain . The data is split into a calibration and training set, where long-term evolution and periodicity in data is a major advantage over previous datasets. However, a major issue is that most of the network traffic is labeled as "background, " which may either be anomalous or benign. Also, there is a mix of synthetically generated network attacks along with real-world network traffic, which is not of the same quality if none of the traffic was simulated. The dataset was labeled based on the logs from their honeypot system in their setup.

UGR 3.1.5 CIDDS-001. The CIDDS-001 dataset was collected in 2017 by four researchers , two PhD students, and two professors, who are affiliated with the Coburg University of Applied Sciences in Germany . The data was part of the project WISENT, funded by the Bavarian Ministry for Economic affairs. The intention of the dataset was to be used as an evaluation dataset for anomaly-based intrusion detection systems. The dataset is labelled and flow-based, where a small business environment was emulated on OpenStack. For the infrastructure, on the Internet, there are three attackers and an external server that has a firewall separating it from a server, where there are three layers: developer, office, and management. There are four servers that are in the OpenStack environment containing the three subnet layers. Generation of DoS, Brute Force, and Port Scanning occurred in the network. The first label attribute is traffic class: normal, attacker, victim, suspicious, and unknown. The second label attribute is attack type and the third being an attack ID. Because the external server emulates a real network environment, the CIDDS-001 dataset is primarily used for benchmarking. There are only three types of attacks, which unveils a lack of diversity in the data .

CICIDS'17. The CICIDS dataset was collected under the Canadian Institute of Cybersecurity as well and University of New Brunswick . The generation of network traffic came from a proposed B-profile system where abstract behaviors were derived for 25 users based on HTTP, HTTPS, FTP, SSH, and email protocols. With regards to the victim and attacker network information, there was a firewall against the IPs 205. .165.80 and 172.16.0.1 and a DNS server at 192.168.10.3. The attackers network comprises two IPs: Kali: 205.174.165.73, Win: 205.174.165.69. The victim network is composed of 2 Web servers 16 Public, 6 Ubuntu servers, 5 Windows servers, and a MAC server. The data collection occurred over the course of five days where Monday was benign activity, Tuesday was brute force, Wednesday was DoS, and Thursday was web attacks where the afternoon saw Botnet, Port Scan, and a DDoS LOIT.

CSE-CIC-IDS2018. The CSE-CIC-IDS2018 dataset is a collaborative project between the Communications Security Establishment (CSE) and the Canadian Institute of Cybersecurity (CIC) . A notion of profiles is adopted to generate data systematically. First is the B profile that captures behavior in users using machine and statistical learning techniques. M-profiles are human users or automated agents who may examine network scenarios. With the environment supported in AWS, the network topology includes an attack network of 50 machines, 5 departments holding 100 machines each and a server with 30 machines.

LITNET-2020. LITNET is a new annotated benchmark dataset where data was collected by four professors, a PhD student, and two students at the Kaunas University of Technology (KTU) . The infrastructure of the network is composed of nodes with communication lines connecting them. The LITNET topology consists of senders and receivers, netflow senders (Cisco routers), and a netflow server. The netflow exporters were in four cities in Lithuania, Vilnius Gediminas Technical University, and two KTU university nodes. The dataset contains real network attacks in Lithuanian-wide network with servers in four geographic locations within the country. 3.1.9 MAWILab. MAWILab is a database containing the dataset from the MAWI archive that records network traffic data between two endpoints [95]: one in Japan and another in the U.S. MAWILab's dataset has been contributed to since 2010 and records 15 minutes of network traces each day. Labels of network traffic are generated from anomaly classifiers based on port numbers, TCP flags, and ICMP codes along with a taxonomy of traffic anomalies based on packets headers and connection patterns . The graph on MAWILab's website divides the type of traffic over the course of 13 years based on byte and packet ratios. HTTP traffic used to be very common from 2007 to 2017, but sharply decreased at the end of 2017. Port Scanning is uncommon, where "multiple points" was the second most dominant traffic type from 2007 to 2017. A spike in denial of service (DoS) data was collected between 2011 and 2012. Currently, the most common type of traffic is multi points, then http, then IPV6 tunneling and alpha flow by byte and packet ratio. The number of anomalies from 2007 to 2020 ranged roughly between 100 to 200 at any time. Outliers are as low as 50 anomalies and as high as 500 anomalies daily. Since the network traffic has been between over the same link and two endpoints since 2007, MAWILab's network may not be as similar to most other networks used now. In addition, the labels fall into four broad categories: anomalous, suspicious, notice, and benign. The labels are dependent on the anomaly classifiers, so there may be misclassified traffic.

Reproducibility on Datasets The code repository by He and others implemented a LSTM neural network, Multimodal Deep Auto Encoder (MDAE), Autoencoder (AE), Gaussian Restricted Boltzmann Machine (RBM), and Multimodal-sequential approach with deep hierarchical progressive network (MS-DHPN) in Python that were trained on the network intrusion datasets NSL-KDD 2009, UNSW NB15 IDS, and CICIDS 2017. The repository contains separate files to load data and run the different models to reproduce results. However, the train and test dataset paths are defined specific to the author's environment along with the naming schemes that they chose. The paper does not specify how their renamed CSV file paths were derived from the original CSVS in each of the datasets. The code is present, but not reproducible without consultation from the authors. The repository by Roberto and others implemented logistic regression (LR), random forest (RF), and SVM in Python on the UGR 2016 dataset. The AUC, precision, recall, F1-score, and support metrics are reproducible for these models, where the model, number of iterations, number of cross-validation folds, and configuration file path are specified. However, only the SVM model results were included in the code repository. There was scaling of the data prior to training and testing the models when running the main Python file, but their implementations of the partial least squares regressions described in the paper were not provided in the code. The code is partially reproducible for some of the models' performances, but not all. The code repository made public by Faker and others implemented all their preprocessing and machine learning models in IPython on the CICIDS 2017 network intrusion dataset. However, no details in the README file points to Python package versions, resulting in the user inferring what versions were used at the time the code was run by the authors. The tensorflow package should not be version 2 for the code to run, which restricts the versions of Python to 3.7 or earlier. The package distkeras contains missing methods in its SequentialWorker class such as add_history and training_history, so a follow-up on package versions and fixes with the authors is needed. The repository common to Zhang and others' 2019 papers on hierarchical clustering and parallel cross convolutional neural network download process can be time-consuming. Also, there may be version issues, depending on the Python version, but python3.6 -m venv env can create a Python 3.6 virtual environment that supports tensorflow before version 2: pip install tensorflow==1.5. The data used in the paper is online and models are reproducible. The code repository released by Zhong and others contains a demo that consolidates the code for parsing the network flow packets, extracting features, training the deep belief network autoencoder and LSTM, and plotting the anomaly scores for the indices of the network packets. The model was tested on the MAWILab and CICIDS 2017 intrusion datasets. The code is able to completely recreate the results from the paper. The code repository provided by Xu and others is not reproducible, as the code and datasets link in the paper leads to a site with an insecure connection and a privacy error. Further consultation with the authors would need to take place.

A TAXONOMY: CHALLENGES AND METHODS Figure presents a hierarchical chart of categorized high-level challenges and recent methods to resolve them. This section will discuss the challenges and introduce the methods in details. The papers in the taxonomy were included because they are relatively highly cited by other researchers and can highlight a moment in the progression of a research area, such as big data or dynamic data.

Lack of Real-world Network Data Challenge. When network traffic data was initially being collected, even as early as the KDD Cup dataset from 1999, attacks were outdated and not compatible to attacks done in the real-world. Because using real-world networks to collect network traffic was costly, researchers looked to simulating realistic networks with synthetic data generation or a simulated virtual network as an alternative. Initially, honeypots were used as a means of simulating a virtual network environment to attract attackers and gather traffic data. Honeypots are security resources that are meant to be misused by malicious attackers, where such attacks would be recorded in databases. They consist of a decoy, or an information source, and a security program that provides attack monitoring and detection . These mechanisms can be used to collect network intrusion data with simulated realism that run in a virtual machine , containing possibly more than one honeypot to resemble a distributed honeypot system to simulate a distributed network more accurately . The main drawback with honeypots is their limited vision on network attacks. A honeypot is only aware of an attack if it is attacked, but would not be able to detect attacks directed at other systems. The use of TCP dumps in IXIA traffic generation also plays a large role in simulating realistic network intrusion data by synthetically generating data, which Moustafa and Slay have done to create the UNSW-NB15 dataset. They generated data with an IXIA traffic generator, then collected pcap files extracted from a tcpdump. This synthetic data generation was improved upon in 2017 by Haider et al. with the generation of network traffic via IXIA Perfect Storm and collection of the host's network logs during the simulation. This was better than the UNSW-NB15 dataset, because UNSW-NB15 lacked the information of normal and synthetic data that came from the operating system's log files. Haider et al. also verified the realism of their dataset through the Sugeno fuzzy inference engine . Architectures of main approaches to the creation of real-world network data are illustrated in Figure . Collection in public network infrastructure. In the past couple of years, researchers have looked to collect network traffic data in a cloud environment due to the growing usage of cloud computing platforms such as Amazon Web Services and Google Cloud. A mixture of virtualization and cloud intrusion detection using hypervisors have been implemented as well, which can resolve the issue of small datasets by aggrandizing network traffic data. In 2018, Hongda et al. combined network virtualization with software-defined networks to handle attack traffic. Their virtual network intrusion detection system (vNIDS) employed static program analysis to determine the detection states to share. The prototype of vNIDS was done in CloudLab for flexibility with processing capacity and placement location. In the past year, Aldribi et al. acknowledged the new challenging terrain that cloud computing provides for attackers. In turn, they implemented a new hypervisor-based cloud network intrusion detection system using multivariate statistical change analytics to detect anomalies. Alongside further research into generating network traffic data in the cloud, the realism in past datasets was called into question because of their outdated attacks and synthetic traffic generation. A proposed solution involved generating real-world network through gathering network traffic from a university network such as the Lithuanian Research and Education Network or a real virtual network of a tier-3 ISP done in the UGR'16 dataset .

Ability to Transfer. Challenge. There are no guarantees on how well network anomaly detection systems can perform in networks that consumers or corporations actively use. In fact, Allix and others state that it is impossible of obtain a dataset that reflects current real-world networks due to the rarity and secrecy of network intrusions. And it would not be practical to train a network anomaly detection system in a real-network setting due to the consequences of undetected intrusions on the security of the network. However, researchers can transfer what an intrusion detection system has learned in a simulated environment to an in-use network if the environment mimics traffic patterns of networks currently in use.

IDS Methods. There are a few recent paradigms for simulating a real in-use network environment, which are intended to be more efficient or scalable than past architectures: controllermicroservices virtualization or container-based traffic collection. A network simulation approach can vary based on whether the traffic is being delivered entirely from a commercial generator (e.g., IXIA PerfectStorm Tool) or at least partially derived from an enterprise tracing project. Enterprise tracing projects collect typical traffic in a enterprise network. The controller-microservices virtualization architecture introduced in Hongda et al. distributes network traffic to different detection logic program instances based on the network header information. The decomposition of the network intrusion detection system into three microservices allows for independent detection for different network traffic, reflecting a "divide and conquer" approach that can reduce resource consumption in the virtualization of NIDS. They generated background network traffic by delivering typical campus, internet, or enterprise traces of network traffic and labeled attack traffic from penetration tests in an isolated environment. Using typical in-use background network traffic in a simulated environment while introducing malicious attacks during penetration testing can provide estimates of an intrusion detection model's performance in a real-world network. Expanding from traffic collection in virtual machines, Clausen and others examine containerized networks to address the lack of ground truth traffic origin labels due to traffic originating from multiple background processes and a static design in virtualizations. Virtual machines require the use of hypervisors, which share the host's operating system resources. Containerized networks do not rely on hypervisors and instead share resources simultaneously across containers. Because containers isolate specific running applications, labels on the ground truth of traffic origin can be gathered. Containers are also lightweight and easily clonable, making containerized networks scalable and dynamic to changes in network environments. Attack traffic is produced by a select group of machines in the containerized environment, while benign traffic is generated using commercial traffic generators such as IXIA PerfectStorm Tool. The authors also mimicked network congestion by writing scripts in NetEm to artificially create packet delays, loss, and corruption. Optimal network generation can occur when benign traffic data is generated using typical traffic recorded in an in-use network most similar to the network that will implement the NIDS technology. Malicious traffic can be implemented by other machines in the environment that deploy current attacks such as Denial of Service. This traffic can be relayed in a virtual machine or containerized environment with Hongda and Clausen's architectures being two specific examples, respectively, and can be accompanied with artificial packet loss or delays to mimic real-world network congestion. Although an IDS trained in the artificial network may not perform well in a real network setting, the more similar a simulated training environment is to the network integrating the IDS, the better the IDS will perform. Challenge. Some traffic data in datasets may contain outliers that can come in the form of lessfrequent traffic classes. To combat noisy data or data with outliers, feature normalization methods have been applied to scale features and allow them to have similar effects in the model so noise would not weigh differently than the rest of the data. In other instances, density-based feature selection was used to identify the most important features by finding overlaps between feature probability distributions as well as non-overlapping regions. Feature normalization. Feature normalization methods can be applied to scale features and allow them to have similar effects in the model so noise will not be weighed differently than the rest of the data. Statistical methods have been used to facilitate network anomaly classification. In 2015, Delahoz et al. studied a probabilistic Bayesian self-organizing map model to perform unsupervised learning. To overcome the challenge of noise in the network data, they normalized continuous variables to have a mean of 0 and variance of 1, a standard normal distribution. For categorical variables, they are encoded before normalized. Categorical encodings are 1 if a feature is "activated" and 0 if not. Although normalization to a standard normal distribution via x -x σ is one method, rescaling logarithmically is another option. Hsu et al. developed an online intrusion detection system based on an autoencoder, SVM, and Random Forest ensemble where noise was dealt with feature normalization, where they used the two normalization functions: The functions were meant to rescale feature values to the proper range, where a is the original raw data value, a max being the max value among all values under the same feature as a, and (loд(a + 1)) max being the maximum loд(raw value + 1) for all logarithmic values under the same feature as a. Packets sent and received were two features that were extremely variable, because certain attacks (DDoS) entail much larger amounts of traffic in the network, so those feature values are normalized by its logarithm divided by its max value (first normalization equation). For features with lower variance, they are normalized by division of their max value (second equation). Specific to the sensitivity to noise innate in SVMs, Liu et al. worked towards mitigating the sensitivity that SVMs have for noise samples by applying a fuzzy membership to measure the distance between a sample and the hyperplane, as in SVM. The larger the distance, the smaller the weight coefficient for the sample. Each sample will have a distinct effect on the optimized classification hyperplane so outliers and noise (values with larger distance) will not impact the classifier plane as much as they are assigned lower weights. Density-based clustering. In other instances, density-based clustering is used to group together data from the same class and identify outliers that are unusually distant from the clusters observed. Because of the scattered nature of DoS attacks in wireless sensor networks (WSNs), Shamshirband et al. introduced an imperialist competitive algorithm (ICA) with density-based algorithms and fuzzy logic. Dense areas in data space are clusters and low-density areas (noise) surround them. Density-based clustering can detect shape clusters and handle noise. As network intrusion detection involves outlier detection, one may broaden the density-based approach to outlier detection. Tang and He presented an effective density-based outlier detection method where a relative density-based outlier score is assigned to observations as a means of distinguishing major clusters in a dataset from outliers. Similarly, Gu et al. applied a density-based initial cluster center selection algorithm to a Hadoop-based hybrid feature selection method for the mitigation of outlier effects.

Handling Redundant Data. Challenge. Some features in a network intrusion feature set may not contribute significantly to the predictive power of a model, so they may be removed based on feature importance. To handle redundant data, frameworks have been made to remove redundancies. Significant methods to handle redundant features in data are illustrated in Figure . Feature removal frameworks. The presence of data redundancies is a prevalent issue among network intrusion datasets, so researchers have developed frameworks where specific data removal techniques are recommended. Initial feature removal methods were integrated into computational intelligence approaches over the course of the 2000s and into the 2010s. In 2013, Ganapathy et al. wrote a review detailing a gradual feature removal method and modified mutual information method that selects features to maximize information for outputs (maximize relevance between inputs and outputs), conditional random field (CRF) as a layered method (each layer representing an attack type), and genetic feature selection where a set of trees are generated and the best set of features are extracted. Recent research appears to be reflective on integrating feature removal methods into a more streamlined model creation process. Bamakan et al. proposed an effective intrusion detection framework where feature selection is embedded in their objective Fig. . Methods for dealing with redundant features: Besides the above two methods, Autoencoder and Fuzzy Rough Set have also been used for reducing redundant features. function combined with time-varying chaos particle swarm optimization (TVCPSO). They streamlined their weighted objective function approach in a flow chart where, with each iteration, the fitness of the particles is updated in particle swarm optimization and chaotic search is done to find the global optima. Carrion et al. addressed the lack of the evaluation in network intrusion detection methods by providing a structured methodology that involved more rigorous feature selection or removal techniques. Including steps on how feature selection or removal took place to arrive at a final accuracy, as they stated, can allow for easier replication and more reliable evaluation in network intrusion detection literature. Feature selection. Feature selection can rule out redundant features and select a subset of the features in the data without significantly degrading the performance of the model . Early 2010's saw an interest in filtering-based feature selection methods as Koc et al. applied the hidden naïve Bayes (HNB) model to data with highly correlated features. Accompanying their HNB model was a filter-based feature selection model that is both correlation and consistency-based and relies only on the statistical properties in the data. Correlation feature-selection picks features that are biased towards highly correlated classes. The consistency-based filter has an inconsistency criterion that specifies when to stop reducing the dimensionality of the data. After filter-based methods, there was interest in using forward selection for feature ranking via Random Forest by Aljarrah et al. . But rather than finding the most optimal feature set, recently, Elmasry et al. claimed that feature selection can be time-consuming due to its exhaustive search, and that evolutionary computation techniques may be applied to find near-optimal solutions in a shorter amount of time. Automatic feature extraction. In the realm of automatic feature extraction, rough set theory and autoencoders are two important automation methods. Rough set ranks extracted features from network intrusion data and generalizes an information system by replacing the original attribute values with some discrete ranges , and autoencoders are considered to be nonlinear generalizations of principal component analysis that use an adaptive, multilayer "encoder" network to reduce data dimensionality . The early 2010's saw research interest in rough set theory for feature selection. Because simplified swarm optimization (SSO) may find premature solutions, Chung and Wahid went about improving the performance of it by conducting a local weighted search after SSO to produce more satisfactory solutions. They applied k-means clustering to continuous network data values and rough set theory to minimally sized subsets of the feature. The goodness in selected features is evaluated using the fitness function given input data D, |C | being the number of features, |R| being the length of a feature subset where R is a feature subset, and γ R as the classification quality of feature set R: Data is changing rapidly and with the increasing presence of irrelevant features, Liu et al. introduced a Gaussian mixture model to extract structural features in a network and identify anomalous and normal patterns where redundant features were removed and important features were optimally selected using fuzzy rough set theory. Alongside irrelevant features and the age of big data, the speed in which a model's objective function converges slows down. Both fuzzy rough set methods and autoencoders have been devised to tackle the large volume of data. With uncertainty surrounding whether network traffic is normal or anomalous, Selvakumar et al. presented a fuzzy rough set attribute selection method where the fuzzy-oriented rough degree on dependency of γ P (D) to subset P is defined as γ P (D), where a subset of features is evaluated on its relevance to the data. To handle growing data, as well as irrelevant data, Alqatf et al. proposed the use of an autoencoder for feature learning and dimensionality reduction to extract the most important features and filter out those that are redundant. Then they pass the reduced data into an SVM model for network traffic classification.

Handling Weakly Correlated Data. Challenge. The lack of strong correlation between features in data may make the construction of a model more challenging. Correlation can be artificially made through increasing the dimensionality of the data by data fusion or the introduction of new features. Increase dimensionality. Given one-dimensional feature data, Li et al. augmented the data to two dimensions and performed data segmentation where split data was later fused back together for network intrusion classification. They split feature data into four separate parts based on features that are correlated with one another. The one-dimensional feature space is converted to grayscale, then the data output from the four data components are merged and passed to the output layer of the multi-fusion CNN.

Discussion on Model Robustness. Challenge. A model is robust if the accuracy in its predictions is not impacted by changes in the input data such as from distribution shifts or outliers . For intrusion detection, changes in network flow data can also come from an "adversary" that may "obfuscate" attack payloads to mimic its benign counterparts. To mitigate loss in intrusion detection accuracy due to noise or adversaries, different robust methods have been developed. Robust Methods. Gornitz and others reframed network anomaly detection as an active learning task and tested the robustness of a one-class SVM. They first viewed a network payload as a vector x containing data of the network packet and mapping it to a vector space using string s and embedding function ϕ. For each string s, ϕ (x) returns 1 if s is in the payload x and 0 otherwise. Using this vector space representation, the support vector domain description (SVDD) was designed so normal data could be separated from anomalous data, where anomalies could easily be distinguished as outliers. They guided a security expert to low-confidence regions of the feature or vector space to administer active learning, where more attention was directed towards network data that had less accurate predictions. Their SVM was not designed to be robust against adversaries or noise in the network data, because model robustness was not factored into the construction of the SVM. It was during the empirical evaluation of their approach when they analyzed the effects of an adversary on their model's performance. Recent work focused on designing methods robust to distributional changes or the presence of outliers in network data. Papers either tackle method-specific limitations in robustness such as the sensitivity of SVMs to noise or general limitations that result in high false positive rates or undetected false negative outliers. Bamakan and others use ramp loss to remedy support vector's sensitivity to outliers. The ramp loss replaces hinge loss, which is a non-convex loss function that "depresses" the pressure of these outliers to make support vector models more robust and reliable. Armed with a new loss function, the authors apply the "concave-convex" procedure to minimize ramp loss by selecting the optimal s for the ramp loss R s (z) given the input vector z. Then for each pair of ∀i, j ∈ {1, . . . ,p} (i, j) for p output labels, the training dataset is partitioned into a positive, negative, and zero class. Variables δ 1 , k = 1 are initialized and an iterative update to δ i for the ith iteration is applied to construct a decision function of the form д work packet observation x has its label predicted based on the constructed decision functions. The ramp loss results in more sparsity, or more zero quantities, in the support vector model, because misclassified training examples do not simply become support vectors. To tackle the general problem of being unable to capture an intrusion signal occurring on a network, Ahsan and others applied kernel density estimation to Hotelling's T 2 control chart to design robust estimators. The Hotelling's T 2 chart can track the mean of a process where we observe independent and random vectors x i . The procedure is designed so, first, a matrix X normal is constructed, which is the representation of the benign training data in the network. Then fast minimum covariance determinant (MCD) is then run where Manhalanobis distances are computed per i ∈ {1, . . . , n} and the distances are sorted to form some permutation of the original set {1, . . . , n}. T and S are the mean and covariance of the new permutation set. The T 2 statistic in the Hotelling control chart using the mean vector and covariance matrix is computed for normal network connection data:T 2 F ast -MCD,i = (x i -T) T S -1 (x i -T). The distribution of theT 2 statistic is computed with kernel density estimation (KDE) using the Gaussian kernel. Then the control limit is calculated using the CDF of the empirical density of the T 2 F MCD,i statistic: The design of the robust method is centered around the computation of robust estimators for the Hotelling T 2 control chart, which can result in more accurate control limits, or horizontal lines denoting the boundaries between normal and anomalous data, in Hotelling T 2 charts.

Discussion on Tolerance to Adversarial Attacks. Challenge. An "adversary" can be a data generator or a network security expert that can mask network payloads to appear benign when they are in fact malicious. They have the intention of deceiving an intrusion detection system and leaving attacks on a computer network undetected. It is challenging to determine how an adversary will behave and ways to mitigate false positives or false negatives when detecting network intrusions, but methods using data generation have been devised to help models handle adversarial situations. Against Adversarial Attacks. Marino and others implemented an adversarial approach that sought to enable a machine learning model to correctly classify misclassified examples given they are modified by adversarial sample generation. Rather than deceiving their classifiers that have a linear model and a multi-layer perceptron model, the authors intend to understand why their network data is being misclassified. They find an adversarial example x that is classified as y while minimizing the distance between x and the original data x 0 : min x H ( y, p(y, x, w ))αI ( x, y) + ( xx 0 ) T Q ( xx 0 ) with the constraint that x min x x max , where Q is a positive semidefinite matrix that can be adjusted using specific weights. Note that y is not the same as the true label of the network data observation x 0 . x 0 , y is a sample from the dataset. H ( y, p(y, x, w )) is the cross-entropy between the estimated label of the adversarial example, p(y| x, w ), and the target label y. α weighs the contribution of the cross-entropy in the objective function and I ( x, y) is the indicator function that returns 0 if x is classified is y and 1 otherwise. The quadratic program optimization above is run and minimum changes are applied to correctly classify only misclassified samples x 0 , where we intend to construct x such that y is the predicted label. Explainability in misclassifications can be derived from adversarial sample generation, as the average of the deviations x 0x can be used to explain how far off the misclassified samples are from samples that would be classified correctly. Instead of using one adversarial attack generation method, Pawlicki and others constructed a pipeline for artificial neural networks that uses four different approaches, each minimizing the distance between the produced adversarial and real samples. The input network traffic dataset is partitioned into four subsets A, B, C, D. Portion A is used to train the intrusion detection system. Portion B is split between testing the detection system and training the adversary detector by performing four adversarial attacks-Carlini and Wagner attack, fast gradient sign method, basic iterative method, projected gradient descent-on 1397 "Attack" samples that are labeled as "adversarial. " The remaining data labeled as "non-adversarial" are added to the "adversarial" examples and form the adversarial detector training dataset. C, D are used to test the adversarial detector.

Handling Too Few Labels. Challenge. Data may have a lack of labels, particularly when network traffic is ambiguous or unlabeled. This poses another challenge between the stages of data preprocessing and model creation. Figure illustrates transfer learning, adversarial sample generation, and deep learning paradigms used to resolve the issue of unlabeled data. Unsupervised/Supervised Learning. Initially with a completely unsupervised learning approach, Casas et al. used an unsupervised sub-space clustering method to detect network intrusions by aggregated traffic packets into multi-resolution traffic flows. With too few labeled data, researchers may look to semi-supervised learning: First perform unsupervised learning on unlabeled data to label it, then pass the labeled data to a supervised learning model. More recently, there has been more research on semi-supervised network intrusion detection methods. Khan et al. proposed a semi-supervised model that initially classified unlabeled traffic as normal or anomalous with a probability score that was used as input for an unsupervised autoencoder to train on, then the data was passed into stacked pretrained neural layers with a soft-max layer for classification. Through a more randomized approach, Ravi and Shalinie proposed a semi-supervised learning model that employed repeated random sampling and k-means to label data as different traffic types, then passed it through classifiers developed in related work. Transfer learning. Transfer learning can compensate for the lack of labeled data via transfer of knowledge from other labeled data sources . Singla et al. examined the viability in transfer learning for imbalanced datasets; namely, the UNSW-NB15 dataset was split into labeled sub-datasets. Each sub-dataset is split into a source dataset and a target dataset, where the classifier was pretrained on the source dataset, then retrained on the target dataset to combat the lack of labeled data. Beyond the synthetic dataset UNSW-NB15, a network type that has recently been explored was the consumer network, which does not have the firewall or switches to deter network intrusion attacks. Patel et al. proposed normalized entropy from features in payload, packet and frame statistics to be funneled into a training and testing dataset and passed into a one-class SVM for classification of traffic in consumer networks. Through the collection of packet capture data sent from programs on devices in a consumer network, a consumer network dataset was constructed to combat the lack of consumer network datasets. Patel and other researchers exhibited that exhaustively labeled datasets are not necessary for accurate intrusion detection models.

Adversarial sample generation. Adversarial sample generation is done to fool a machine learning model, especially a neural network, with adversarial samples, so correctly classified data can be mistakenly identified for another class . Using a random forest, Apruzzese et al. used network flows to identify normal and botnet activity. The adversary is assumed to have already compromised at least one machine in the network and deployed a bot to communicate with other machines through limited "Command and Control infrastructure. " The attacker intends to trick the classifier by slightly increasing flow duration and exchanged bytes and packets. Instead of a base adversary that changed feature attributes in adversarial samples, Cheng used a generative adversarial network (GAN) where a generator aims to refine the generation of fake data while a discriminator determines which network traffic flows are legitimate or anomalous, which was what Usama et al. did as well . Similar to Apruzzese's adversarial sample generation, but in a more controlled environment, Aiken and Scott-Hayward developed an adversarial testing tool called Hydra that behaves as an emulator for a system that launches attacks in a software-defined network where a test manager sends traffic, evading the classifier by changing payload size and rate. In all such cases, adversarial sample generation not only offers more data to combat unlabeled data, but can develop defensive mechanisms for more robust NID systems.

Handling Unbalanced Labels. Challenge. The data may also be imbalanced where network intrusion attacks are disproportionately smaller than that of normal network activity. As discussed in Section 3 on common public datasets, most network intrusion datasets face considerable imbalance between normal and anomalous traffic, but especially among attack types. Figure highlights the random oversampling and undersampling techniques used to handle minority and majority classes in network intrusion datasets and main machine learning models implemented to handle unbalanced classes. Over/under-sampling. Oversampling is meant to increase samples from the minority class and balance the distribution of data among attacks and normal activity in a network. Undersampling removes samples from the majority class to allow minority and majority classes to become similar in size, disallowing misclassifications of underrepresented network attacks . A collection of work has been written last year on the use of over or under sampling to balance network intrusion datasets. Mikhail et al. resolved the issue of minority attack classes by training an ensemble classifier with undersampling data and training each sub-ensemble. Gao et al. noticed that the KDD Cup dataset they used had a large amount of user to root (U2R) attacks, so they changed the proportion of classes in samples passed as input into the models. They used classification and regression trees (CARTs) where multiple trees were trained on adjusted samples by random undersampling-similar to Mikhail and others' work-where 1 16 of normal traffic (a majority class) was sampled to solve imbalances. Although minority sampling can allow for more evenly proportioned classes for network intrusion detection, there is the potential for majority classes to be predicted with lower accuracy due to undersampling of majority classes or oversampling of minority classes. Zhang et al. resolved this issue by combining weighted oversampling with a boosting method. The weighted oversampling technique updates weights associated with minority classes and the misclassified majority class observations are forced on the classifier to learn. Optimal feature extraction. Ranking features based on their importance can be done to reduce a feature set to an optimal feature subset. Thaseen et al. used a consistency-based feature selection method that determines whether the value and class label of two observations match. Zhang et al. aggregated time intervals of network traffic into subgroups to find information from the five features: address count, packet count, port count, byte count, and the bytes per packet. Siamese neural network. To combat the challenge of minority and majority classes in imbalanced datasets, Bedi et al. employed a few-shot learning method called a Siamese Neural Network that was first introduced by Bromley et al. . Siamese neural networks compute the similarity between two input samples to determine how similar or dissimilar they are, so pairs of samples belonging to the same class such as DoS-DoS, Normal-Normal, U2R-U2R were considered most similar and labeled with a 1, whereas distinct pairs were labeled with a 0. Traditional methods of oversampling and undersampling were bypassed with the use of siamese neural networks paired with sampling equal number of observations per network traffic class. Feature fusion. Feature fusion can combine different data that will, together, result in balanced attention to features. Zhang et al. a parallel cross convolutional neural network that fused traffic flow features learned by two separate convolutional neural networks to make the network pay more attention to minority attack classes. After downsampling the two neural networks, the number of channels was doubled in the output feature map, then a pooling layer was applied to reduce the dimensionality of the data by combining outputs of clusters in one layer into one neuron in the next layer. Genetic programming. Genetic programming uses an agent to learn an optimal or near-optimal solution to a problem and can be used in conjunction with machine learning models to evolve the model until its fitness is optimized for network intrusion detection. Le et al. found genetic programming to perform well on imbalanced datasets when using accuracy as the fitness function: the number of true positives and true negatives over all classified observations.

Discussion on Explainability. Challenge. Model explainability is being able to understand the behavior of a machine learning model and why it presents specific solutions or predictions for given tasks . Explainability in network intrusion detection models is important due to the side effects of a wrong prediction. If a model predicts a false negative, or presumes that a network packet is not anomalous or malicious when it is responsible for intrusion of a computer network, then the entire network could be in jeopardy, leading to possible breaches in private information. And if one cannot explain why a model made this poor and costly decision, then individuals will be less accepting of novel intrusion detection systems powered by machine learning models. Thereby, research into more explainable intrusion detection models can heighten the chances of integrating the model into a corporate or public network. Explainable Methods. Explainable network intrusion detection models have been gaining traction such as in References , but there are a few representative papers that portray the changes of explainable IDS methodologies. Adetunmbi and others explored seeking model explainabillity using a rule system. Their rule system is based off of rough set theory, where rules are denoted by logical implications. Based on the values of a set of features, or attributes A 1 , . . . , A k , the rules (A 1 = a 1 ) ∧ . . . ∧ (A k = a k ) will decide the outcome of whether or not a network connection record is anomalous. Although rough sets can generate simple decision rules that are explainable to practitioners and indeed three times faster than a traditional k-nearest neighbors approach that they implemented, the approach did not perform well on remote to user (R2L) or U2R attacks in the KDD Cup 1999 dataset. To improve detection accuracy while maintaining model explainability, Amarasinghe and colleagues present a post hoc framework of explanations for their deep neural network (DNN) predictions. They provide the relevance of input features for the prediction, the prediction confidence, and a textual summary of why the prediction was made such as "DoS attack WITH high confidence BECAUSE connections to the same host in the last 2 seconds is high. " The textual summary and feature relevancy are similar to rough set's decision rules that are based off relevant features. Nguyen and others combat the limitations of excessive amounts of labeled data needed to train supervised learning models such as DNNs. They examine an unsupervised method called a variational autoencoder and use gradients generated by the autoencoder to form "gradient-based fingerprinting" and explain anomaly predictions. A fingerprint is formed from the feature and corresponding gradient of it.

Methods for Instance-based Challenges: Dynamics and Large or Too Small Volume.

Handling Dynamic Data. Challenge. Due to the changing landscape of new data being generated daily, adaptive models have been ever more important to dynamic data, especially as data has been growing exponentially for the past decade and now the digital world contains roughly 2.7 zetabytes . Figure summarizes the significant and novel dynamic network intrusion models developed recently. Stream-based models. Since dynamic data may come in the form of a stream, researchers have looked at specializing model for stream data. To resolve the issue of irrelevant data in dynamic streaming data, Thakran et al. employed density and partition-based clustering methods along with weighted attributes to handle noisy data in streaming data, which was used for outlier detection. For better real-time responsiveness from intrusion detection models, HewaNadungodage et al. accelerated outlier detection with parallelized processing power from a graphics computing unit (GPU). Instead of improving upon the real-time speed in which outliers are detected, Noorbehbahani et al. looked towards a more adaptive model that uses incremental learning, which still performs well with limited labels in streaming data. They implemented a mixed self-organizing map incremental neural network (MSOINN) and "within and between" clustering for offline and online learning. An initial cluster set from the network training data and initial classification model are generated during the offline phase. Clusters are updated Reinforcement learning. Reinforcement learning is one type of machine learning that learns a mapping, or a policy, between the states of a system and the actions it can execute given a reward and punishment notion . Through an adaptive approach, Bensefia and Ghoualmi proposed the integration of an adaptive artificial neural network and a learning classifier system that uses a reactive learning base to learn new attack patterns. There has recently been research on cloud environments and applying reinforcement learning to changing data in the cloud by Sethi et al. , who applied reinforcement learning to the cloud where a host network communicates with an agent network through VPN. Log generation from the virtual machine was provided to an agent that applied a deep Q-network and compared the model's result with the actual result from the administrator network, calculating the reward and iterating until the reward was maximized. Incremental learning. With data in dynamic environments, it is necessary that pretrained models are updated with new data in an incremental fashion without compromising classification performance on preceding data . Addressing botnet intrusion attacks, Feilong Chen et al. argued that botnet detection starts with the set of server IP-addresses visited by past client machines, so an incremental least-squares SVM was implemented to be adaptive to feature and data evolution. Meng-Hui Chen et al. made a population-based incremental learning method that learned from evolved data through past experiences and applied collaborative filtering to automate classification, adapting to key features in the data. A shift towards more scalable applications came with an online neural network accompanied by an SVM in Reference .

Handling Big Data. Challenge. For big data, processing such large amounts of data is overwhelming, so optimization methods were devised to speed up preprocessing, such as reduction methods that remove redundant features and reduce the size of the data. Figure depicts the paradigms from three pivotal methods handling large amounts of data using incremental learning, parallel processes, and Apache Spark for Cloud Computing. Incremental learning. To handle such large amounts of data, incremental learning may be applied to process it in increments. Chen et al. implemented an incremental training method that 8. Novel small data transfer meta learning. repeatedly trained one convolutional layer then added another layer to a convolutional neural network (CNN) as new data came in until the target structure was achieved for the final CNN to optimize training time. Cloud computing. With the advent of cloud computing platforms such as Amazon Web Services (AWS) and the Apache software foundation, using virtual services is not only available, but fast. The current research interests appear to lie in implementing machine learning with the Apache services. Manzoor and Morgan used Apache Storm to accelerate intrusion detection and employ a real-time support vector machine-based intrusion detection system; Faker and Dogdu used Apache Spark to implement deep feed-forward neural network, random forest and gradient boosting tree methods; most recently, Morfino and Rampone used the MLlib library of Apache Spark to reduce training time for their highest performing model-a decision tree-so they can fit the model to over 2 million rows of data and tackle SYN-DOS attacks.

Handling Small Data. Challenge. The concomitant challenge with a growing network intrusion data repository is the continued lack of data on more current, diverse network attack types. As seen from Section 3, datasets have been riddled with a lack of evenly represented attack classes. Some datasets are dominated by specific attacks, while other types of attacks are underrepresented. Some datasets are dominated by non-attack (benign) class and all the attack types are minority classes. To resolve the issue of small amounts of data, specifically a lack of attack types, meta-and transfer-learning techniques have been explored. Novel machine learning models implementing the two techniques are highlighted in Figure . Meta learning. Meta-learning uses automated learning to improve the way in which a model learns from data. Typically data is split into learning and prediction sets. The support set is in the learning set, and training and testing sets are in the prediction set. In "few-shot" learning, prediction error on unlabeled data is intended to be reduced given only a meager support set. Panda et al. conducted learning with multiple classifiers where ensembles of balanced nested dichotomies for multi-class problems were employed to handle multi-class datasets and make intelligent decisions in identifying network intrusions. A similar ensemble-based method using bagging and Adaboost was proposed by Abdelrahman and Abraham . They implemented the meta-learning technique of Error correcting output code (ECOC), where, per attack class, a binary string of length k is made so each bit is a classifier output and the class with closest string of outputs are returned and used for classification. As a direct response to handling the limited number of malicious samples in network data, Xu et al. devised a few-shot meta-learning method that used a deep neural network and a feature extraction network. The few-shot detection begins with a comparison between feature sets extracted from two data flows and a delta score indicating how different the two input data flows are. During the meta-training phase, samples from query and sample sets are compared and average delta scores are calculated. During meta-testing, samples from the test set and support set are compared and predicted labels for samples are the ones with the minimum average delta score in the support set. Transfer learning. Just as with the lack of labeled data, transferring knowledge from other data sources through transfer learning can resolve issues of a lack of data, specifically on attack types. Because generating labels for data can be time-consuming, Zhao et al. employed a heterogeneous feature-based transfer learning method to detect network anomalies that was compared to other feature-based approaches such as HeMap and Correlation Alignment (CORAL). Rather than feature-based methods, mimic learning has been applied as a means of transfer learning by retraining a parent model-pretrained on private data-on public data to protect privately collected data and improve accuracy in the final model. Shafee et al. transferred the knowledge from a privately trained model-a random forest that performed best during experimentation of the teacher model-to a public training setting, producing a shareable student model. More niche to robust vehicles, Controller Area Networks (CANs) were revealed to be easily exploited and that there was a lack of intrusion data on CANs. Thereby, Tariq et al. recently collected CAN traffic data using two CAN buses and applied transfer learning to train a convolutional long-short term memory network on the new intrusion data.

RESEARCH TRENDS AND FUTURE DIRECTIONS Figure displays the trends of research interests from 2010 to 2020 on data-driven NID methods.

Research Trends Upon examining literature from the past decade on NID, there was already a pre-existing interest in big data research since 2010. This interest can be attributed to the large amounts of data on the Internet since 2010, as mentioned in Section 2 of the article, which continued growing through the past decade. 2019 saw the largest number of articles on big data where researchers continued to study parallel processing techniques and incremental learning methods to handle processing large amounts of data. In 2010, there was also effort put into resolving the challenge of small data. Although there were large amounts of data, data on different attack types were lacking, as exhibited in the datasets attack type breakdown and entropy analysis in Section 3 of the article. In general, the lack of network intrusion attack types, pertinent to the challenge of small data, comes from the typically short time frame that intrusions take place. Small data issues were first researched in the early 2010s, particularly with meta-learning. With noisy data challenges, authors have done more extensive research into methods that weigh noisy observations over others in network intrusion datasets since 2017. Although there have not been many papers on handling noisy data, solutions to noisy data have been well established, such as rescaling features or using density-based feature selection. The majority of the research between 2010 and 2015 studied ways to work around big data and too few data. Since then, big data processing has remained a popular research topic in the field of network intrusion detection. However, due to the changing environment of the present-day databases, research addressing dynamic data issues has gone up. The lack of labeled data has seen more research proposing semi-supervised learning models. However, one area of research that has not seen much attention is real-world network data. 2010 and 2011 saw some honeypot emulation of networks for data collection, and it was only recently in 2020 when the LITNET dataset was made and released as one of the first real-world network intrusion datasets.

Real-world Data Collection. There was initially a step towards real-world network intrusion data by emulating a realistic network environment with honeypots that would attract attackers with synthetic (IXIA) data generation. However, simulated data may not be as valuable to fit and test a model on as data collected on a real-world network due to possibly incorrect network attack models and behaviors in sandbox network environments. The issue with the current research on applying models to network intrusion is that 46 of the papers in the taxonomy used the KDD Cup 1999 as an evaluation dataset for their models. Because it is synthetically generated, there is bias in the traffic patterns that real-world traffic would not have. A step towards more modern network attacks on a real-world network came with the LITNET dataset collected in 2020 on a Lithuanian network covering nodes in four major Lithuanian cities as being one of the first long-term (10 months) and real-world network intrusion datasets produced and made available for researchers. Realism and availability are the two significant areas that current network intrusion datasets should be striving to have, which will be a future goal for researchers interested in creating new real-world datasets. Currency and realism in normal network traffic and attacks are problems confirmed through word vector analyses in the figure referenced earlier. In turn, network intrusion research requires further data collection of realistic attacks in real-world networks.

Labeling Real-world Traffic. Although traffic flows may be labelled manually by network security experts, real-world network traffic flow can easily grow into the millions. The UGR dataset from 2016 was labeled using log files from the honeypot system used for data collection. Often experts may be the ones responsible for labeling traffic data, while other datasets such as LITNET in 2020 are less clear on how labeling took place. Labelling training data has been a roadblock for anomaly-based intrusion detection since the late 2000s . Labeling traffic too scrupulously may go against privacy policies, so detection models tend be updated whenever data becomes labeled and manual labeling still occurs with offline learning . To handle newly labeled data being fed into intrusion detection models, there should be further development in adaptive models or incremental models such as an online incremental neural network with SVM by Constantinides et al. . Future research in labeling network data lies in devising more adaptive detection models and developing paradigms and techniques for efficient traffic data labeling .

Consumer Network Intrusion. Specific to collecting data in a real-world network, the collection of data on consumer networks such as those at home, which are not armed with the same security resources as enterprise networks, lack datasets. Recently, Patel et al. handled the natural entropy with detecting anomalies in a home network by collecting basic traffic features such as packet size, source, and destination ports and analyzing feature entropy. Further data collection in consumer networks has yet to be seen but is a viable route for research in the future.

Extending Anomaly Detection to Cloud Environments. Aside from speedup in model convergence or reducing anomaly detection time with cloud computing, exploring network intrusion in cloud environments has yet to be exhaustively researched. A hypervisor-based cloud network intrusion detection system based on statistical analytics was devised by Aldribi et al. , but more sophisticated attack methods have yet to be implemented, as Aldribi and others have noted the overtly regular pattern in the traffic data that was collected. Another trait of cloud environments now is that there is constantly changing data. Because a tremendous amount of data is stored on the cloud, looking to develop machine learning for dynamic data in the cloud should be a future step in research. Sethi et al. applied a deep Q-learning reinforcement model to the cloud that is adaptable to changing data. Although there has been some work towards incorporating machine learning on dynamic data in the cloud, this is still nascent in terms of research and has potential to be studied further. Applying edge computing to cloud computing environments housing large amounts of network data is a potential route of research in the upcoming years to speed up detection time by bringing data storage and computation closer to the location where it is needed .

Machine Learning Scalability and Performance Improvements. Parallelism in big data machine learning models could help researchers improve anomaly-based intrusion detection methods as currently , an emphasis is made instead on signature-based techniques using CUDA. NID data and traffic is rapidly changing, and a natural approach to handling dynamic data is processing data in increments using incremental learning. Recently, Constantinides et al. focused on scalability with incremental machine learning models. To handle the growth of their incremental self-organizing neural network commensurate with the growth of new data, a parameter n is used so any node that is nearest in Euclidean distance to more than n input vectors (more than n "wins") passes a "win" to the node with more than n "wins. " The aging parameter in the network also removes nodes that are not updated to maintain a manageable size. With the dearth of scalability research, in the future, researchers should continue to study methods that enable incremental machine learning models to be more scalable in light of tremendous data growth.

CONCLUSIONS Network intrusion detection has existed for a little over two decades when network resources were misused. Although most data-driven network intrusion systems have not been integrated with an anomaly-based intrusion detection system on a large scale due to high false positive rates, researchers continue to improve anomaly detection accuracy and performance in the literature because of anomaly detection's ability to detect novel network attacks. This article introduces a general taxonomy on data-driven network intrusion detection methods based on a challengemethod heuristic and examines common public datasets used by papers in the taxonomy. Our focus is on the research trends gathered from the survey on network intrusion detection methods in the past decade. We conclude that, given the research trends over time, areas requiring future research are in big network data, streaming and changing data, and real-world network data collection and availability. Based on Table , only two of the papers that we investigated have fully reproducible code, so prospective papers can fill this gap in the research. Many solutions have been implemented for the other challenges specified in the taxonomy, but there remains a dearth of real-world network data, especially data on consumer networks, that could limit the accuracy of model performance in simulated network environments using real in-use network traffic data. This survey provides a high-level overview of the background on network intrusion detection, common datasets, a taxonomy of important research areas, and future directions.