<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Reinforcement Learning for Cyber Security</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2021-11-02">2 Nov 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Thanh</forename><forename type="middle">Thi</forename><surname>Nguyen</surname></persName>
							<email>thanh.nguyen@deakin.edu.au.</email>
						</author>
						<author>
							<persName><forename type="first">Vijay</forename><forename type="middle">Janapa</forename><surname>Reddi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Deakin University</orgName>
								<address>
									<addrLine>Melbourne Burwood Campus</addrLine>
									<postCode>3125</postCode>
									<settlement>Burwood</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Paulson School of Engineering and Applied Sciences</orgName>
								<orgName type="institution" key="instit1">John A</orgName>
								<orgName type="institution" key="instit2">Harvard University</orgName>
								<address>
									<postCode>02138</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Reinforcement Learning for Cyber Security</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-11-02">2 Nov 2021</date>
						</imprint>
					</monogr>
					<idno type="MD5">B20A37159B787533831C9AD9E8009E4A</idno>
					<idno type="DOI">10.1109/TNNLS.2021.3121870</idno>
					<idno type="arXiv">arXiv:1906.05799v4[cs.CR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-02T12:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>survey</term>
					<term>review</term>
					<term>deep reinforcement learning</term>
					<term>deep learning</term>
					<term>cyber security</term>
					<term>cyber defense</term>
					<term>cyber attacks</term>
					<term>Internet of Things</term>
					<term>IoT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The scale of Internet-connected systems has increased considerably, and these systems are being exposed to cyber attacks more than ever. The complexity and dynamics of cyber attacks require protecting mechanisms to be responsive, adaptive, and scalable. Machine learning, or more specifically deep reinforcement learning (DRL), methods have been proposed widely to address these issues. By incorporating deep learning into traditional RL, DRL is highly capable of solving complex, dynamic, and especially high-dimensional cyber defense problems. This paper presents a survey of DRL approaches developed for cyber security. We touch on different vital aspects, including DRL-based security methods for cyber-physical systems, autonomous intrusion detection techniques, and multiagent DRL-based game theory simulations for defense strategies against cyber attacks. Extensive discussions and future research directions on DRL-based cyber security are also given. We expect that this comprehensive review provides the foundations for and facilitates future studies on exploring the potential of emerging DRL to cope with increasingly complex cyber security problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I NTERNET of Things (IoT) technologies have been em- ployed broadly in many sectors such as telecommunications, transportation, manufacturing, water and power management, healthcare, education, finance, government, and even entertainment. The convergence of various information and communication technology (ICT) tools in the IoT has boosted its functionalities and services to users to new levels. ICT has witnessed a remarkable development in terms of system design, network architecture, and intelligent devices in the last decade. For example, ICT has been advanced with the innovations of cognitive radio network and 5G cellular network <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, software-defined network (SDN) <ref type="bibr" target="#b2">[3]</ref>, cloud computing <ref type="bibr" target="#b3">[4]</ref>, (mobile) edge caching <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, and fog computing <ref type="bibr" target="#b6">[7]</ref>. Accompanying these developments is the increasing vulnerability to cyber attacks, which are defined as any type of offensive maneuver exercised by one or multiple computers to target computer information systems, network infrastructures, or personal computer devices. Cyber attacks may be instigated by economic competitors or state-sponsored attackers. There has been thus a critical need of the development of cyber security technologies to mitigate and eliminate impacts of these attacks <ref type="bibr" target="#b7">[8]</ref>.</p><p>Artificial intelligence (AI), especially machine learning (ML), has been applied to both attacking and defending in the cyberspace. On the attacker side, ML is utilized to compromise defense strategies. On the cyber security side, ML is employed to put up robust resistance against security threats in order to adaptively prevent and minimise the impacts or damages occurred. Among these ML applications, unsupervised and supervised learning methods have been used widely for intrusion detection <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>, malware detection <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>, cyberphysical attacks <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref>, and data privacy protection <ref type="bibr" target="#b17">[18]</ref>. In principle, unsupervised methods explore the structure and patterns of data without using their labels while supervised methods learn by examples based on data's labels. These methods, however, cannot provide dynamic and sequential responses against cyber attacks, especially new or constantly evolving threats. Also, the detection and defending responses often take place after the attacks when traces of attacks become available for collecting and analyzing, and thus proactive defense solutions are hindered. A statistical study shows that 62% of the attacks were recognized after they have caused significant damages to the cyber systems <ref type="bibr" target="#b18">[19]</ref>.</p><p>Reinforcement learning (RL), a branch of ML, is the closest form of human learning because it can learn by its own experience through exploring and exploiting the unknown environment. RL can model an autonomous agent to take sequential actions optimally without or with limited prior knowledge of the environment, and thus, it is particularly adaptable and useful in real time and adversarial environments. With the power of function approximation and representation learning, deep learning has been incorporated into RL methods and enabled them to solve many complex problems <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b23">[24]</ref>. The combination of deep learning and RL therefore indicates excellent suitability for cyber security applications where cyber attacks are increasingly sophisticated, rapid, and ubiquitous <ref type="bibr" target="#b24">[25]</ref>- <ref type="bibr" target="#b27">[28]</ref>.</p><p>The emergence of DRL has actually witnessed great success in different fields, from video game domain, e.g. Atari <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, game of Go <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, real-time strategy game StarCraft II <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b35">[36]</ref>, 3D multi-player game Quake III Arena Capture the Flag <ref type="bibr" target="#b36">[37]</ref>, and teamwork game Dota 2 <ref type="bibr" target="#b37">[38]</ref> to real-world applications such as robotics <ref type="bibr" target="#b38">[39]</ref>, autonomous vehicles <ref type="bibr" target="#b39">[40]</ref>, autonomous surgery <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, natural language processing <ref type="bibr" target="#b42">[43]</ref>, biological data mining <ref type="bibr" target="#b43">[44]</ref>, and drug design <ref type="bibr" target="#b44">[45]</ref>. DRL methods have also recently been applied to solve various problems in the IoT area. For example, a DRL-based resource allocation framework that integrates networking, caching, and computing capabilities for smart city applications is proposed in <ref type="bibr" target="#b45">[46]</ref>. DRL algorithm, i.e., double dueling deep Q-network <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, is used to solve this problem because it involves a large state space, which consists of the dynamic changing status of base stations, mobile edge caching (MEC) servers and caches. The framework is developed based on the programmable control principle of SDN and the caching capability of information-centric networking. Alternatively, Zhu et al. <ref type="bibr" target="#b48">[49]</ref> explored MEC policies by using the context awareness concept that represents the user's context information and traffic pattern statistics. The use of AI technologies at the mobile network edges is advocated to intelligently exploit operating environment and make the right decisions regarding what, where, and how to cache appropriate contents. To increase the caching performance, a DRL approach, i.e., the asynchronous advantage actor-critic algorithm <ref type="bibr" target="#b49">[50]</ref>, is used to find an optimal policy aiming to maximize the offloading traffic.</p><p>Findings from our current survey show that applications of DRL in cyber environments are generally categorized under two perspectives: optimizing and enhancing the communications and networking capabilities of the IoT applications, e.g. <ref type="bibr" target="#b50">[51]</ref>- <ref type="bibr" target="#b58">[59]</ref>, and defending against cyber attacks. This paper focuses on the later where DRL methods are used to solve cyber security problems with the presence of cyber attacks or threats. Next section provides a background of DRL methods, followed by a detailed survey of DRL applications in cyber security in Section III. We group these applications into three major categories, including DRL-based security solutions for cyber-physical systems, autonomous intrusion detection techniques, and DRL-based game theory for cyber security. Section IV concludes the paper with extensive discussions and future research directions on DRL for cyber security.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DEEP REINFORCEMENT LEARNING PRELIMINARY</head><p>Different from the other popular branch of ML, i.e., supervised methods learning by examples, RL characterizes an agent by creating its own learning experiences through interacting directly with the environment. RL is described by concepts of state, action, and reward (Fig. <ref type="figure">1</ref>). It is a trial and error approach in which the agent takes action at each time step that causes two changes: current state of the environment is changed to a new state, and the agent receives a reward or penalty from the environment. Given a state, the reward is a function that can tell the agent how good or bad an action is. Based on received rewards, the agent learns to take more good actions and gradually filter out bad actions. Fig. <ref type="figure">1</ref>. Interactions between the agent and its environment in RL, characterized by state, action and reward. Based on the current state s and reward r, the agent will take an optimal action, leading to changes of state and reward. The agent then receives the next state s and reward r from the environment to determine the next action, making an iterative process of agent-environment interactions.</p><p>A popular RL method is Q-learning whose goal is to maximize the discounted cumulative reward based on the Bellman equation <ref type="bibr" target="#b59">[60]</ref>:</p><formula xml:id="formula_0">Q(s t , a t ) = E[r t+1 + γr t+2 + γ 2 r t+3 + ...|s t , a t ] (1)</formula><p>The discount factor γ ∈ [0, 1] manages the importance levels of future rewards. It is applied as a mathematical trick to analyze the learning convergence. In practice, discount is necessary because of partial observability or uncertainty of the stochastic environment.</p><p>Q-learning needs to use a lookup table or Q-table to store expected rewards (Q-values) of actions given a set of states. This requires a large memory when the state and action spaces increase. Real-world problems often involve continuous state or action space, and therefore, Q-learning is inefficient to solve these problems. Fortunately, deep learning has emerged as a powerful tool that is a great complement to traditional RL techniques. Deep learning methods have two typical capabilities, i.e. function approximation and representation learning, which help them to learn a compact low-dimensional representation of raw high-dimensional data effectively <ref type="bibr" target="#b60">[61]</ref>. The combination of deep learning and RL was the research direction that Google DeepMind has initiated and pioneered. They proposed deep Q-network (DQN) with the use of a deep neural network (DNN) to enable Q-learning to deal with highdimensional sensory inputs <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b61">[62]</ref>.</p><p>Using DNNs to approximate the Q-function however is unstable due to the correlations among the sequences of observations and the correlations between the Q-values Q(s, a) and the target values Q(s , a ). Mnih et al. <ref type="bibr" target="#b28">[29]</ref> proposed the use of two novel techniques, i.e., experience replay memory and target network, to address this problem (Fig. <ref type="figure">2</ref>). On the one hand, experience memory stores an extensive list of learning experience tuples (s, a, r, s ), which are obtained from the agent's interactions with the environment. The agent's learning process retrieves these experiences randomly to avoid the correlations of consecutive experiences. On the other hand, the target network is technically a copy of the estimation network, Fig. <ref type="figure">2</ref>. DQN architecture with the loss function described by</p><formula xml:id="formula_1">L(β) = E[(r + γ max a Q(s , a |β ) -Q(s, a|β)) 2 ]</formula><p>where β and β are parameters of the estimation and target deep neural networks respectively. Each action taken by the agent will generate an experience, which consists of the current state s, action a, reward r and next state s . These learning experiences (samples) are stored in the experience replay memory, which are then retrieved randomly for a stable learning process.</p><p>but its parameters are frozen and only updated after a period. For instance, the target network is updated after 10,000 updates of the estimation network, as demonstrated in <ref type="bibr" target="#b28">[29]</ref>. DQN has made a breakthrough as it is the first time an RL agent can provide a human-level performance in playing 49 Atari games by using just raw image pixels of the game board.</p><p>As a value-based method, DQN takes long training time and has limitations in solving problems with continuous action spaces. Value-based methods, in general, evaluate the goodness of an action given a state using the Q-value function. When the number of states or actions is large or infinite, they show inefficiency or even impracticality. Another type of RL, i.e., policy gradient methods, has solved this problem effectively. These methods aim to derive actions directly by learning a policy π(s, a) that is a probability distribution over all possible actions. REINFORCE <ref type="bibr" target="#b63">[64]</ref>, vanilla policy gradient <ref type="bibr" target="#b64">[65]</ref>, trust region policy optimization (TRPO) <ref type="bibr" target="#b65">[66]</ref> and proximal policy optimization (PPO) <ref type="bibr" target="#b66">[67]</ref> are notable policy gradient methods. The gradient estimation, however, often suffers from a large fluctuation <ref type="bibr" target="#b67">[68]</ref>. The combination of value-based and policygradient methods has been developed to aggregate the advantages and eradicate the disadvantages of these two methods. This kind of combination has constituted another type of RL, i.e., actor-critic methods. This structure comprises two components: an actor and a critic that can be both characterized by DNNs. The actor attempts to learn a policy by receiving feedback from the critic. This iterative process helps the actor improve its strategy and converge to an optimal policy. Deep deterministic policy gradient (DDPG) <ref type="bibr" target="#b68">[69]</ref>, distributed distributional DDPG (D4PG) <ref type="bibr" target="#b69">[70]</ref>, asynchronous advantage actor-critic (A3C) <ref type="bibr" target="#b49">[50]</ref> and unsupervised reinforcement and auxiliary learning (UNREAL) <ref type="bibr" target="#b70">[71]</ref> are methods that utilize the actor-critic framework. An illustrative architecture of the popular algorithm A3C is presented in Fig. <ref type="figure" target="#fig_0">3</ref>. A3C's structure consists of a hierarchy of a master learning agent (global) and individual learners (workers). Both master agent and individual learners are modeled by DNNs with each having two outputs: one for the critic and another for the actor. The first output is a scalar value representing the expected reward of a given state V (s) while the second output is a vector of values representing a probability distribution over all possible actions π(s, a).</p><p>The value loss function of the critic is specified by:</p><formula xml:id="formula_2">L 1 = (R -V (s)) 2<label>(2)</label></formula><p>where R = r + γV (s ) is the discounted future reward. Also, the actor is pursuing minimization of the following policy loss function:</p><formula xml:id="formula_3">L 2 = -log(π(a|s)) * A(s) -ϑH(π)<label>(3)</label></formula><p>where A(s) = R -V (s) is the estimated advantage function, and H(π) is the entropy term, which handles the exploration capability of the agent with the hyperparameter ϑ controlling the strength of the entropy regularization. The advantage function A(s) shows how advantageous the agent is when it is in a particular state. The learning process of A3C is asynchronous because each learner interacts with its separate environment and updates the master network independently. This process is iterated, and the master network is the one to use when the learning is finished. Table <ref type="table">I</ref> summarizes comparable features of value-based, policy-gradient, and actor-critic methods, and their typical example algorithms. Valued-based methods are more sample efficient than policy-gradient methods because they are able to exploit data from other sources such as experts <ref type="bibr" target="#b71">[72]</ref>. In DRL, a value function or a policy function is normally approximated by a universal function approximator such as a (deep) neural network, which can take either discrete or continuous states as inputs. Therefore, modelling state spaces is more straightforward than dealing with action spaces in DRL. Value-based methods are suitable for problems with discrete action spaces as they evaluate every action explicitly and choose an action at each time step based on these evaluations. On the other hand, policy-gradient and actor-critic methods are more suitable for continuous action spaces because they describe the policy (a mapping between states and actions) as a probability distribution over actions. The continuity characteristic is the main difference between discrete and continuous action spaces. In a discrete action space, actions are characterized as a mutually exclusive set of options while in a continuous action space, an action has a value from a certain range or boundary <ref type="bibr" target="#b72">[73]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DRL IN CYBER SECURITY: A SURVEY</head><p>A large number of applications of RL to various aspects of cyber security have been proposed in the literature, ranging from data privacy to critical infrastructure protection. However, drawbacks of traditional RL have restricted its capability in solving complex and large-scale cyber security problems. The increasing number of connected IoT devices in recent years have led to a significant increase in the number of cyber</p><p>TABLE I SUMMARY OF FEATURES OF DRL TYPES AND THEIR NOTABLE METHODS DRL types Value-based Policy-gradient Actor-critic Features -Compute value of action given a state Q(s, a).</p><p>-No learned explicit policy.</p><p>-Sample efficient <ref type="bibr" target="#b71">[72]</ref>.</p><p>-No value function is needed.</p><p>-Explicit policy is constructed.</p><p>-Sample inefficient <ref type="bibr" target="#b71">[72]</ref>.</p><p>-Actor produces policy π(s, a).</p><p>-Critic evaluates action by V (s).</p><p>-Often perform better than valuebased or policy-gradient methods. Typical methods -DQN <ref type="bibr" target="#b28">[29]</ref> -Double DQN <ref type="bibr" target="#b46">[47]</ref> -Dueling Q-network <ref type="bibr" target="#b47">[48]</ref> -Prioritized Experience Replay DQN <ref type="bibr" target="#b62">[63]</ref> -REINFORCE <ref type="bibr" target="#b63">[64]</ref> -Vanilla Policy Gradient <ref type="bibr" target="#b64">[65]</ref> -TRPO <ref type="bibr" target="#b65">[66]</ref> -PPO <ref type="bibr" target="#b66">[67]</ref> -DDPG <ref type="bibr" target="#b68">[69]</ref> -D4PG <ref type="bibr" target="#b69">[70]</ref> -A3C <ref type="bibr" target="#b49">[50]</ref> -UNREAL <ref type="bibr" target="#b70">[71]</ref> Applications Suitable for problems with discrete action spaces, e.g., classic control tasks: Acrobot, CartPole, and MountainCar as described and implemented in the popular OpenAI Gym toolkit <ref type="bibr" target="#b73">[74]</ref>.</p><p>More suitable for problems with continuous action spaces, e.g., classic control tasks described and implemented in the OpenAI Gym toolkit: MountainCarContinuous and Pendulum <ref type="bibr" target="#b73">[74]</ref> or BipedalWalker and CarRacing problems <ref type="bibr" target="#b74">[75]</ref>.</p><p>attack instances as well as their complexity. The emergence of deep learning and its integration with RL have created a class of DRL methods that are able to detect and fight against sophisticated types of cyber attacks, such as falsified data injection to cyber-physical systems <ref type="bibr" target="#b85">[86]</ref>, deception attack to autonomous systems <ref type="bibr" target="#b92">[93]</ref>, distributed denial-of-service attacks <ref type="bibr" target="#b113">[114]</ref>, intrusions to host computers or networks <ref type="bibr" target="#b124">[125]</ref>, jamming <ref type="bibr" target="#b141">[142]</ref>, spoofing <ref type="bibr" target="#b156">[157]</ref>, malware <ref type="bibr" target="#b160">[161]</ref>, attacks in adversarial networking environments <ref type="bibr" target="#b167">[168]</ref>, and so on. This section provides a comprehensive survey of state-of-the-art DRLpowered solutions for cyber security, ranging from defense methods for cyber-physical systems to autonomous intrusion detection approaches, and game theory-based solutions. The structure of the survey is presented in Fig. <ref type="figure" target="#fig_1">4</ref>. We limit the survey to existing applications of DRL to cyber security. There are other topics in cyber security where DRL has not been applied to and they are therefore discussed in Section IV (Discussions and Future Research Directions). Those potential topics include a multi-agent DRL approach to cyber security, combining host-based and network-based intrusion detection systems, model-based DRL and combining model-free and model-based DRL methods for cyber security applications, investigating methods that can deal with continuous action spaces in cyber environments, offensive AI, deepfakes, machine learning poisoning, adversarial machine learning, human-machine teaming within a human-on-the-loop architecture, bit-and-piece distributed denial-of-service attacks as well as potential attacks by quantum physics-based powerful computers to crack encryption algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. DRL-based Security Methods for Cyber-Physical Systems</head><p>Investigations of defense methods for cyber-physical systems (CPS) against cyber attacks have received considerable attention and interests from the cyber security research community. CPS is a mechanism controlled by computer-based algorithms facilitated by internet integration. This mechanism provides efficient management of distributed physical systems via the shared network. With the rapid development of the Internet and control technologies, CPSs have been used extensively in many areas including manufacturing <ref type="bibr" target="#b75">[76]</ref>, health monitoring <ref type="bibr" target="#b76">[77]</ref>, <ref type="bibr" target="#b77">[78]</ref>, smart grid <ref type="bibr" target="#b78">[79]</ref>- <ref type="bibr" target="#b80">[81]</ref>, and transportation <ref type="bibr" target="#b81">[82]</ref>, <ref type="bibr" target="#b82">[83]</ref>. Being exposed widely to the Internet, these systems are increasingly vulnerable to cyber attacks <ref type="bibr" target="#b83">[84]</ref>. In 2015, hackers attacked the control system of a steel mill in Germany by obtaining login credentials via the use of phishing emails. This attack caused a partial plant shutdown and resulted in damage of millions of dollars. Likewise, there was a costly cyber attack to a power grid in Ukraine in late December 2015 that disrupted electricity supply to a few hundred thousand end consumers <ref type="bibr" target="#b84">[85]</ref>.</p><p>In an effort to study cyber attacks on CPS, Feng et al. <ref type="bibr" target="#b84">[85]</ref> characterized the cyber state dynamics by a mathematical model:</p><formula xml:id="formula_4">ẋ(t) = f (t, x, u, w; θ(t, a, d)); x(t 0 ) = x 0 (4)</formula><p>where x, u and w represent the physical state, control inputs and disturbances correspondingly (see Fig. <ref type="figure">5</ref>). In addition, θ(t, a, d) describes cyber state at time t with a and d referring to cyber attack and defense respectively.</p><p>The CPS defense problem is then modeled as a two-player zero-sum game by which utilities of players are summed up to zero at each time step. The defender is represented by an actor-critic DRL algorithm. Simulation results demonstrate that the proposed method in <ref type="bibr" target="#b84">[85]</ref> can learn an optimal strategy to timely and accurately defend the CPS from unknown cyber attacks.</p><p>Applications of CPS in critical safety domains such as autonomous automotive, chemical process, automatic pilot avionics, and smart grid require a certain correctness level. Akazaki et al. <ref type="bibr" target="#b85">[86]</ref> proposed the use of DRL, i.e., double DQN and A3C algorithms, to find falsified inputs (counterexamples) for CPS models. This allows for effective yet automatic detection of CPS defects. Due to the infinite state Fig. <ref type="figure">5</ref>. The dynamics of attack and defense in a cyber-physical system. The physical layer is often uncertain with disturbances w while cyber attack a directly affects the cyber layer where a defense strategy d needs to be implemented. The dynamics of attack-defense characterized by θ(t, a, d) is injected into the conventional physical system to develop a cyber-physical co-modelling as presented in Eq. ( <ref type="formula">4</ref>). space of CPS models, conventional methods such as simulated annealing <ref type="bibr" target="#b86">[87]</ref> and cross entropy <ref type="bibr" target="#b87">[88]</ref> were found inefficient. Experimental results show the superiority of the use of DRL algorithms against those methods in terms of the smaller number of simulation runs. This leads to a more practical detection process for CPS models' defects despite the great complexity of CPS's software and physical systems.</p><p>Autonomous vehicles (AVs) operating in the future smart cities require a robust processing unit of intra-vehicle sensors, including camera, radar, roadside smart sensors, and inter-vehicle beaconing. Such reliance is vulnerable to cyberphysical attacks aiming to get control of AVs by manipulating the sensory data and affecting the reliability of the system, e.g., increasing accident risks or reducing the vehicular flow. Ferdowsi et al. <ref type="bibr" target="#b88">[89]</ref> examined the scenarios where the attackers manage to interject faulty data to the AV's sensor readings while the AV (the defender) needs to deal with that problem to control AV robustly. Specifically, the car following model <ref type="bibr" target="#b89">[90]</ref> is considered in which the focus is on autonomous control of a car that follows closely another car. The defender aims to learn the leading vehicle's speed based on sensor readings. The attacker's objective is to mislead the following vehicle to a deviation from the optimal safe spacing. The interactions between the attacker and defender are characterized by a game-theoretic problem. The interactive game structure and its DRL solution are diagrammed in Fig. <ref type="figure">6</ref>. Instead of directly deriving a solution based on the mixed-strategy Nash equilibrium analytics, the authors proposed the use of DRL to solve this dynamic game. Long short term memory (LSTM) <ref type="bibr" target="#b90">[91]</ref> is used to approximate the Q-function for both defending and attacking agents as it can capture the temporal dynamics of the environment.</p><p>Likewise, Rasheed et al. <ref type="bibr" target="#b91">[92]</ref> introduced an adversarial DRL method that integrates LSTM and generative adversarial network (GAN) model to cope with data infusion attacks in autonomous vehicles equipped with 5G communication links. The adversary attempts to inject faulty data to impact safe distance spacing between autonomous vehicles while the autonomous vehicles manage to minimize this deviation. LSTM is used as a generator while a convolutional neural network (CNN) is used as a discriminator to resemble a GAN structure, which is able to capture previous temporal actions of the autonomous vehicle and attacker as well as previous distance deviations. A DRL algorithm is proposed based on these observations to select optimal actions (suitable velocity) for the autonomous vehicle to avoid collisions and accidents.</p><p>Autonomous systems can be vulnerable to inefficiency from various sources such as noises in communication channels, sensor failures, errors in sensor measurement readings, packet errors, and especially cyber attacks. Deception attack to autonomous systems is widespread as it is initiated by an adversary whose effort is to inject noises to the communication channels between sensors and the command center. This kind of attack leads to corrupted information being sent to the command center and eventually degrades the system performance. Gupta and Yang <ref type="bibr" target="#b92">[93]</ref> studied the ways to increase the robustness of autonomous systems by allowing the system to learn using adversarial examples. The problem is formulated as a zero-sum game with the players to be the command center (observer) and the adversary. The inverted pendulum problem from Roboschool <ref type="bibr" target="#b66">[67]</ref> is used as a simulation environment. The TRPO algorithm is employed to design an observer that can reliably detect adversarial attacks in terms of measurement corruption and automatically mitigate their effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DRL-based Intrusion Detection Systems</head><p>To detect intrusions, security experts conventionally need to observe and examine audit data, e.g., application traces, network traffic flow, and user command data, to differentiate between normal and abnormal behaviors. However, the volume of audit data surges rapidly when the network size is enlarged. This makes manual detection difficult or even impossible. An intrusion detection system (IDS) is a software or hardware platform installed on host computers or network equipment to detect and report to the administrator abnormal or malicious activities by analysing the audit data. An intrusion detection and prevention system may be able to take appropriate actions immediately to reduce impacts of the malevolent activities.</p><p>Depending on different types of audit data, IDSs are grouped into two categories: host-based or network-based IDS. Host-based IDS typically observes and analyses the host computer's log files or settings to discover anomalous behaviors. Network-based IDS relies on a sniffer to collect transmitting packets in the network and examines the traffic Fig. <ref type="figure">6</ref>. The architecture of the adversarial DRL algorithm for robust AV control. A deep neural network (DNN) consisting of a long short term memory (LSTM), a fully connected layer (FCL), and regression is used to learn longterm dependencies within a large data sets, which contain the outcomes of the players' past interactions. The DNN can approximate the Q functions to find optimal actions for players, i.e., AV (defender) and especially attacker, who seeks to inject faulty data to AV sensor readings.</p><p>data for intrusion detection. Host-based systems normally lack cross-platform support and implementing them requires knowledge of the host operating systems and configurations. Network-based systems aim to monitor traffic over specific network segments, and they are independent of the operating systems and more portable than host-based systems. Implementing network-based systems is thus easier and they offer more monitoring power than host-based systems. However, a network-based IDS may have difficulty in handling heavy traffic and high-speed networks because it must examine every packet passing through its network segment.</p><p>Regardless of the IDS type, two common detection methods are used: signature-based and anomaly-based detection. Signature detection involves the storage of patterns of known attacks and comparing characteristics of possible attacks to those in the database. Anomaly detection observes the normal behaviors of the system and alerts the administrator if any activities are found deviated from normality, for instance, the unexpected increase of traffic rate, i.e., number of IP packets per second. Machine learning techniques, including unsupervised clustering and supervised classification methods, have been used widely to build adaptive IDSs <ref type="bibr" target="#b93">[94]</ref>- <ref type="bibr" target="#b97">[98]</ref>. These methods, e.g., neural networks <ref type="bibr" target="#b98">[99]</ref>, k-nearest neighbors <ref type="bibr" target="#b98">[99]</ref>, <ref type="bibr" target="#b99">[100]</ref>, support vector machine (SVM) <ref type="bibr" target="#b98">[99]</ref>, <ref type="bibr" target="#b100">[101]</ref>, random forest <ref type="bibr" target="#b101">[102]</ref> and recently deep learning <ref type="bibr" target="#b102">[103]</ref>- <ref type="bibr" target="#b104">[105]</ref>, however normally rely on fixed features of existing cyber attacks so that they are deficient in detecting new or deformed attacks. The lack of prompt responses to dynamic intrusions also leads to ineffective solutions produced by unsupervised or supervised techniques. In this regard, RL methods have been demonstrated effectively in various IDS applications <ref type="bibr" target="#b105">[106]</ref>. The following subsections review the use of DRL methods in both host-based and network-based IDSs.</p><p>1) Host-based IDS: As the volume of audit data and complexity of intrusion behaviors increase, adaptive intrusion detection models demonstrate limited effectiveness because they can only handle temporally isolated labeled or unlabeled data. In practice, many complex intrusions comprise temporal sequences of dynamic behaviors. Xu and Xie <ref type="bibr" target="#b106">[107]</ref> proposed an RL-based IDS that can handle this problem. System call trace data are fed into a Markov reward process whose state value can be used to detect abnormal temporal behaviors of host processes. The intrusion detection problem is thus converted to a state value prediction task of the Markov chains. The linear temporal difference (TD) RL algorithm <ref type="bibr" target="#b107">[108]</ref> is used as the state value prediction model where its outcomes are compared with a predetermined threshold to distinguish normal traces and attack traces. Instead of using the errors between real values and estimated ones, TD learning algorithm uses the differences between successive approximations to update the state value function. Experimental results obtained from using system call trace data show the dominance of the proposed RL-based IDS in terms of higher accuracy and lower computational costs compared to SVM, hidden Markov model, and other machine learning or data mining methods. The proposed method based on the linear basis functions, however, has a shortcoming when sequential intrusion behaviors are highly nonlinear. Therefore, a kernel-based RL approach using least-squares TD <ref type="bibr" target="#b108">[109]</ref> was suggested for intrusion detection in <ref type="bibr" target="#b109">[110]</ref>, <ref type="bibr" target="#b110">[111]</ref>. Relying on the kernel methods, the generalization capability of TD RL is enhanced, especially in highdimensional and nonlinear feature spaces. The kernel leastsquares TD algorithm is, therefore, able to predict anomaly probabilities accurately, which contributes to improving the detection performance of IDS, especially when dealing with multi-stage cyber attacks.</p><p>2) Network-based IDS: Deokar and Hazarnis <ref type="bibr" target="#b111">[112]</ref> pointed out the drawbacks of both anomaly-based and signature-based detection methods. On the one hand, anomaly detection has a high false alarm rate because it may categorize activities which users rarely perform as an anomaly. On the other hand, signature detection cannot discover new types of attacks as it uses a database of patterns of well-known attacks. The authors, therefore, proposed an IDS that can identify known and unknown attacks effectively by combining features of both anomaly and signature detection through the use of log files. The proposed IDS is based on a collaboration of RL methods, association rule learning, and log correlation techniques. RL gives a reward (or penalty) to the system when it selects log files that contain (or do not contain) anomalies or any signs of attack. This procedure enables the system to choose more appropriate log files in searching for traces of attack.</p><p>One of the most difficult challenges in the current Internet is dealing with the distributed denial-of-service (DDoS) threat, which is a DoS attack but has the distributed nature, occurring with a large traffic volume, and compromising a large number of hosts. Malialis and Kudenko <ref type="bibr" target="#b112">[113]</ref>, <ref type="bibr" target="#b113">[114]</ref> initially introduced the multiagent router throttling method based on the SARSA algorithm <ref type="bibr" target="#b114">[115]</ref> to address the DDoS attacks by learning multiple agents to rate-limit or throttle traffic towards a victim server. That method, however, has a limited capability in terms of scalability. They therefore further proposed the coordinated team learning design to the original multiagent router throttling based on the divide-and-conquer paradigm to eliminate the mentioned drawback. The proposed approach integrates three mechanisms, namely, task decomposition, hierarchical team-based communication, and team rewards, involving multiple defensive nodes across different locations to coordinately stop or reduce the flood of DDoS attacks. A network emulator is developed based on the work of Yau et al. <ref type="bibr" target="#b115">[116]</ref> to evaluate throttling approaches. Simulation results show that the resilience and adaptability of the proposed method are superior to its competing methods, i.e., baseline router throttling and additive-increase/multiplicative-decrease throttling algorithms <ref type="bibr" target="#b115">[116]</ref>, in various scenarios with different attack dynamics. The scalability of the proposed method is successfully experimented with up to 100 RL agents, which has a great potential to be deployed in a large internet service provider network.</p><p>Alternatively, Bhosale et al. <ref type="bibr" target="#b116">[117]</ref> proposed a multiagent intelligent system <ref type="bibr" target="#b117">[118]</ref> using RL and influence diagram <ref type="bibr" target="#b118">[119]</ref> to enable quick responses against the complex attacks. Each agent learns its policy based on local database and information received from other agents, i.e., decisions and events. Shamshirband et al. <ref type="bibr" target="#b119">[120]</ref>, on the other hand, introduced an intrusion detection and prevention system for wireless sensor Fig. <ref type="figure">7</ref>. Two-phase intrusion detection and prevention system based on a game theory approach and fuzzy Q-learning. In Phase 1, the sink node uses fuzzy Q-learning to detect anomalies caused by the attacker to victim nodes. The malicious information is preprocessed and checked against a threshold by the sink node before passing to Phase 2 where the base station also employs fuzzy Q-learning to select optimal defense actions. networks (WSNs) based on a game theory approach and employed a fuzzy Q-learning algorithm <ref type="bibr" target="#b120">[121]</ref>, <ref type="bibr" target="#b121">[122]</ref> to obtain optimal policies for the players. Sink nodes, a base station, and an attacker constitute a three-player game where sink nodes and base station are coordinated to derive a defense strategy against the DDoS attacks, particularly in the application layer. The IDS detects future attacks based on the fuzzy Q-learning algorithm that takes part in two phases: detection and defense (Fig. <ref type="figure">7</ref>). The game commences when the attacker sends an overwhelming volume of flooding packets beyond a specific threshold as a DDoS attack to a victim node in the WSN. Using the low energy adaptive clustering hierarchy (LEACH), which is a prominent WSN protocol <ref type="bibr" target="#b122">[123]</ref>, the performance of the proposed method is evaluated and compared with that of existing soft computing methods. The results show the efficacy and viability of the proposed method in terms of detection accuracy, energy consumption and network lifetime.</p><p>In another approach, Caminero et al. <ref type="bibr" target="#b123">[124]</ref> proposed a model, namely adversarial environment using RL, to incorporate the RL theory in implementing a classifier for network intrusion detection. A simulated environment is created where random samples drawn from a labelled network intrusion dataset are treated as RL states. The adversarial strategy is employed to deal with unbalanced datasets as it helps to avoid training bias via an oversampling mechanism and thus decrease classification errors for under-represented classes. Likewise, a study in <ref type="bibr" target="#b124">[125]</ref> applied DRL methods such as DQN, double DQN (DDQN), policy gradient and actor-critic models for network intrusion detection. With several adjustments and adaptations, DRL algorithms can be used as a supervised approach to classifying labelled intrusion data. DRL policy network is simple and fast, which is suitable for online learning and rapid responses in modern data networks with evolving environments. Results obtained on two intrusion detection datasets show DDQN is the best algorithm among the four employed DRL algorithms. DDQN's performance is equivalent and even better than many traditional machine learning methods in some cases. Recently, Saeed et al. <ref type="bibr" target="#b125">[126]</ref> examined the existing multiagent IDS architectures, including several approaches that utilized RL algorithms. The adaptation capability of RL methods can help IDS to respond effectively to changes in the environments. However, optimal solution is not guaranteed because convergence of a multiagent system is hard to obtain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. DRL-based Game Theory for Cyber Security</head><p>Traditional cyber security methods such as firewall, antivirus software, or intrusion detection are normally passive, unilateral, and lagging behind dynamic attacks. Cyberspace involves various cyber components, and thus, reliable cyber security requires the consideration of interactions among these components. Specifically, the security policy applied to a component has a certain impact on the decisions taken by other components. Therefore, the decision space increases considerably, with many what-if scenarios when the system is large. Game theory has been demonstrated effectively in solving such large-scale problems because it can examine many scenarios to derive the best policy for each player <ref type="bibr" target="#b126">[127]</ref>- <ref type="bibr" target="#b130">[131]</ref>. The utility or payoff of a game player depends not only on its actions but also on other players' activities. In other words, the efficacy of cyber defending strategies must take into account the attacker's strategies and other network users' behaviors. Game theory can model the conflict and cooperation between intelligent decision makers, resembling activities of cyber security problems, which involve attackers and defenders. This resemblance has enabled game theory to mathematically describe and analyze the complex behaviors of multiple competitive mechanisms. In the following, we present game theoretic models involving multiple DRL agents that characterize cyber security problems in different attacking scenarios, including jamming, spoofing, malware, and attacks in adversarial environments.</p><p>1) Jamming attacks: Jamming attacks can be considered as a special case of DoS attacks, which are defined as any event that diminishes or eradicates a network's capacity to execute its expected function <ref type="bibr" target="#b131">[132]</ref>- <ref type="bibr" target="#b133">[134]</ref>. Jamming is a serious attack in networking and has attracted a great interest of researchers who used machine learning or especially RL to address this problem, e.g., <ref type="bibr" target="#b134">[135]</ref>- <ref type="bibr" target="#b140">[141]</ref>. The recent development of deep learning has facilitated the use of DRL for jamming handling or mitigation. Xiao et al. <ref type="bibr" target="#b141">[142]</ref> studied security challenges of the MEC systems and proposed an RL-based solution to provide secure offloading to the edge nodes against jamming attacks. MEC is a technique that allows cloud computing functions to take place at the edge nodes of a cellular network or generally of any network. This technology helps to decrease network traffic, reduce overhead and latency when users request to access contents that have been cached in the edges closer to the cellular customer. MEC systems, however, are vulnerable to cyber attacks because they are physically located closer to users and attackers with less secure protocols compared to cloud servers or database center. In <ref type="bibr" target="#b141">[142]</ref>, the RL methodology is used to select the defense levels and important Fig. <ref type="figure">8</ref>. Secure offloading method in MEC based on DQN with hotbooting technique. The DQN agent' actions are to find optimal parameters such as offloading rate, power, and channel for the mobile device to offload the traces to the edge node accordingly. The attackers may deploy jamming, spoofing, DoS, or smart attacks to disrupt this process. By interacting with the edge caching systems, the agent can evaluate the reward of the previous action and obtain new state, enabling it to select the next optimal action. parameters such as offloading rate and time, transmit channel and power. As the network state space is large, the authors proposed the use of DQN to handle high-dimensional data, as illustrated in Fig. <ref type="figure">8</ref>. DQN uses a CNN to approximate the Q-function that requires high computational complexity and memory. To mitigate this disadvantage a transfer learning method named hotbooting technique is used. The hotbooting method helps to initialize weights of CNN more efficiently by using experiences that have been learned in similar circumstances. This reduces the learning time by avoiding random explorations at the start of each episode. Simulation results demonstrate that the proposed method is effective in terms of enhancing the security and user privacy of MEC systems and it can protect the systems in confronting with different types of smart attacks with low overhead.</p><p>On the other hand, Aref et al. <ref type="bibr" target="#b142">[143]</ref> introduced a multiagent RL method to deal with anti-jamming communications in wideband autonomous cognitive radios (WACRs). WACRs are advanced radios that can sense the states of the radio frequency spectrum and network, and autonomously optimize its operating mode corresponding to the perceived states. Cognitive communication protocols, however, may struggle when there are unintentional interferences or malicious users who attempt to interrupt reliable communications by deliberate jamming. Each radio's effort is to occupy the available common wideband spectrum as much as possible and avoid sweeping signal of a jammer that affects the entire spectrum band. The multiagent RL approach proposed in <ref type="bibr" target="#b142">[143]</ref> learns an optimal policy for each radio to select appropriate sub-band, aiming to avoid jamming signals and interruptions from other radios. Comparative studies show the significant dominance of the proposed method against a random policy. A drawback of the proposed method is the assumption that the jammer uses a fixed strategy in responding to the WACRs strategies, although the jammer may be able to perform adaptive jamming with the cognitive radio technology. In <ref type="bibr" target="#b143">[144]</ref>, when the current spectrum sub-band is interfered by a jammer, Qlearning is used to optimally select a new sub-band that allows uninterrupted transmission as long as possible. The reward structure of the Q-learning agent is defined as the amount of time that the jammer or interferer takes to interfere with the WACR transmission. Experimental results using the hardwarein-the-loop prototype simulation show that the agent can detect the jamming patterns and successfully learns an optimal subband selection policy for jamming avoidance. The obvious drawback of this method is the use of Q-table with a limited number of environment states.</p><p>The access right to spectrum (or more generally resources) is the main difference between cognitive radio networks (CRNs) and traditional wireless technologies. RL in general or Q-learning has been investigated to produce optimal policy for cognitive radio nodes to interact with their radio-frequency environment <ref type="bibr" target="#b144">[145]</ref>. Attar et al. <ref type="bibr" target="#b145">[146]</ref> examined RL solutions against attacks on both CRN architectures, i.e., infrastructurebased, e.g., the IEEE 802.22 standard, and infrastructure-less, e.g., ad hoc CRN. The adversaries may attempt to manipulate the spectrum sensing process and cause the main sources of security threats in infrastructure-less CRNs. The external adversary node is not part of the CRN, but such attackers can affect the operation of an ad hoc CRN via jamming attacks. In an infrastructure-based CRN, an exogenous attacker can mount incumbent emulation or perform sensorjamming attacks. The attacker can increase the local falsealarm probability to affect the decision of the IEEE 802.22 base station about the availability of a given band. A jamming attack can have both short-term and long-term effects. Wang et al. <ref type="bibr" target="#b146">[147]</ref> developed a game-theoretic framework to battle against jamming in CRNs where each radio observes the status and quality of available channels and the strategy of jammers to make decisions accordingly. The CRN can learn optimal channel utilization strategy using minimax-Q learning policy <ref type="bibr" target="#b147">[148]</ref>, solving the problems of how many channels to use for data and to control packets along with the channel switching strategy. The performance of minimax-Q learning represented via spectrum-efficient throughput is superior to the myopic learning method, which gives high priority to the immediate payoff and ignores the environment dynamics as well as the attackers' cognitive capability.</p><p>In CRNs, secondary users (SUs) are obliged to avoid disruptions to communications of primary users (PUs) and can only gain access to the licensed spectrum when it is not occupied by PUs. Jamming attacks are emergent in CRNs due to the opportunistic access of SUs as well as the appearance of smart jammers, which can detect the transmission strategy of SUs. Xiao et al. <ref type="bibr" target="#b148">[149]</ref> studied the scenarios where a smart jammer aims to disrupt the SUs rather than PUs. The SUs and jammer, therefore, must sense the channel to check the presence of PUs before making their decisions. The constructed scenarios consist of a secondary source node supported by relay nodes to transmit data packets to secondary receiving nodes. The smart jammer can learn quickly the frequency and transmission power of SUs while SUs do not have full knowledge of the underlying dynamic environment. The interactions between SUs and jammer are modeled as a cooperative transmission power control game, and the optimal strategy for SUs is derived based on the Stackelberg equilibrium <ref type="bibr" target="#b149">[150]</ref>. The aim of SU players is to select appropriate transmission powers to efficiently send data messages in the presence of jamming attacks. The jammer's utility gain is the SUs' loss and vice versa. RL methods, i.e., Q-learning <ref type="bibr" target="#b59">[60]</ref> and WoLF-PHC <ref type="bibr" target="#b150">[151]</ref>, are used to model SUs as intelligent agents for coping with the smart jammer. WoLF-PHC stands for the combination of Win or Learn Fast algorithm and policy hill-climbing method. It uses a varying learning rate to foster convergence to the game equilibrium by adjusting the learning speed <ref type="bibr" target="#b150">[151]</ref>. Simulation results show the improvement in the anti-jamming performance of the proposed method in terms of the signal to interference plus noise ratio (SINR). The optimal strategy achieved from the Stackelberg game can minimize the damage created by the jammer in the worst-case scenario.</p><p>Recently, Han et al. <ref type="bibr" target="#b151">[152]</ref> introduced an anti-jamming system for CRNs using the DQN algorithm based on a frequencyspatial anti-jamming communication game. The game simulates an environment of numerous jammers that inject jamming signals to disturb the ongoing transmissions of SUs. The SU should not interfere with the communications of PUs and must defeat smart jammers. This communication system is two-dimensional that utilizes both frequency hopping and user mobility. The RL state is the radio environment consisting of PUs, SUs, jammers, and serving base stations/access points. The DQN is used to derive an optimal frequency hopping policy that determines whether the SU should leave an area of heavy jamming or choose a channel to send signals.</p><p>Experimental results show the superiority of the DQN-based method against the Q-learning based strategy in terms of faster convergence rate, increased SINR, lower cost of defense, and improved utility of the SU. DQN with the core component CNN helps to speed the learning process of the system, which has a large number of frequency channels, compared with the benchmark Q-learning method.</p><p>To improve the work of Han et al. <ref type="bibr" target="#b151">[152]</ref>, Liu et al. <ref type="bibr" target="#b152">[153]</ref> also proposed an anti-jamming communication system using a DRL method but having different and more extensive contributions. Specifically, Liu et al. <ref type="bibr" target="#b152">[153]</ref> used the raw spectrum information with temporal features, known as spectrum waterfall <ref type="bibr" target="#b153">[154]</ref> to characterize the environment state rather than using the SINR and PU occupancy as in <ref type="bibr" target="#b151">[152]</ref>. Because of this, Liu et al.'s model does not necessitate prior knowledge about the jamming patterns and parameters of the jammer but rather uses the local observation data. This prevents the model from the loss of information and facilitates its adaptability to a dynamic environment. Furthermore, Liu et al.'s work does not assume that the jammer needs to take the same channel-slot transmission structure with the users as in <ref type="bibr" target="#b151">[152]</ref>. The recursive CNN is utilized to deal with a complex infinite environment state represented by spectrum waterfall, which has a recursion characteristic. The model is tested using several jamming scenarios, which include the sweeping jamming, comb jamming, dynamic jamming, and intelligent comb jamming. A disadvantage of both Han et al. and Liu et al.'s methods is that they can only derive an optimal policy for one user, which inspires a future research direction focusing on multiple users' scenarios.</p><p>2) Spoofing attacks: Spoofing attacks are popular in wireless networks where the attacker claims to be another node using the faked identity such as media access control to gain access to the network illegitimately. This illegal penetration may lead to man-in-the-middle, or DoS attacks <ref type="bibr" target="#b154">[155]</ref>. Xiao et al. <ref type="bibr" target="#b155">[156]</ref>, <ref type="bibr" target="#b156">[157]</ref> modeled the interactions between the legitimate receiver and spoofers as a zero-sum authentication game and utilized Q-learning and Dyna-Q <ref type="bibr" target="#b157">[158]</ref> algorithms to address the spoofing detection problem. The utility of receiver or spoofer is computed based on the Bayesian risk, which is the expected payoff in the spoofing detection. The receiver aims to select the optimal test threshold in PHY-layer spoofing detection while the spoofer needs to select an optimal attacking frequency. To prevent collisions, spoofers are cooperative to attack the receiver. Simulation and experimental results show the improved performance of the proposed methods against the benchmark method with a fixed test threshold. A disadvantage of the proposed approaches is that both action and state spaces are quantized into discrete levels, bounded within a specified interval, which may lead to locally optimal solutions.</p><p>3) Malware attacks: One of the most challenging malwares of mobile devices is the zero-day attacks, which exploit publicly unknown security vulnerabilities, and until they are contained or mitigated, hackers might have already caused adverse effects on computer programs, data or networks <ref type="bibr" target="#b158">[159]</ref>, <ref type="bibr" target="#b159">[160]</ref>. To avoid such attacks, the traces or log data produced by the applications need to be processed in real time. With limited computational power, battery life and radio bandwidth, mobile devices often offload specific malware detection tasks to security servers at the cloud for processing. The security server with powerful computational resources and more updated malware database can process the tasks quicker, more accurately, and then send a detection report back to mobile devices with less delay. The offloading process is, therefore, a key factor affecting the cloud-based malware detection performance. For example, if too many tasks are offloaded to the cloud server, there would be a radio network congestion that can lead to long detection delay. Wan et al. <ref type="bibr" target="#b160">[161]</ref> enhanced the mobile offloading performance by improving the previously proposed game model in <ref type="bibr" target="#b161">[162]</ref>. The Q-learning approach used in <ref type="bibr" target="#b161">[162]</ref> to select optimal offloading rate suffers the curse of highdimensionality when the network size is increased, or a large number of feasible offloading rates is available for selection. Wan et al. <ref type="bibr" target="#b160">[161]</ref> thus advocated the use of hotbooting Qlearning and DQN, and showed the performance improvement in terms of malware detection accuracy and speed compared to the standard Q-learning. The cloud-based malware detection approach using DQN for selecting the optimal offloading rate is illustrated in Fig. <ref type="figure">9</ref>.</p><p>4) Attacks in adversarial environments: Traditional networks facilitate the direct communications between client application and server where each network has its switch control that makes the network reconfiguration task time-consuming and inefficient. This method is also disadvantageous because the requested data may need to be retrieved from more than one database involving multiple servers. Software-defined network is a next-generation networking technology as it can reconfigure the network adaptively. With the control being programmable with a global view of the network architecture, SDN can manage and optimize network resources effectively. RL has been demonstrated broadly in the literature as a robust Fig. <ref type="figure">9</ref>. Cloud-based malware detection using DQN where the stochastic gradient descent (SGD) method is used to update weights of the CNN. Malicious detection is performed in the cloud server with more powerful computational resources than mobile devices. The DQN agent helps to select optimal task offloading rates for mobile devices to avoid network congestion and detection delay. By observing the network status and evaluating utility based on malware detection report from the server, the agent can formulate states and rewards, which are used to generate a sequence of optimal actions, i.e., dynamic offloading rates. method for SDN controlling, e.g., <ref type="bibr" target="#b162">[163]</ref>- <ref type="bibr" target="#b166">[167]</ref>.</p><p>Although RL's success in SDN controlling is abundant, the attacker may be able to falsify the defender's training process if it is aware of the network control algorithm in an adversarial environment. To deal with this problem, Han et al. <ref type="bibr" target="#b167">[168]</ref> proposed the use of adversarial RL to build an autonomous defense system for SDN. The attacker selects important nodes in the network to compromise, for example, nodes in the backbone network or the target subnet. By propagating through the network, the attacker attempts to eventually compromise the critical server while the defender prevents the server from being compromised and preserve as many unaffected nodes as possible. To achieve those goals, the RL defender takes four possible actions, consisting of "isolating", "patching", "reconnecting" and "migrating". Two types of DRL agents are trained to model defenders, i.e., double DQN and A3C, to select appropriate actions given different network states. The reward is characterized based on the status of the critical server, the number of preserved nodes, migration costs, and the validity of the actions taken. That study considered the scenarios where attackers can penetrate the learning process of RL defender by flipping reward signs or manipulating states. These causative attacks poison the defender's training process and cause it to perform sub-optimal actions. The adversarial training approach is applied to reduce the impact of poisoning attacks with its eminent performance demonstrated via several experiments using the popular network emulator Mininet <ref type="bibr" target="#b168">[169]</ref>.</p><p>In an adversarial environment, the defender may not know the private details of the attacker such as the type of attack, attacking target, frequency, and location. Therefore, the defender, for example, may allocate substantial resources to protect an asset that is not a target of the attacker. The defender needs to dynamically reconfigure defense strategies to increase the complexity and cost for the intruder. Zhu et al. <ref type="bibr" target="#b169">[170]</ref> introduced a model where the defender and attacker can repeatedly change the defense and attack strategies. The defender has no prior knowledge about the attacker, such Fig. <ref type="figure">10</ref>. The defender and attacker interact via the intrusion detection system (IDS) in an adversarial environment, involving defense and attack cycles. Using these two cycles, a defender and an attacker can repeatedly change their defense and attack strategies. This model can be used to study defense strategies for different classes of attacks such as buffer over-read attacks <ref type="bibr" target="#b170">[171]</ref> and code reuse attacks <ref type="bibr" target="#b171">[172]</ref>.</p><p>as launched attacks and attacking policies. However, it is aware of the attacker classes and can access to the system utilities, which are jointly contributed by the defense and attack activities. Two interactive RL methods are proposed for cyber defenses in <ref type="bibr" target="#b169">[170]</ref>, namely adaptive RL and robust RL. The adaptive RL handles attacks that have a diminishing exploration rate (non-persistent attacker) while the robust RL deals with intruders who have a constant exploration rate (persistent attacker). The interactions between defender and attacker are illustrated via the attack and defense cycles as in Fig. <ref type="figure">10</ref>. The attackers and defenders do not take actions simultaneously but asynchronously. On the attack cycle, the attacker evaluates previous attacks before launching a new attack if necessary. On the defense cycle, after receiving an alert, the defender carries out a meta-analysis on the latest attacks and calculates the corresponding utility before deploying a new defense if needed. An advantage of this system model is that it does not assume any underlying model for the attacker but instead treats attack strategies as black boxes.</p><p>Alternatively, Elderman et al. <ref type="bibr" target="#b172">[173]</ref> simulated cyber security problems in networking as a stochastic Markov game with two agents, one attacker, and one defender, with incomplete information and partial observability. The attacker does not know the network topology but attempts to reach and get access to the location that contains a valuable asset. The defender knows the internal network but does not see the attack types or position of intruders. This is a challenging cyber security game because a player needs to adapt its strategy to defeat the unobservable opponents <ref type="bibr" target="#b173">[174]</ref>. Different algorithms, e.g., Monte Carlo learning, Q-learning, and neural networks are used to learn both defender and attacker. Simulation results show that Monte Carlo learning with the softmax exploration is the best method for learning both attacking and defending strategies. Neural network algorithms have a limited adversarial learning capability, and thus they are outperformed by Qlearning and Monte Carlo learning techniques. This simulation has a disadvantage that simplifies the real-world cyber security problem into a game of only two players with only one asset. In real practice, there can be multiple hackers simultaneously penetrating a server that holds valuable data. Also, a network may contain useful data in different locations instead of in a single location as simulated.</p><p>IV. DISCUSSIONS AND FUTURE RESEARCH DIRECTIONS DRL has emerged over recent years as one of the most successful methods of designing and creating human or even superhuman AI agents. Many of these successes have relied on the incorporation of DNNs into a framework of traditional RL to address complex and high-dimensional sequential decisionmaking problems. Applications of DRL algorithms, therefore, have been found in various fields, including IoT and cyber security. Computers and the Internet today play crucial roles in many areas of our lives, e.g., entertainment, communication, transportation, medicine, and even shopping. Lots of our personal information and important data are stored online. Even financial institutions, e.g., banks, mortgage companies, and brokerage firms, run their business online. Therefore, it is essential to have a security plan in place to prevent hackers from accessing our computer systems. This paper has presented a comprehensive survey of DRL methods and their applications to cyber security problems, with notable examples summarized in Table <ref type="table">II</ref>. The adversarial environment of cyber systems has instigated various proposals of game theory models involving multiple DRL agents. We found that this kind of application occupies a major proportion of papers in the literature relating to DRL for cyber security problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Challenges and future work on applying DRL for CPS security solutions</head><p>An emerging area is the use of DRL for security solutions for cyber-physical systems <ref type="bibr" target="#b174">[175]</ref>, <ref type="bibr" target="#b175">[176]</ref>. The large-scale and complex nature of CPSs, e.g., in environmental monitoring networks, electrical smart grid systems, transportation management network, and cyber manufacturing management system, require security solutions to be responsive and accurate. This has been addressed by various DRL approaches, e.g., TRPO algorithm <ref type="bibr" target="#b92">[93]</ref>, LSTM-Q-learning <ref type="bibr" target="#b88">[89]</ref>, double DQN, and A3C <ref type="bibr" target="#b85">[86]</ref>. One of the great challenges in implementing DRL algorithms for CPS security solutions is the lack of realistic CPS simulations. For example, the work in <ref type="bibr" target="#b85">[86]</ref> had to use the Matlab/Simulink CPS modelling and embed it into the OpenAI Gym environment. This implementation is expensive in terms of computational time due to the overhead caused by integrating the Matlab/Simulink CPS simulation in the OpenAI Gym library. More proper simulations of CPS models embedded directly in DRL-enabled environments are thus encouraged in a future work. Another common challenge in applying DRL algorithms is to transfer the trained policies from simulations to real-world environments. While simulations are cheap and safe for training DRL agents, the reality gap due to modelling impreciseness and errors make the transfer challenging. This is more critical for CPS modelling because of the complexity, dynamics and large scale of CPS. A research in this direction, i.e., sim-to-real transfer for DRL-based security solutions for CPS, is worth investigating as it can help to reduce time, costs and increase safety during training process of DRL agents, and eventually reduce costly mistakes when executing in realworld environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Challenges and future work on applying DRL for IDS</head><p>Although there have been a large number of applications of traditional RL methods for IDSs, there has been a small amount of work on DRL algorithms for this kind of application. This is probably because the integration of deep learning and RL methods has just been sustained very recently. The complexity and dynamics of intrusion detection problems are expected to be solved effectively by DRL methods, which combine the powerful representation learning and function approximation capabilities of deep learning and the optimal sequential decision-making capability of traditional RL. Applying DRL for IDS requires simulated or real intrusion environments for training agents interactively. This is a great challenge because using real environments for training is costly while simulated environments may be far from reality. Most of the existing studies on DRL for intrusion detection relied on game-based settings (e.g., Fig. <ref type="figure">7</ref>) or labelled intrusion datasets. For example, the work in <ref type="bibr" target="#b124">[125]</ref> used two datasets of labelled intrusion samples and adjusted the DRL machinery for it to work on these datasets in a supervised learning manner. This kind of application lacks a live environment and proper interactions between DRL agents and the environment. There is thus a gap for future research on creating more realistic environments, which are able to respond in real time to actions of the DRL agents and facilitate the full exploitation of the DRL's capabilities to solve complex and sophisticated cyber intrusion detection problems. Furthermore, as host-based and network-based IDSs have both advantages and disadvantages, combining these systems could be a logical approach. DRLbased solutions for this kind of integrated system would be another interesting future study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Exploring capabilities of model-based DRL methods</head><p>Most DRL algorithms used for cyber defense so far are model-free methods, which are sample inefficient as they require a large quantity of training data. These data are difficult to obtain in real cyber security practice. Researchers generally utilize simulators to validate their proposed approaches, but these simulators often do not characterize the complexity and dynamics of real cyber space of the IoT systems fully. Modelbased DRL methods are more appropriate than model-free methods when training data are limitedly available because, with model-based DRL, it can be easy to collect data in a scalable way. Exploration of model-based DRL methods or the integration of model-based and model-free methods for cyber defense is thus an interesting future study. For example, function approximators can be used to learn a proxy model of the actual high-dimensional and possibly partial observable environment <ref type="bibr" target="#b176">[177]</ref>- <ref type="bibr" target="#b178">[179]</ref>, which can be then employed to deploy planning algorithms, e.g., Monte-Carlo tree search techniques <ref type="bibr" target="#b179">[180]</ref>, to derive optimal actions. Alternatively, model-based and model-free combination approaches, such as model-free policy with planning capabilities <ref type="bibr" target="#b180">[181]</ref>, <ref type="bibr" target="#b181">[182]</ref> or model-based lookahead search <ref type="bibr" target="#b30">[31]</ref>, can be used as they aggregate advantages of both methods. On the other hand, current literature on applications of DRL to cyber security often limits at discretizing the action space, which restricts the</p><p>TABLE II SUMMARY OF TYPICAL DRL APPLICATIONS IN CYBER SECURITY Applications Goals/Objectives Algorithms States Actions Rewards Robustness-guided falsification of CPS [86] Find falsifying inputs (counterexamples) for CPS Double DQN and A3C</p><p>Defined as the output of the system.</p><p>Choose the next input value from a set of piecewiseconstant input signals.</p><p>Characterized by a function of past-dependent life-long property, output signal and time. Security and safety in autonomous vehicle systems <ref type="bibr" target="#b88">[89]</ref> Maximize the robustness of AV dynamics control to cyberphysical attacks that inject faulty data to sensor readings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q-learning with LSTM</head><p>AV's own position and speed along with distance and speed of some nearby objects, e.g., the leading AV.</p><p>Take appropriate speeds to maintain safe spacing between AVs. Using a utility function that takes into account the deviation from the optimal safe spacing. Increasing robustness of the autonomous system against adversarial attacks [93] Devise filtering schemes to detect corrupted measurements (deception attack) and mitigate the effects of adversarial errors. TRPO Characterized by sensor measurements and actuation noises. Determine which estimation rule to use to generate an estimated state from a corrupted state. Defined via a function that takes state features as inputs. Secure offloading in mobile edge caching [142] Learn a policy for a mobile device to securely offload data to edge nodes against jamming and smart attacks. DQN with hotbooting transfer learning technique. Represented via a combination of user density, battery levels, jamming strength, and radio channel bandwidth. Agent's actions include choosing an edge node, selecting offloading rate and time, transmit power and channel. Computed based on secrecy capacity, energy consumption, and communication efficiency.</p><p>Anti-jamming communication scheme for CRN <ref type="bibr" target="#b151">[152]</ref> Derive an optimal frequency hopping policy for CRN SUs to defeat smart jammers based on a frequency-spatial antijamming game.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DQN that employs CNN</head><p>Consist of presence status of PUs and SINR information at time t -1 received from serving base station or access point.</p><p>SUs take action to leave a geographical area of heavy jamming obstructed by smart jammers or choose a frequency channel to send signals.</p><p>Represented via a utility function based on SINR and transmission cost.</p><p>Anti-jamming communication method <ref type="bibr" target="#b152">[153]</ref>, improving the previous work in <ref type="bibr" target="#b151">[152]</ref> Propose a smart anti-jamming scheme similar to <ref type="bibr" target="#b151">[152]</ref> with two main differences: spectrum waterfall is used as the state, and jammers can have different channel-slot transmission structure with users.</p><p>DQN with recursive CNN due to recursion characteristic of spectrum waterfall.</p><p>Using temporal and spectral information, i.e., spectrum waterfall containing both frequency and time domain information of the network environment.</p><p>Agent's action is to select a discretized transmission frequency from a predefined set.</p><p>Defined by a function involving SINR-based transmission rate and cost for frequency switching.</p><p>Spoofing detection in wireless networks <ref type="bibr" target="#b155">[156]</ref>, <ref type="bibr" target="#b156">[157]</ref> Select the optimal authentication threshold.</p><p>Q-learning and Dyna-Q Include false alarm rate and missed detection rate of the spoofing detection system at time t -1 Action set includes the choices of different discrete levels of the authentication thresholds bounded within a specified interval.</p><p>Using a utility function calculated based on the Bayesian risk, which is the expected payoff in spoofing detection.</p><p>Mobile offloading for cloud-based malware detection <ref type="bibr" target="#b160">[161]</ref>, improving the previous work in <ref type="bibr" target="#b161">[162]</ref> Improve malware detection accuracy and speed. Hotbooting Q-learning and DQN.</p><p>Consist of current radio bandwidth and previous offloading rates of other devices.</p><p>Select optimal offloading rate level for each mobile device.</p><p>Represented by a utility function calculated based on the detection accuracy, response speed, and transmission cost. Autonomous defense in SDN <ref type="bibr" target="#b167">[168]</ref> Tackle the poisoning attacks that manipulate states or flip reward signals during the training process of RL-based defense agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Double DQN and A3C</head><p>Represented by an array of zeros and ones showing the state of the network (whether a node is compromised or a link is switched on/off). Array length is equal to several nodes plus several links. Attackers learn to select a node to compromise while a defender can take four actions: isolate, patch, reconnect and migrate to protect server and preserve as many nodes as possible.</p><p>Modelled based on the status of the critical server, number of preserved nodes, migration cost and the validity of actions taken.</p><p>Secure mobile crowdsensing (MCS) system <ref type="bibr" target="#b192">[193]</ref> Optimize payment policy to improve the sensing performance against faked sensing attacks by formulating a Stackelberg game.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DQN</head><p>Consist of the previous sensing quality and the payment policy.</p><p>Select the server's optimal payment vector to smartphone users.</p><p>Using a utility function that involves the total payment to users and the benefit of server from sensing reports of different accuracy levels. Automated URLbased phishing detection <ref type="bibr">[198]</ref> Detect malicious websites (URLs)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DQN</head><p>Characterized by the vector space representation of website features such as HTTPS protocols, having IP address, prefix or suffix in URLs.</p><p>Select either 0 or 1, corresponding to a benign or phishing URL.</p><p>Based on the classification action, the reward equates to 1 or -1 if the URL is classified correctly or incorrectly.</p><p>full capability of the DRL solutions to real-world problems. An example is the application of DRL for selecting optimal mobile offloading rates in <ref type="bibr" target="#b160">[161]</ref>, <ref type="bibr" target="#b161">[162]</ref> where the action space has been discretized although a small change of the rate would primarily affect the performance of the cloud-based malware detection system. Investigation of methods that can deal with continuous action spaces in cyber environments, e.g., policy gradient and actor-critic algorithms, is another encouraging research direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Training DRL in adversarial cyber environments</head><p>AI can help defend against cyber attacks but can also facilitate dangerous attacks, i.e., offensive AI. Hackers can take advantages of AI to make attacks smarter and more sophisticated to bypass detection methods to penetrate computer systems or networks. For example, hackers may employ algorithms to observe normal behaviors of users and employ the users' patterns to develop untraceable attacking strategies. Machine learning-based systems can mimic humans to craft convincing fake messages that are utilized to conduct largescale phishing attacks. Likewise, by creating highly realistic fake video or audio messages based on AI advances (i.e., deepfakes <ref type="bibr" target="#b182">[183]</ref>), hackers can spread false news in elections or manipulate financial markets <ref type="bibr" target="#b183">[184]</ref>. Alternatively, attackers can poison the data pool used for training deep learning methods (i.e., machine learning poisoning) or attackers can manipulate the states or policies, falsify part of the reward signals in RL to trick the agent into taking sub-optimal actions, resulting in the agent being compromised <ref type="bibr" target="#b184">[185]</ref>. These kinds of attacks are difficult to prevent, detect, and fight against as they are part of a battle between AI systems. Adversarial machine learning, especially supervised methods, have been used extensively in cyber security <ref type="bibr" target="#b185">[186]</ref> but very few studies have been found on using adversarial RL <ref type="bibr" target="#b186">[187]</ref>. Adversarial DRL or DRL algorithms trained in various adversarial cyber environments are worth comprehensive investigations as they can be a solution to battle against the increasingly complex offensive AI systems <ref type="bibr" target="#b187">[188]</ref>- <ref type="bibr" target="#b189">[190]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Human-machine teaming with human-on-the-loop models</head><p>With the support of AI systems, cyber security experts no longer examine a huge volume of attack data manually to detect and defend against cyber attacks. This has many advantages because the security teams alone cannot sustain the volume. AI-enabled defense strategies can be automated and deployed rapidly and efficiently but these systems alone cannot issue creative responses when new threats are introduced. Moreover, human adversaries are always behind the cybercrime or cyber warfare. Therefore, there is a critical need for human intellect teamed with machines for cyber defenses. The traditional human-in-the-loop model for humanmachine integration struggles to adapt quickly with cyber defense system because autonomous agent carries out part of the task and need to halt to wait for human's responses before completing the task. The modern human-on-the-loop model would be a solution for a future human-machine teaming cyber security system. This model allows agents to autonomously perform the task whilst humans can monitor and intervene operations of agents only when necessary. How to integrate human knowledge into DRL algorithms <ref type="bibr" target="#b190">[191]</ref> under the humanon-the-loop model for cyber defense is an interesting research question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Exploring capabilities of multiagent DRL methods</head><p>As hackers utilized more and more sophisticated and largescale approach to attack computer systems and networks, the defense strategies need to be more intelligent and large-scale as well. Multiagent DRL is a research direction that can be explored to tackle this problem. Game theory models for cyber security reviewed in this paper have involved multiple agents but they are restricted at a couple of attackers and defenders with limited communication, cooperation and coordination among the agents. These aspects of multiagent DRL need to be investigated thoroughly in cyber security problems to enable an effective large-scale defense plan. Challenges of multiagent DRL itself then need to be addressed such as non-stationarity, partial observability, and efficient multiagent training schemes <ref type="bibr" target="#b191">[192]</ref>. On the other hand, the RL methodology has been applied to deal with various cyber attacks, e.g. jamming, spoofing, false data injection, malware, DoS, DDoS, brute force, Heartbleed, botnet, web attack, and infiltration attack <ref type="bibr" target="#b192">[193]</ref>- <ref type="bibr">[198]</ref>. However, recently emerged or new types of attacks have been largely unaddressed. One of these new types is the bit-and-piece DDoS attack. This attack injects small junk into legitimate traffic of over a large number of IP addresses so that it can bypass many detection methods as there is so little of it per address. Another emerging attack, for instance, is attacking from the computing cloud to breach systems of companies who manage IT systems for other firms or host other firms' data on their servers. Alternatively, hackers can use quantum physics-based powerful computers to crack encryption algorithms that are currently used to protect various types of invaluable data <ref type="bibr" target="#b183">[184]</ref>. Consequently, a future study on addressing these new types of attacks is encouraged.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. The learning architecture of A3C, consisting of a global network and a number of worker agents. Each worker initially resets its parameters to those of the global network and interacts with its copy of the environment for learning. Gradients obtained from these individual learning processes will be used to update the global network asynchronously. This increases the learning speed and diversifies the experience learned by the global network as the experiences obtained by individual worker agents are independent.</figDesc><graphic coords="3,339.83,56.07,195.35,213.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Different (sub)sections of the survey on DRL in cyber security.</figDesc><graphic coords="4,48.96,390.64,251.90,138.03" type="bitmap" /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cognitive radio network and network service chaining toward 5G: challenges and requirements</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kakalou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Psannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Krawiec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Badea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A deep reinforcement learning-based approach to dynamic eMBB/URLLC multiplexing in 5G NR</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="6439" to="6456" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Datadriven software defined network attack detection: state-of-the-art and perspectives</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">513</biblScope>
			<biblScope unit="page" from="65" to="83" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Integration of cloud computing and Internet of Things: a survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Botta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">De</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Persico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pescapé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="684" to="700" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neuromemristive circuits for edge computing: a review</title>
		<author>
			<persName><forename type="first">O</forename><surname>Krestinskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="23" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mobile edge computing: a survey</title>
		<author>
			<persName><forename type="first">N</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Taherkordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Skeie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="450" to="465" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fog computing: Helping the Internet of Things realize its potential</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dastjerdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="112" to="116" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The future of cybersecurity: major role of artificial intelligence, machine learning, and deep learning in cyberspace</title>
		<author>
			<persName><forename type="first">B</forename><surname>Geluvaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Satwik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Networks and Communication Technologies</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="739" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A survey of data mining and machine learning methods for cyber security intrusion detection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Buczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Guven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys and Tutorials</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1153" to="1176" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the effectiveness of machine and deep learning for cyber security</title>
		<author>
			<persName><forename type="first">G</forename><surname>Apruzzese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Colajanni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ferretti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marchetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Cyber Conflict (CyCon)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="371" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Machine learning and deep learning methods for cybersecurity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="35365" to="35381" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Machine learning aided Android malware classification</title>
		<author>
			<persName><forename type="first">N</forename><surname>Milosevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dehghantanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K R</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Electrical Engineering</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="266" to="274" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A short review on applications of deep learning for cyber security</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mohammed Harun Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vinayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Soman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.06292</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A survey of deep learning methods for cyber security</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Buczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Chavis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Corbett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">122</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A learning-based solution for an adversarial repeated game in cyber-physical power systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2019.2955857</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey on security control and attack detection for industrial cyber-physical systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="page" from="1674" to="1683" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Detecting cyber-physical attacks in CyberManufacturing systems with machine learning methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">B</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Manufacturing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1111" to="1123" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">IoT security techniques based on machine learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.06275</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Analysis of security data from a large computing organization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kalbarczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dependable Systems and Networks (DSN), IEEE/IFIP 41st International Conference on</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="506" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">System design perspective for human-level agents using deep reinforcement learning: A survey</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="27091" to="27102" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Formation control with collision avoidance through deep reinforcement learning using model-guided demonstration</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2020.3004893</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Price trailing for financial trading using deep reinforcement learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tsantekidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Passalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Toufa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saitas-Zarkias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chairistanidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tefas</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2020.2997523</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A multi-objective deep reinforcement learning framework</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02965</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Approximate policy-based accelerated deep reinforcement learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1820" to="1830" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Application of reinforcement learning for security enhancement in cognitive radio networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L A</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Poh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="809" to="829" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A survey of dynamic spectrum allocation based on reinforcement learning algorithms in cognitive radio networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="493" to="506" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Reinforcement learning based PHY authentication for VANETs</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3068" to="3079" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An efficient reinforcement learning-based botnet detection approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alauthman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Kasassbeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Qerem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K R</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page">102479</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A human mixed strategy approach to deep reinforcement learning</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Systems, Man, and Cybernetics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4023" to="4028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mastering the game of Go without human knowledge</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">550</biblScope>
			<biblScope unit="issue">7676</biblScope>
			<biblScope unit="page" from="354" to="359" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ewalds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Vezhnevets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04782</idno>
		<title level="m">StarCraft II: A new challenge for reinforcement learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.07193</idno>
		<title level="m">TStarBots: Defeating the cheating level builtin AI in StarCraft II in the full game</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">On reinforcement learning for full-length game of StarCraft</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.09095</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01830</idno>
		<title level="m">Relational deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Human-level performance in firstperson multiplayer games with population-based deep reinforcement learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dunning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Marris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Castaneda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sonnerat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.01281</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">OpenAI Five</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/five/" />
		<imprint>
			<date type="published" when="2019-03-01">2019. March 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Holly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3389" to="3396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Navigating occluded intersections with autonomous vehicles using deep reinforcement learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cosgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fujimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2034" to="2039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A new tensioning method using deep reinforcement learning for surgical pattern cutting</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICIT.2019.8755235</idno>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Industrial Technology (ICIT)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Manipulating soft tissues by deep reinforcement learning for autonomous robotic surgery</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guest</surname></persName>
		</author>
		<idno type="DOI">10.1109/SYSCON.2019.8836924</idno>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Systems Conference (SysCon)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Keneshloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2469" to="2489" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Applications of deep learning and reinforcement learning to biological data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vassanelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2063" to="2079" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for de novo drug design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Popova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Isayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tropsha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">7885</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Software-defined networks with mobile edge computing and caching for smart cities: A big data deep reinforcement learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="31" to="37" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning with double Q-learning</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Hasselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2094" to="2100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dueling network architectures for deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hasselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1995" to="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for mobile edge caching: Review, new features, and open issues</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="50" to="57" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1928" to="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Intelligent cloud resource management with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="60" to="69" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A new deep-Q-learningbased transmission scheduling mechanism for the cognitive Internet of Things</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2375" to="2385" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Self-tuning sectorization: deep reinforcement learning meets broadcast beam optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shafin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4038" to="4053" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Review on the research and practice of deep learning and reinforcement learning in smart grids</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CSEE Journal of Power and Energy Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="362" to="370" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Green resource allocation based on deep reinforcement learning in contentcentric IoT</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<idno type="DOI">10.1109/TETC.2018.2805718</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computing</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Trust-based social networks with computing, caching and communications: A deep reinforcement learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNSE.2018.2865183</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Network Science and Engineering</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Applications of deep reinforcement learning in communications and networking: A survey</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1109/COMST.2019.2916583</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys and Tutorials</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Blockchain and deep reinforcement learning empowered intelligent 5G beyond</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maharjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="10" to="17" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for wireless sensor scheduling in cyber-physical systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Quevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Karl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page">108759</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Q-learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning: A brief survey</title>
		<author>
			<persName><forename type="first">K</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Deisenroth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Bharath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="26" to="38" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Playing Atari with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5602</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Prioritized experience replay</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05952</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Trust region policy optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1889" to="1897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Variance reduction for policy gradient with actiondependent factorized baselines</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07246</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.02971</idno>
		<title level="m">Continuous control with deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Barth-Maron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Horgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Muldal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.08617</idno>
		<title level="m">Distributed distributional deterministic policy gradients</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Reinforcement learning with unsupervised auxiliary tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05397</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Bridging the gap between value and policy based reinforcement learning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2775" to="2785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Deep Reinforcement Learning Hands-On: Apply modern RL methods, with deep Q-networks, value iteration, policy gradients, TRPO, AlphaGo Zero and more</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lapan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Packt Publishing Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Classic control: control theory problems from the classic RL literature</title>
		<ptr target="https://gym.openai.com/envs/#classiccontrol" />
	</analytic>
	<monogr>
		<title level="m">OpenAI Gym Toolkit Documentation</title>
		<imprint>
			<date type="published" when="2020-12-14">December 14, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Box2D: continuous control tasks in the Box2D simulator</title>
		<ptr target="https://gym.openai.com/envs/#box2d" />
	</analytic>
	<monogr>
		<title level="m">OpenAI Gym Toolkit Documentation</title>
		<imprint>
			<date type="published" when="2020-12-14">December 14, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Current status and advancement of cyber-physical systems in manufacturing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Torngren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Onori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Manufacturing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="517" to="527" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Health-CPS: Healthcare cyber-physical system assisted by cloud and big data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alamri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Systems Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="95" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Maintaining security and privacy in health care system using learning based deep-Q-networks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Shakeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Dhulipala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Jaber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Systems</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">186</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A survey on smart grid cyber-physical system testbeds</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Cintuglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Akkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Uluagac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys and Tutorials</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="446" to="464" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Evaluation of reinforcement learning-based false data injection attack to automatic voltage control</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Smart Grid</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2158" to="2169" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A multistage game in smart grid security: A reinforcement learning solution</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2018.2885530</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Interdependenceaware game-theoretic framework for secure intelligent transportation systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ferdowsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eldosouky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Saad</surname></persName>
		</author>
		<idno type="DOI">10.1109/JIOT.2020.3020899</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Nonlane-discipline-based car-following model for electric vehicles in transportation-cyber-physical systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="47" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Reinforcement Learning for Cyber-Physical Systems: with Cybersecurity Case Studies</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning based optimal defense for cyber-physical system in presence of unknown cyber attack</title>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Intelligence (SSCI)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Falsification of cyber-physical systems using deep reinforcement learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Akazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Formal Methods</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="456" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Convergence proofs for simulated annealing falsification of safety properties</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fainekos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 50th Annual Allerton Conference on Communication, Control, and Computing</title>
		<meeting><address><addrLine>Allerton</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1594" to="1601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Falsification of temporal properties of hybrid systems using the cross-entropy method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fainekos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 15th ACM International Conference on Hybrid Systems: Computation and Control</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Robust deep reinforcement learning for security and safety in autonomous vehicle systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ferdowsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Challita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Saad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Mandayam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="307" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Long memory is important: A test study on deep-learning based car-following model</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<biblScope unit="volume">514</biblScope>
			<biblScope unit="page" from="786" to="795" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning approach for autonomous vehicle systems for maintaining security and safety using LSTM-GAN</title>
		<author>
			<persName><forename type="first">I</forename><surname>Rasheed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vehicular Communications</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">100266</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Adversarial reinforcement learning for observer design in autonomous systems under cyber attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.06784</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Machine learning based intrusion detection system for software defined networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abubakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pranggono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 Seventh International Conference on Emerging Security Technologies (EST)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="138" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">A survey on anomaly based host intrusion detection system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Malathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jayaseeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physics: Conference Series</title>
		<imprint>
			<biblScope unit="volume">1000</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12049</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Adaptive and online network intrusion detection system using clustering and extreme learning machines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akusok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lendasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Franklin Institute</title>
		<imprint>
			<biblScope unit="volume">355</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1752" to="1779" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">A machine learning based intrusion detection scheme for data fusion in mobile clouds involving heterogeneous client networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sampalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="205" to="215" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Introducing deep learning self-adaptive misuse network intrusion detection systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Papamartzivanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Mármol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kambourakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="13546" to="13560" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Windows based data sets for evaluation of robustness of host based intrusion detection systems (IDS) to zero-day and stealth attacks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Haider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Creech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">HIDS: A host based intrusion detection system for cloud computing environment</title>
		<author>
			<persName><forename type="first">P</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Peddoju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Junaid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of System Assurance Engineering and Management</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="567" to="576" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">A host-based intrusion detection and mitigation framework for smart home IoT using Open-Flow</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nobakht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boreli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International Conference on Availability, Reliability and Security</title>
		<imprint>
			<publisher>ARES</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="147" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">A survey of random forest based methods for intrusion detection systems</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A A</forename><surname>Resende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">LSTM-based system-call language modeling and robust ensemble method for designing hostbased intrusion detection systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Paek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01726</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Host based intrusion detection system with combined CNN/RNN model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fallon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">A hybrid deep learning model for efficient intrusion detection in big data environment</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gumaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alsanad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alrubaian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fortino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">513</biblScope>
			<biblScope unit="page" from="386" to="396" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Analysis of Network Intrusion Detection System with Machine Learning Algorithms (Deep Reinforcement Learning Algorithm)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Janagam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hossen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>Blekinge Institute of Technology, Sweden</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Dissertation</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">A reinforcement learning approach for host-based intrusion detection using sequences of system calls</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Computing</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="995" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Learning to predict by the methods of temporal differences</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="44" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">A sparse kernel-based least-squares temporal difference algorithm for reinforcement learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Natural Computation</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">A kernel-based reinforcement learning approach to dynamic behavior modeling of intrusion detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Neural Networks</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="455" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Sequential anomaly detection based on temporal-difference learning: Principles, models and case studies</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="859" to="867" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Intrusion detection system using log files and reinforcement learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Deokar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hazarnis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Distributed Reinforcement Learning for Network Intrusion Response</title>
		<author>
			<persName><forename type="first">K</forename><surname>Malialis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<pubPlace>University of York, UK</pubPlace>
		</imprint>
	</monogr>
	<note>Doctoral Dissertation</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Distributed response to network intrusions using multiagent reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Malialis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kudenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="270" to="284" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">Introduction to Reinforcement Learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Defending against distributed denial-of-service attacks with max-min fair server-centric router throttles</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="42" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Cooperative machine learning for intrusion detection system</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kulkarni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Scientific and Engineering Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1780" to="1785" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Multiagent systems for network intrusion detection: A review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Herrero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Corchado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Intelligence in Security for Information Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="143" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Influence diagrams for team decision analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Detwarasiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="207" to="228" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Cooperative game theoretic approach using fuzzy Q-learning for detecting and preventing intrusions in wireless sensor networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shamshirband</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Anuar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L M</forename><surname>Kiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="228" to="241" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Optimization of load balancing using fuzzy Q-learning for next generation wireless networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Muñoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>De La Bandera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="984" to="994" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">An appraisal and design of a multiagent system based cooperative wireless intrusion detection computational intelligence technique</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shamshirband</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Anuar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L M</forename><surname>Kiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2105" to="2127" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Variants of LEACH routing protocol in WSN: A comparative analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 8th International Conference on Cloud Computing</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="199" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Adversarial environment reinforcement learning algorithm for intrusion detection</title>
		<author>
			<persName><forename type="first">G</forename><surname>Caminero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lopez-Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="96" to="109" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Application of deep reinforcement learning to intrusion detection for supervised problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lopez-Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Esguevillas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<date type="published" when="2020">112963. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">A systematic state-of-the-art analysis of multiagent intrusion detection</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Saeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Selamat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Rohani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Krejcar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Chaudhry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="180184" to="180209" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">A survey of game theory as applied to network security</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shandilya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">43rd Hawaii International Conference on System Sciences</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Game theory for cyber security</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dasgupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Sixth Annual Workshop on Cyber Security and Information Intelligence Research</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Dynamic game theories in cyber security</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Stefanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of Dynamic Systems and Applications</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="303" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">A survey of game theoretic methods for cyber security</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE First International Conference on Data Science in Cyberspace</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="631" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Game theory meets network security: A tutorial</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2018 ACM SIGSAC Conference on Computer and Communications Security</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2163" to="2165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">A survey on jamming attacks and countermeasures in WSNs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mpitziopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gavalas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Konstantopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pantziou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys and Tutorials</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="42" to="56" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Resilient eventtriggered controller synthesis of networked control systems under periodic DoS jamming attacks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCYB.2018.2861834</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Secure identification under passive eavesdroppers and active jamming attacks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Boche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="472" to="485" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Anti-jamming games in multi-channel cognitive radio networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Clancy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="15" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Anti-jamming in cognitive radio networks using reinforcement learning algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wireless and Optical Communications Networks (WOCN), Ninth International Conference on</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Competing mobile network game: Embracing antijamming and jamming strategies with reinforcement learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dastangoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fossa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Kung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Communications and Network Security (CNS)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Cognitive jamming game for dynamically countering ad hoc cognitive radio networks</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Conley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MILCOM 2013-2013 IEEE Military Communications Conference</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1176" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">A fictitious play-based game-theoretical approach to alleviating jamming attacks for cognitive radios</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dabcevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Betancourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Marcenaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Regazzoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="8158" to="8162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Jamming mitigation in cognitive radio networks using a modified Q-learning algorithm</title>
		<author>
			<persName><forename type="first">F</forename><surname>Slimeni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scheers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chtourou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Le</forename><surname>Nir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 International Conference on Military Communications and Information Systems (ICMCIS)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">UAV relay in VANETs against smart jamming with reinforcement learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4087" to="4097" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Security in mobile edge caching with reinforcement learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="116" to="122" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Multiagent reinforcement learning based cognitive anti-jamming</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Aref</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Jayaweera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Machuzak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wireless Communications and Networking Conference</title>
		<imprint>
			<publisher>WCNC</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Reinforcement learning based anti-jamming with wideband autonomous cognitive radios</title>
		<author>
			<persName><forename type="first">S</forename><surname>Machuzak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Jayaweera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE/CIC International Conference on Communications in China</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Reinforcement learning-based spectrum management for cognitive radio networks: A literature review and case study</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Felice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bedogni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bononi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Cognitive Radio</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1849" to="1886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">A survey of security challenges in cognitive radio networks: Solutions and future research directions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Attar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Vasilakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3172" to="3186" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">An anti-jamming stochastic game for cognitive radio networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Clancy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="877" to="889" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Markov games as a framework for multiagent reinforcement learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 11th International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Power control with reinforcement learning in cooperative cognitive radio networks against jamming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Supercomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3237" to="3257" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Coping with a smart jammer in wireless networks: A Stackelberg game approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Richa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4038" to="4047" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Multiagent learning using a variable learning rate</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bowling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="250" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Two-dimensional anti-jamming communication based on deep reinforcement learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 42nd IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2087" to="2091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Anti-jamming communications using spectrum waterfall: A deep reinforcement learning approach</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anpalagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Letters</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="998" to="1001" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Perceptual spectrum waterfall of pattern shape recognition algorithm</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 18th International Conference on Advanced Communication Technology</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="382" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Non-cryptographic authentication and identification in wireless networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mohapatra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="56" to="62" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Spoofing detection with reinforcement learning in wireless networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Global Communications Conference (GLOBECOM)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">PHY-layer spoofing detection with reinforcement learning in wireless networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="10037" to="10047" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Integrated architecture for learning, planning, and reacting based on approximating dynamic programming</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 7th International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="216" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Using Bayesian networks for probabilistic identification of zero-day attack paths</title>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2506" to="2521" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Zero-day signature extraction for high-volume attacks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Afek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bremler-Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Feibish</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNET.2019.2899124</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Reinforcement learning based mobile offloading for cloud-based malware detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GLOBECOM 2017-IEEE Global Communications Conference</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Mobile cloud offloading for malware detections with learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Communications Workshops</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="197" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Software-defined networking for RSU clouds in support of the internet of vehicles</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Salahuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="144" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Energy-efficient monitoring in software defined wireless sensor networks using reinforcement learning: A prototype</title>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Distributed Sensor Networks</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">360428</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Congestion prevention mechanism based on Q-leaning for efficient routing in SDN</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talukder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Networking (ICOIN)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="124" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">QoS-aware adaptive routing in multi-layer hierarchical software defined networks: A reinforcement learning approach</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Akyildiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Services Computing</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="25" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Knowledge-defined networking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mestres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodriguez-Natal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barlet-Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alarcón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Solé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Estrada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2" to="10" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Reinforcement learning for autonomous defence in software-defined networking</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">I</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Alpcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">De</forename><surname>Vel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Decision and Game Theory for Security</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="145" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">A mininet-based virtual testbed for distributed SDN development</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>O'connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ACM SIGCOMM Computer Communication Review</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="365" to="366" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Reinforcement learning algorithms for adaptive cyber defense against Heartbleed</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First ACM Workshop on Moving Target Defense</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Risk assessment of buffer &quot;Heartbleed&quot; over-read vulnerabilities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="555" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">A survey of code reuse attack and defense</title>
		<author>
			<persName><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent and Interactive Systems and Applications</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="782" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Adversarial reinforcement learning in a cyber security simulation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Elderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Pater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Thie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Drugan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Agents and Artificial Intelligence (ICAART)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="559" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Game theory with learning for cyber security monitoring</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Kamhoua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Kwiat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">T</forename><surname>Kalbarczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Iyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 17th International Symposium on High Assurance Systems Engineering</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Cyber-attack recovery strategy for smart grid based on deep reinforcement learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Smart Grid</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2476" to="2486" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning for cybersecurity assessment of wind integrated power systems</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ospina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Konstantinou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03025</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Action-conditional video prediction using deep networks in atari games</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2863" to="2871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">Deep multi-scale video prediction beyond mean square error</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05440</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nagabandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Fearing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7559" to="7566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">A survey of Monte Carlo tree search methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Powley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitehouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">I</forename><surname>Cowling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rohlfshagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Colton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Intelligence and AI in Games</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Value iteration networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2154" to="2162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<title level="m" type="main">Learning model-based planning from scratch</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Racanière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06170</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<title level="m" type="main">Deep learning for deepfakes creation and detection: a survey</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11573</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Five emerging cyber-threats to worry about in 2019</title>
		<author>
			<persName><forename type="first">M</forename><surname>Giles</surname></persName>
		</author>
		<ptr target="https://www.technologyreview.com/2019/01/04/66232/five-emerging-cyber-threats-2019/" />
	</analytic>
	<monogr>
		<title level="j">MIT Technology Review</title>
		<imprint>
			<date type="published" when="2019-01-04">2019. January 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Vulnerability of deep reinforcement learning to policy induction attacks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Behzadan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Munir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning and Data Mining in Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="262" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">A survey of adversarial machine learning in cyber warfare</title>
		<author>
			<persName><forename type="first">V</forename><surname>Duddu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Defence Science Journal</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="356" to="366" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Adversarial attack and defense in reinforcement learning-from AI security view</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cybersecurity</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<monogr>
		<title level="m" type="main">Challenges and countermeasures for adversarial attacks on deep reinforcement learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ilahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Usama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Janjua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Fuqaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09684</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Finding needles in a moving haystack: prioritizing alerts with adversarial reinforcement learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Laszka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vorobeychik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="946" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<title level="m" type="main">Stealthy and efficient adversarial attacks against deep reinforcement learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.07099</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Multi-agent deep reinforcement learning with human strategies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICIT.2019.8755032</idno>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Industrial Technology (ICIT)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for multiagent systems: a review of challenges, solutions, and applications</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3826" to="3839" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">A secure mobile crowdsensing game with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="47" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning based smart mitigation of DDoS flooding in software-defined networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 23rd International Workshop on Computer Aided Modeling and Design of Communication Links and Networks</title>
		<meeting><address><addrLine>CA-MAD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Interferenceaware cooperative anti-jamming distributed channel selection in UAV communication networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="1911">1911. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">A collaborative multiagent reinforcement learning anti-jamming algorithm in wireless networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jia</surname></persName>
		</author>
		<idno type="DOI">10.1109/LWC.2019.2904486</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications Letters</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">On the performance of deep reinforcement learning-based anti-jamming method confronting intelligent jammer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">1361</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
