A Taxonomy of Network Threats and the Effect of Current Datasets on Intrusion Detection Systems

As the world moves towards being increasingly dependent on computers and automation, building secure applications, systems and networks are some of the main challenges faced in the current decade. The number of threats that individuals and businesses face is rising exponentially due to the increasing complexity of networks and services of modern networks. To alleviate the impact of these threats, researchers have proposed numerous solutions for anomaly detection; however, current tools often fail to adapt to ever-changing architectures, associated threats and zero-day attacks. This manuscript aims to pinpoint research gaps and shortcomings of current datasets, their impact on building Network Intrusion Detection Systems (NIDS) and the growing number of sophisticated threats. To this end, this manuscript provides researchers with two key pieces of information; a survey of prominent datasets, analyzing their use and impact on the development of the past decade's Intrusion Detection Systems (IDS) and a taxonomy of network threats and associated tools to carry out these attacks. The manuscript highlights that current IDS research covers only 33.3% of our threat taxonomy. Current datasets demonstrate a clear lack of real-network threats, attack representation and include a large number of deprecated threats, which together limit the detection accuracy of current machine learning IDS approaches. The unique combination of the taxonomy and the analysis of the datasets provided in this manuscript aims to improve the creation of datasets and the collection of real-world data. As a result, this will improve the efficiency of the next generation IDS and reflect network threats more accurately within new datasets.

I. INTRODUCTION

The world is becoming more dependent on connected devices, actuators and sensors, regulating the lives of millions of people. Furthermore, sensor data is expected to increase by around 13%, reaching 35% of overall data communication in 2020, reaching a peak of 50 billion connected devices and an increased monthly Internet traffic volume reaching 30 GB on average per capita compared to around 10 GB in 2016 . While each device in an Internet of Things (IoT) system exchanges data, associated services often provide interfaces to interact with the collected data, often increasing the attack The associate editor coordinating the review of this manuscript and approving it for publication was Xiaofan surface. Therefore, it is crucial to build robust tools to defend networks against security threats in modern IoT networks. Current detection tools are often based on outdated datasets that do not reflect the reality of recent/modern network attacks, rendering Intrusion Detection Systems (IDS) ineffective against new threats and zero-days. To the best knowledge of the authors, there are currently no manuscripts that analyze the shortcomings of available networking datasets, nor provide a taxonomy of the current network threats and the associated tools used to carry out these attacks.

The contributions of this research are threefold:

• An evaluation of the limitations of the available network-based datasets and their impact on the development of IDSs

• A review of the last decade's research on NIDS • A Threat taxonomy is presented, and categorized by:

-The Threat Sources -The Open Systems Interconnection (OSI) Layer -Active or Passive modes The evaluation of current network-based datasets provides researchers with an insight of the shortcomings of the datasets presented when used for training against real-world threats. A threat taxonomy is derived from the datasets and current real-world networking threats. This taxonomy serves two purposes-firstly, it strengthens our argument on the shortcomings of currently available datasets, but most importantly, it provides researchers with the ability to identify threats and tools underrepresented in currently available datasets. To facilitate this endeavor, we further map the current threats with their associated tools, which in turn can be used by research to create new datasets.

The rest of the paper is organized as follows; Section II depicts the main differences between IDSs, the metrics to consider for their evaluation and the role of feature selection in building IDSs. Section III reviews IDSs of the past decade and their individual contributions are assessed. This section also evaluates the drawbacks and limitations of the available datasets. Section IV provides the threat taxonomy. Section V summarizes the challenges presented in this work and provides recommendations. Finally, the paper is concluded in Section VI.

II. BACKGROUND A. INTRUSION DETECTION SYSTEMS

IDSs are defined as systems built to monitor and analyze network traffic and/or systems to detect anomalies, intrusions or privacy violations. When an intrusion is detected, an IDS is expected to (a) log the information related to the intrusion, (b) trigger alerts and (c) take mitigation and corrective actions .

IDS can either be Host Intrusion Detection System (HIDS) or Network Intrusion Detection System (NIDS). HIDS is responsible for monitoring a system internally, having access to log files, users' activities, etc. While NIDS analyses incoming and outgoing communication between network nodes.

IDSs differ based on their detection method. Signaturebased IDSs were the first to be developed. Accurate signatures are built from prior detected attacks. The main advantage of this method is the high accuracy of detecting known attacks. Signature-based IDS is, however, unable to detect zero-days, metamorphic and polymorphic threats . The second method, Anomaly-based detection, depends on identifying patterns and comparing them to normal traffic patterns. This method requires the system to be trained prior to deployment. The accuracy of anomaly-based systems against zero-days, metamorphic and polymorphic threats is better when compared to signature-based IDS. However, the false positive rate of anomaly-based detection is often higher. It is important to mention that benign/normal traffic patterns alone are not sufficient to detect attacks. For this reason, the features used to represent network traffic play an essential role in traffic representation.

Intrusion detection (both signature-based and anomalybased) can be done on a stateless (per packet) or stateful (per flow) basis. Most recent IDSs are stateful, as the flow provides ''context'', while packet analysis (stateless) does not provide this context. It is the responsibility of the researcher to decide which method is best suited for their application.

Anomaly-based IDS can be classified into subcategories based on the training method used. These categories are statistical, knowledge-based and Machine Learning (ML) based. Statistical includes univariate, multivariate and time series. Knowledge-based uses finite state machines and rules like case-based, N-based, expert systems and descriptor languages. Buczak and Guven provide recommendations on choosing the ML/Deep Learning (DL) algorithms based on the problem intended to be solved. Algorithms include Artificial Neural Networks (ANN), clustering, Genetic Algorithms (GA), etc. Specification-based combines the strength of both signature and anomaly based to form a hybrid model.

Owezarski et al. summarize the approaches to validate networking models, which applies to IDS, into four categories; mathematical models, simulation, emulation and real experiments. Each of these approaches has their own pros and cons as discussed by Behal and Kumar .

1) METRICS FOR IDS EVALUATION

In order for an IDS to be considered effective, high detection rate and low false positive rate are key aspects to consider. Multiple metrics could be used for an IDS evaluation. These metrics are discussed subsequently showing the significance and purpose of each. It is important to mention that depending only on detection rate as the only evaluation metric doesn't reflect an IDS performance.

Other important evaluation factors including the transparency and safety of the overall system, memory requirements, power consumption and throughput should be considered. Moreover, adds to the aforementioned requirements, ease of use, interoperability, transparency and collaboration.

IDS accuracy can be defined in terms of:

• True Positive (TP): Number of intrusions correctly detected • True Negative (TN): Number of non-intrusions correctly detected • False Positive (FP): Number of non-intrusions incorrectly detected • False Negative (FN): Number of intrusions incorrectly detected

Hodo et al. , Buse et al. and Aminanto et al. discuss the main metrics to consider for evaluation in their respective work. These include the overall accuracy, decision rates, precision, recall, F1 and Mcc.

Equation 1 provides the overall accuracy. It returns the probability that an item is correctly classified by the IDS.

Equation 2 calculates the Sensitivity, Specificity, Fallout, and Miss Rate detection rates, respectively. Stefan Axelsson stresses the fact that false positive rates (false alarms) highly limit the performance of an IDS due to the ''Base-rate fallacy problem''.

Detection Rates: Sensitivity(aka Recall, True Positive Rate) = TP TP + FN Specificity (aka Selectivity, True Negative Rate) = TN TN + FP Fallout(aka False Positive Rate) = FP TN + FP Miss Rate(aka False Negative Rate) = FN TP + FN (2) Equation 3 provides the percentage of positively classified incidents that are truly positive. Precision = TP TP + FP (3) To visualize the performance of an IDS, i.e. the trade-off between sensitivity (true positive rate) and fallout (true negative rate), AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) also known as Area Under the Receiver Operating Characteristics (AUROC) curve is used [11]-[13] Equation 4 represents the harmonic mean of precision and recall. F1 is better suited to represent the performance of an IDS, specially when dealing with imbalanced classes. F1 = 2TP 2TP + FP + FN (4) Equation 5 provides Matthews correlation coefficient. It can only be used in binary IDS in which incidents are classified as either attack or normal. Mcc = (TP * TN ) -(FP * FN ) √ (TP + FP)(TP + FN )(TN + FP)(TN +FN )

Equation 6 addresses the problem of calculating accuracy in imbalanced datasets. Numerous datasets have a limited number of attacks' data compared to benign traffic, hence, the geometric mean of accuracy provides a more precise metric than overall accuracy measure . Space-Time aware evaluation is introduced by Feargus Pendlebury et al. to overcome both spatial and temporal biases. The authors introduced three constraints to be considered when splitting datasets. gAcc = √ a +ve .a -ve = Sensitivity (TPR) .Specificity (TNR) Additionally, CPU consumption, throughput and power consumption are important metrics for evaluating IDSs. Specifically, these metrics are important for IDSs running on different hardware or with specific settings such as high-speed networks, or on hardware with limited resources.

2) FEATURE SELECTION AND IDS

''Feature Learning'' or ''Feature Engineering'' plays an essential role in building any IDS in a way that chosen features highly affect the IDS performance. Features are obtained using one of three processes; construction, extraction and selection. Selection involves filter, wrapper and embedded techniques . A classification of the features used in recent datasets is provided in . Different features representations (i.e. abstractions) are used to address different areas of threat detection. Some of them could be considered naïve when they contain basic network information. Others are considered rich when they represent deeper details . As highlighted by Rezaei and Liu , there are four main categories of networking features; time series, header, payload and statistical. Unlike header and payload features, time series and statistical ones are available for both encrypted and unencrypted traffic. The authors further discuss the shortcomings of current encrypted traffic classification research. Packet-based and flow-based features have been used for intrusion detection purposes. However, with the advancement of network encryption, packet-based features are rendered impractical for complex communication networks.

B. RELATED WORK

In the past decade, numerous IDSs were developed and evaluated against a range of published available datasets. Diverse review and comparative studies have been published tackling the design of IDS for various applications, as well as, the machine learning techniques used to build IDS, however, the dataset challenges are not discussed.

Current Network IDS surveys often focus on a single aspect of IDS evaluation. Buczak and Guven focus on the different ML and DL algorithms used to build IDS. They explain the different algorithms, mention their time complexity and list notable papers that employ each algorithm to IDS. Hodo et al. extend the ML discussion, the authors focus on the role that feature selection plays in the overall training and performance evaluation of ML techniques. An extensive discussion of features and how they impact the design and accuracy of IDS is plotted by Varma et al. . IDS characteristics are discussed by Debar et al. , as well as, Amer and Hamilton .

Hamed et al. presents an overview of IDS components, listing them as (a) pre-processing/feature extraction, (b) pattern analyzer, which involves knowledge representation and learning processes, and finally (c) decision making. They briefly discuss the benefits of each learning technique.

Additional IDS aspects are considered, for example, Amit et al. list the various problems and challenges involved with using ML in building IDSs.

The aforementioned manuscripts are further analyzed within Section III.

Other perspectives included in recent studies focus on a single network architecture. For example, Ismail Butun et al. discusses Wireless Sensor Networks (WSN), Zhou et al. highlights IDS in industrial process automation while Ghaffarian and Shahriari study ML and Data Mining (DM) techniques for software vulnerability.

While these surveys provide valuable information on the design and the accuracy, none provide a detailed overview of the shortcomings of available datasets nor do they provide information on tools used to carry out attacks. In this manuscript, we address these shortcomings and provide detailed complementary work to build datasets that reflect current network threats. This manuscript is complementary to prior surveys by highlighting the shortcomings of current datasets and the claims of numerous studies on their abilities to detect deprecated attacks.

III. IDS AND DATASETS SURVEY

In this section, prominent datasets are summarized, and their limitations are highlighted. Furthermore, recent IDSs are analyzed, discussing the algorithms used and the datasets the IDSs were evaluated against. Moreover, trends observed in the algorithms used by research over the past decade are discussed, highlighting a clear shift in the use of specific algorithms.

A. DATASETS

Researchers depended on benchmark datasets to evaluate their results. However, currently available datasets lack real-life characteristics of recent network traffic. This is the reason that made most of the anomaly IDSs not applicable for production environments . Furthermore, IDS is unable to adapt to constant changes in networks (i.e. new nodes, changing traffic loads, changing topology, etc.). Networks are constantly changing, for this reason depending solely on old datasets doesn't help the advancement of IDS. The process of generating new datasets should consider this constant change fact. For example, proposing a standard dataset generation platform with extendable functionality, would remove the burden of generating datasets from scratch and cope with concept drift in network patterns. This recommendation and others are further discussed in Section V.

Datasets could either be real (i.e. recorded from a network set-up) or synthetic (i.e. simulated or injected traffic). Synthetic attack injection could be used to either introduce attacks to an existing dataset or balance the attack classes present in a dataset. Viegas et al. mentioned that for a dataset to be considered, it has to cover the following properties. (a) Real network traffic (similar to production ones), (b) valid, such that it has complete scenarios. (c) Labeled, classifying each record as normal or attack, (d) variant, (e) correct, (f) can be updated easily. (g) Reproducible in order to give researchers space to compare across different datasets, and finally, (h) shareable, hence it should not contain any confidential data. Additionally, Sharafaldin et al. mentions that (i) having an appropriate documentation for the feature and dataset collection environment is an important aspect of IDS dataset. Cordero et al. adds (j) having high quality normal and (k) excluding any disturbance or defects as further requirements for evaluation datasets. Furthermore, for NIDS evaluation dataset, functional and non-functional requirements are elaborated in .

In this manuscript, we also identify two problems that impact research domains using datasets, whether they are synthetic or not. i) Sharing datasets is sometimes prohibited due to the data contained, hence, the research in the area is limited. ii) Simulating real-life scenarios and associated attacks is difficult due to the number of parameters required for the model to be viable. However, this manuscript provides a list of the most used and recent datasets. TABLE summarizes the available datasets and categorizes them based on the domain they belong to. Moreover, attacks found in each are presented. Extra remarks, including the publication year, institute and attack classes details are listed in TABLE . These datasets cover mobile applications, Virtual Private Networks (VPN), Tor Networks, IDS, Botnet, Network Flows and IoT. Some of the mentioned datasets are presented in . The evaluation includes DEF-CON , CAIDA , LBNL , CDX , Kyoto , Twente , UMASS and ADFA .

Ring et al. comprehensively overview of NIDS datasets covering their main features, data format, anonymity, size, availability, recording environment, balancing, etc. . . The authors list the datasets and their corresponding values in each of the aforementioned criteria, leaving the choice for researchers to make based on their use-case and scenario. On the contrary, Gharib et al. propose datasets score based on the attacks' coverage, protocols' coverage, metadata availability, anonymity, heterogeneity and labeling. While the authors evaluate attacks in the datasets and present a scientific comparison, the authors fail to provide a detailed analysis of the broader impact of their analysis.

Furthermore, due to the sparsity of the details supplementing the available datasets, the task of evaluating and ranking datasets would introduce unfair results. For example, a dataset that realistically represents background and attack traffic is better than a dataset that doesn't. However, there is no standard metric to evaluate how realistic the generation is, as well as, this information is not released with the dataset.

B. IDS AND ASSOCIATED DATASETS ANALYSIS

In this section, a survey of recent ML IDS is provided, analyzing the associated datasets, and their shortcomings. IEEE Xplore and Google Scholar queries were made using ''Intrusion Detection System*'' OR ''IDS*'' filtering the dates to include manuscripts published in the last decade. The filtration was made to have a wide coverage of datasets, ML techniques and detected attacks. A total of 85 published manuscripts in the period of are analyzed. Analysis of older IDS ML techniques and used features for the period 2004 -2007 was previously conducted by Nguyen and Armitage . They discuss the limitations of port-based and payload-based classification and the emerging use of ML techniques to classify IP traffic.

TABLE summarizes the pre-eminent (i.e., most cited) IDS research from the past decade. Each IDS is mentioned with a list of the algorithms used and the datasets that the IDS was evaluated against. Moreover, the attacks detected are also listed. The algorithmic trends are then discussed alongside the attacks included in the datasets used.

FIGURE shows the distribution of datasets used for research in the last decade. Only 11% of the mentioned IDSs used generated or simulated datasets. It is also clear through this analysis that most datasets lack real-life properties, which were previously mentioned in Section III-A. FIGURE 1 also highlights the use of KDD-99 as the dataset of choice. Amjad Al Tobi and Ishbel Duncan provide a comprehensive analysis of the drawbacks of the KDD'99 dataset. Moreover, Siddique et al. provide a timeline for KDD datasets family. The provided timeline show both the different criticism points and the UCI Lab warning not to use KDD Cup'99 dataset, which further emphasizes the drawbacks of using KDD Cup'99 in the current IDS research. The second most used dataset is the DARPA datasets. DARPA datasets fail to accurately represent current attacks due to their age. Moreover, the use of the KDD'99 and DARPA datasets lead to an endemic situation, numerous results reported in literature claim detection results which are not applicable in real-world scenarios. The shortcomings of the DARPA dataset are analyzed by M. Mahoney and P. Chan and John McHugh . Alongside the limitations of each dataset, they are also deprecated, hence, demonstrating the inability of the IDSs presented in

TABLE 2 to cope with the most recent attacks and threats. FIGURE 2. Covered attacks in discussed IDS (85 IDSs manuscripts listed in Table 2). FIGURE 2 visualizes the attacks detected by the different IDSs presented in TABLE 2. It is shown that the four attacks available in the KDD-99 dataset are the most covered, namely; DoS/DDoS, Probing, R2L, U2R. Moreover, only 12 attacks are listed in FIGURE which highlights potential limitations of these IDS to cope with the broad range of attacks and zero-day attacks. To tackle the detection of zero-day attacks, there is a need to build extendable datasets that could be used to train machine learning models used for anomaly detection. By employing extendable datasets and a standardized method for dataset generation, alongside the advancement in ML , , zero-day detection could be integrated into anomaly-based IDSs. Later in Section IV, our presented threat taxonomy highlights the percentage of attack coverage achieved by current IDSs.

To further analyze the last decade research on IDSs, it is important to consider the algorithms used. Anomaly-based IDSs are based on identifying patterns that define normal and abnormal traffic. These IDSs can be classified into subcategories based on the training method used as aforementioned in Section II. These categories are identified respectively as statistical, knowledge-based and ML based. Statistical includes univariate, multivariate and time series. Knowledge-based uses finite state machines and rules like case-based, n-based, expert systems and descriptor languages. ML algorithms include artificial neural networks, clustering, genetic algorithms, Deep Learning (DL), etc. FIGURE (a) highlights the dominance of ML algorithms employed when building an IDS. As shown, both statistical and knowledge-based algorithms are less represented. This dominance is due to the significant use of ML techniques in various research domains. FIGURE (a) is organized by categories (Inner Circle), subcategories (Centre Circle) and finally, the percentage of the IDSs presented in TABLE 2 using these algorithms (Outer Circle). FIGURE 3 (b) on the other hand, provides a visualization of the distribution of the algorithms used by the IDSs presented in TABLE 2. The dominance of ANN, SVM and k-means as the most used algorithms is reasoned by their ability to discriminate between FIGURE 3. Algorithms usage distribution in the discussed IDS (85 IDSs manuscripts listed in Table 2) Such that: AdaBoost: Adaptive Boosting AIS: Artificial Immune System ANN: Artificial Neural Network CNN: Convolutional Neural Network CUSUM: Cumulative Sum FSM: Finite State Machine GA: Genetic Algorithms k-NN: k-Nearest Neighbors ML: Machine Learning PCA: Principal Component Analysis PSO: Particle Swarm Optimization RNN: Recurrent Neural Network SOM: Self-Organizing Map SVM: Support Vector Machine.

benign and attack classes given a feature set. However, it is important to mention that leveraging new ML techniques and adapting ones from other domains will advance the development of the next decade's IDSs.

IV. THREATS TAXONOMY

Building a generic and modular taxonomy for security threats is of high importance in order to help researchers and cyber-security practitioners build tools capable of detecting various attacks ranging from known to zero-day attacks.

Kendall et al. proposes one of the earliest classifications of intrusions . Kendall classifies intrusions into four categories namely: Denial of Service (DoS), Remote to Local (R2L), User to Root (U2R) and Probing. In DoS, the attacker tends to prevent users from accessing a given service. When the attacker tried to gain authorized access to the target system, either by gaining local access or promoting the user to a root user, these attacks were classified as R2L and U2R respectively. Finally, probing was defined as an attacker actively footprinting a system for vulnerabilities. Donald Welch classifies common threats in wireless networks into seven attack techniques (Traffic Analysis, Passive Eavesdropping, Active Eavesdropping, Unauthorized Access, Man-in-the-middle, Session Hijacking and Replay) . In a paper by Sachin Babar et al. , the problem is addressed from a different perspective. Threats are classified according to the Internet of things security requirements (identification, communication, physical threat, embedded security and storage management). Specific domain taxonomies have also grabbed the attention of researchers. David Kotz discusses privacy threats in the mobile health (mHealth) domain. In the same manner, Keshnee Padayachee , shows the security threats targeting compliant information and Monjur Ahmed and Alan T. Litchfield works on threats from a cloud computing point of view.

This section classifies network threats based on the layers of the OSI model, provides examples of attacks for different threat types and presents a taxonomy associating network threats and the tools used to carry out attacks. The taxonomies aim at helping researchers building IDSs, but more importantly by associating the threats to the OSI model and benchmarking the threats to the tools used to carry attack or take advantage of specific vulnerabilities, the taxonomies aim to achieve higher accuracies and reduce the number of false positives of current IDS and build better datasets. As shown, attacks can target a single layer of the OSI model, but it is important to highlight that other layers may also be affected. The taxonomy presented in this manuscript focuses on the main target layer of attack. An attack is also described to be active if it affects information, performance, VOLUME 8, 2020 104658 VOLUME 8, 2020 VOLUME 8, 2020

A. THREAT SOURCES

or any aspect of the media on which it is running. In contrast to active attacks, during passive attacks the attacker is concerned with either gathering information or monitoring the network. These can be identified by their shape in FIGURE . Active attacks are represented by a rectangle shape, whilst passive attacks are represented by an oval shape. Attacks like adware (FIGURE 2) are forms of active attacks. However, some attacks cannot be considered active or passive until their usage is known. An example of this case is SQL-injection, if it is used for querying data from a database then it is passive. However, if it is used to alter data, drop tables or relations then the attack can be considered as active.

1) NETWORK THREATS

Threats are initiated based on a flow of packets sent over a network. Two of the most common forms of network threats are Denial of Service (DoS) and Distributed Denial of Service (DDoS) (FIGURE .1), where an attacker floods the network with requests rendering the service unresponsive. During these attacks, legitimate users cannot access the services. Note that common anomalies known as 'Flash Crowds' are often mistaken with DoS and DDoS attacks . Flash Crowds happen when a high flow of traffic for a certain service or website occurs. This happens immediately upon the occurrence of a significant event. For example, breaking news, sales events, etc. DoS and DDoS can be divided into four categories including flood attacks (FIGURE Packet forging (FIGURE 4 -1.2) is another form of networking attack. Packet forging or injection is the action where the attacker generates packets that look the same as normal network traffic. These packets can be used to perform unauthorized actions and steal sensitive data like: login credentials, personal data, credit card details, Social Security Numbers (SSN) numbers, etc. When the attacker passively monitors or intercepts communications between two or more entities and starts to control the communication, this attack is referred to as a 'Man in the Middle' attack (FIGURE 4 -1.3). Unlike 'Man in the Middle' attack, a 'Man In The Browser' attack intercepts the browser to alter or add fields to a web page asking the user to enter confidential data. Impersonation (FIGURE 4 -1.5) or pretending to be another user can take different forms. The attacker may impersonate a user to gain higher security level and gain access to unauthorized data (FIGURE Scanning/enumeration are an essential step for initiating attacks. During scanning (FIGURE 4 -1.6), the attacker starts with searching the network for information such as: active nodes, running operating systems, software versions, etc. As defined in , scanning has many forms, using protocols such as TCP (FIGURE

2) HOST THREATS

Host attacks target specific hosts or systems by running malicious software to compromise or corrupt system functionalities. Most host attacks are categorized under the malware (FIGURE .1) category. This includes worms, viruses, adware, spyware, Trojans and ransomware. Viruses are known to affect programs and files when shared with other users on the network, whilst worms are known to self-replicate and affect multiple systems. Adware is known for showing advertisements to users when surfing the Internet or installing software. Although adware is less likely to run malicious code, it can compromise the performance of a system. Spyware gathers information such as documents, user cookies, browsing history, emails, etc. or monitors and tracks user actions. Trojans often look like trusted applications, but allow an attacker to control a device. Furthermore, camouflage malware (FIGURE 4 -2.1.7) evolved over time reaching polymorphic and metamorphic techniques in 1990 and 1998 respectively , . For example, self-mutating malware could use numerous techniques, such as, instruction substitution or permutation, garbage insertion, variable substitutions and control-flow alteration . Last, ransomware is a relatively new type of malware where the system is kept under the control of the attacker -or a third entityby encrypting files until the user/organization pays a ransom .

3) SOFTWARE THREATS

Code injection (FIGURE 4 -3.2) can include SQL Injection to query a database, resulting in obtaining confidential data, or deleting data by dropping columns, rows or tables. Cross-site scripting (XSS) is used to run malicious code to steal cookies or credentials. XSS has three main categories. The first is persistent/stored XSS (FIGURE 4 -3.2.2.1), in this case, a script is saved to a database and is executed every time the page is loaded. The second is Reflected XSS (FIGURE 4 -3.2.2.2), where the script is part of a HTTP request sent to the server. The last is DOM-based XSS (FIGURE 4 -3.2.2.3) which can be considered as an advanced type of XSS. The attacker changes values in the Document Object Model (DOM) e.g. document location, document URL, etc. DOM-based XSS is difficult to detect as the script is never transferred to the server. Driveby or download (FIGURE 4-3.6) is another software threat that requires no action from the user, however, the malicious code is automatically downloaded. It contributed to 48% of all web-based attacks in 2017 , and is considered one of the main threats in 2019 . Fingerprinting (FIGURE 4 -3.3) and misconfiguration are also forms of software threats. Fake server certificates (FIGURE 4 -3.5) are considered alarming and should be considered while analyzing communications as they could deceive the browser/user thinking that the connection is secure. This could result in phishing websites looking legitimate. Moreover, they could be used as a seed to perform other attacks like Man-in-the-Middle.

4) PHYSICAL THREATS

Physical attacks are a result of a tempering attempt on the network hardware (edge, or other devices) or its configuration. This can include changing configurations (FIGURE 4 -4.2) and introducing backdoors (i.e. The Evil Maid).

5) HUMAN THREATS

The last category of networking attacks is one based on human actions. These include user masquerade (FIGURE 4 -5.1). Phishing is another form of human attacks where the attacker uses emails or other electronic messaging services to obtain credentials or confidential data. When a user attempts to obtain higher privileges, it is considered a human attack like User to Root (FIGURE 4 -5.3) and Remote to Local R2L (FIGURE . Additionally, a user can be denied an action such as repudiation attack (FIGURE 4 -5.5). Human attacks can also include session hijacking or sniffing, these attacks are based on the attacker gaining access over an active session to access cookies and tokens.

Based on the taxonomy discussed in FIGURE and the recent IDSs discussed in Section III-B, it can be seen that there are many threats that are not addressed by recent IDSs. FIGURE visualizes all the threats mentioned in the taxonomy. The associated percentage represents attacks covered by the IDSs discussed in TABLE . As shown a large number of attacks (72%) are not covered. Hence, the network threat taxonomy aims at addressing the following:

• Help researchers generate datasets that cover nonaddressed attacks.

• Provide an up-to-date taxonomy of attacks allowing to measure threats covered by datasets and the ability of IDSs to detect these threats

• Provide a structured way to address and represent threats and attacks.

B. ATTACKING TOOLS

Many tools , have been developed to initiate different attacks. FIGURE shows the main tools classified by the attacks they are used for. This can be used by researchers when building an IDS for a specific threat, then the associated tools are ones of interest. For example, for an IDS classifying impersonation attacks, Caffe-Latte, Hirte, EvilTwin and Cain and Abel are tools to check. Yaga and SQL attacks are tools used for U2R and so on.

V. CHALLENGES AND RECOMMENDATIONS

In this section, our findings are outlined based on the discussion in Section III and Section IV. A list of limitations is reviewed then the recommendations are listed.

A. LIMITATIONS AND CHALLENGES

The limitations and challenges in datasets used in IDSs can be summarized in the following:

• Attacks Coverage: As shown in this work only 33.3% of known attacks are covered in publicly available datasets reviewed. This is considered one of the biggest challenges preventing IDSs to be used in real-life environments.

• Real-life Simulation: Only 11% of the past decade IDSs use recent and/or real-life generated or simulated datasets. This demonstrates a flaw in the development of IDSs but highlights their limited ability to cope with the emerging needs.

• Zero-Day Attacks Handling: Attacks evolve at a pace that datasets are not currently coping with. New dataset generation techniques are needed. If the process of generating datasets and making them publicly available is made more efficient, IDS models can be quickly updated and re-trained to cope with the changes.

• Special Purpose Datasets: There are a limited number of available datasets serving special purpose IDSs. For example, publicly available datasets for IoT, SCADA and Tor networks are currently insufficient.

• Dataset Outlook: Rapid advances in networking and associated technologies require a shift in dataset VOLUME 8, 2020 generation paradigm. Emerging technologies, such as Blockchain, Software Defined Network (SDN), Network Function Virtualisation (NFV), Big-Data, and their associated threats are currently not covered within available datasets. Yielding the dataset generation following trends in technologies [91]-[93].

B. RECOMMENDATIONS

Guided by the critical impact of datasets on the evolvement of IDSs and the importance of robust and accurate IDS models, the following recommendations help build the next generation IDSs. The research direction should focus equally on building complex models for IDSs and gathering/generating data that represent benign and attack scenarios accurately. This will result in IDSs suitable for real-life deployments.

• ML-First Vs Data-First: As discussed in Section III-A, obtaining valid, representative, and accurate data should be considered as the primary focus of research for the creation of IDSs. Building IDSs based on skewed and biased data only produces models unfit for exploitation, hence, Data-First models must be considered before ML-First.

• Using precise evaluation metrics: As discussed in Section II, metrics -other than accuracy -should be considered to precisely reflect an IDS performance. For example, FP and Recall should be reported.

Furthermore, the geometric mean should be used with imbalanced datasets, as well as, networking metrics such as throughput. Conventional ML models report loss and accuracy by default unless other parameters are defined.

Relying on the recorded loss and accuracy without measuring proposed evaluation metrics may result in misleading assessments of the overall IDS efficiency.

• Introduce modular and extendable datasets: As aforementioned, special purpose datasets are demanded, either to cover bespoke networks and architectures (e.g. IoT, SCADA, Tor, etc.) or to introduce new and zero-day attacks. To increase the impact of datasets, they are required to be easily extendable and capable of integrating with other datasets. As a result, datasets would be adaptable to the continuous network changes. Also, dataset generation could be rendered in the IDS pipeline, therefore, not requiring the generation of a new dataset with every introduced change. To this end, anomaly based IDSs could be trained to use advanced ML techniques to identify new and zero-day attacks.

• Standardize attack dataset generation/collection method: One of the main challenges forcing researchers to work with outdated datasets is the lack of documentation associated with newly available datasets. Moreover, publishing raw packet data, not only the computed features, is needed to expand the use of datasets. One of the VOLUME 8, 2020

ways to generate datasets relies on α (using descriptive language to describe attacks) and β (using behavior and statistical measures to describe attacks) profiles, as described by Shiravi et al. . Ring et al. recommends being careful with anonymization and choosing which fields to be discarded.

Privacy is depicted as one of the main obstacles against the collection of new attacks data. Furthermore, the lack of standard tools for data collection, anonymization, documentation and publication demand researchers to use their own tailored methods.

• Introduce models to inject realistic attacks: Flow-Level Anomaly Modeling Engine FLAME was one of the first tools to inject attacks that leave traces into network flows. ID2T , , is a proposed flexible model to inject scenarios to existing datasets. The absence of thorough documentation of datasets makes it harder to map one dataset to another, rendering it impractical to add new attacks to existing datasets. Moreover, assuming that there exists a standard method to export realistic traffic, there isn't enough information about how to inject newly collected data to existing ones. Furthermore, the existing traffic injection proposals are limited to a single usage/prototype.

• Generated dataset resilience: To ensure dataset resilience, variations of the dataset should be generated. This could include variation of attack scenarios, different attacks, diverse benign traffic load (different time of day load). This, with other measures, would guarantee an extended dataset lifetime. Moreover, the complexity of dataset variation generation should be kept minimal.

It is key for a dataset to be provided in a raw state to allow researchers to make a choice between using stateless or stateful analysis. If a dataset is provided only in a pre-processed form, researchers may lose the ability to use stateless or stateful detection methods and hinder the detection and accuracy of their algorithms.

• Leveraging network monitoring to create real traffic: Since most of the available benchmark datasets lack real-life properties, new datasets generation should benefit from network monitoring to generate realistic background traffic . Furthermore, if real traffic could not be included in the dataset due to privacy concerns, real traffic should act as the ground truth for further traffic generation/simulation. Moreover, for special purpose networks, relying on released IoT/Critical infrastructure network architecture case studies should act as a guidance for network simulation. This should reduce the gap in terms of accurate realistic datasets. Different validation approaches should be used for IDS, however, with the advancement of IDS research, realistic experiments should be the main focus as demonstrated in .

• Dataset Validation: Newly generated datasets should be validated based on network traffic validation techniques. Molnár et al. list the various metrics that could be used for this purpose. Furthermore, the similarities between real and synthetic traffic should also be evaluated as proposed in , .

• Updated Threats Taxonomy: The networking threat taxonomy presented at this work aims at helping create datasets that cover a wider range of attacks. Maintaining the taxonomy in a timely manner will keep it an up-to-date reference for future IDSs research. Furthermore, the taxonomy is made available for public contribution through a GitHub repository to encourage contributions from other researchers to extend, revise and update it. While these recommendations might appear trivial at first, the majority of recent and old datasets proposed online do not conform to these guidelines as demonstrated within the previous sections. Hence, through this section, we provided recommendations for future datasets to follow ensuring the creation/generation of usable/accurate datasets.

VI. CONCLUSION

This research aims at tackling the problem of having a generic taxonomy for network threats. A proposed taxonomy is presented for categorizing network attacks based on the source, OSI model layer and whether the threat is active or passive. The prominent IDS research over the past decade (2008 -2020) is analyzed. The analysis results in three main findings. First, benchmark datasets lack real-world properties and fail to cope with constant changes in attacks and network architectures, thus, limiting the performance of IDS. Second, we present a taxonomy of tools and associated attacks, and demonstrate that current IDS research only covers around 33.3% of threats presented in the taxonomy. Third, we highlight that -whilst ML is used by 97.25% of the examined IDS -ANN, k-means and SVM represent the majority of the algorithms used. While these algorithms present outstanding results, we also highlight that these results are obtained on outdated datasets and, therefore, not representative of real-world architectures and attack scenarios.

Finally, the network threat taxonomy and the attacks and associated tool taxonomy are open-sourced and available through GitHub, allowing both security and academic researchers to contribute to the taxonomy and ensure its relevance in the future.

TABLE 2. Over a decade of intrusion detection systems (2008 -2020). VOLUME 8, 2020

I. INTRODUCTION The world is becoming more dependent on connected devices, actuators and sensors, regulating the lives of millions of people. Furthermore, sensor data is expected to increase by around 13%, reaching 35% of overall data communication in 2020, reaching a peak of 50 billion connected devices and an increased monthly Internet traffic volume reaching 30 GB on average per capita compared to around 10 GB in 2016 . While each device in an Internet of Things (IoT) system exchanges data, associated services often provide interfaces to interact with the collected data, often increasing the attack The associate editor coordinating the review of this manuscript and approving it for publication was Xiaofan surface. Therefore, it is crucial to build robust tools to defend networks against security threats in modern IoT networks. Current detection tools are often based on outdated datasets that do not reflect the reality of recent/modern network attacks, rendering Intrusion Detection Systems (IDS) ineffective against new threats and zero-days. To the best knowledge of the authors, there are currently no manuscripts that analyze the shortcomings of available networking datasets, nor provide a taxonomy of the current network threats and the associated tools used to carry out these attacks. The contributions of this research are threefold: • An evaluation of the limitations of the available network-based datasets and their impact on the development of IDSs • A review of the last decade's research on NIDS • A Threat taxonomy is presented, and categorized by: -The Threat Sources -The Open Systems Interconnection (OSI) Layer -Active or Passive modes The evaluation of current network-based datasets provides researchers with an insight of the shortcomings of the datasets presented when used for training against real-world threats. A threat taxonomy is derived from the datasets and current real-world networking threats. This taxonomy serves two purposes-firstly, it strengthens our argument on the shortcomings of currently available datasets, but most importantly, it provides researchers with the ability to identify threats and tools underrepresented in currently available datasets. To facilitate this endeavor, we further map the current threats with their associated tools, which in turn can be used by research to create new datasets. The rest of the paper is organized as follows; Section II depicts the main differences between IDSs, the metrics to consider for their evaluation and the role of feature selection in building IDSs. Section III reviews IDSs of the past decade and their individual contributions are assessed. This section also evaluates the drawbacks and limitations of the available datasets. Section IV provides the threat taxonomy. Section V summarizes the challenges presented in this work and provides recommendations. Finally, the paper is concluded in Section VI.

II. BACKGROUND A. INTRUSION DETECTION SYSTEMS IDSs are defined as systems built to monitor and analyze network traffic and/or systems to detect anomalies, intrusions or privacy violations. When an intrusion is detected, an IDS is expected to (a) log the information related to the intrusion, (b) trigger alerts and (c) take mitigation and corrective actions . IDS can either be Host Intrusion Detection System (HIDS) or Network Intrusion Detection System (NIDS). HIDS is responsible for monitoring a system internally, having access to log files, users' activities, etc. While NIDS analyses incoming and outgoing communication between network nodes. IDSs differ based on their detection method. Signaturebased IDSs were the first to be developed. Accurate signatures are built from prior detected attacks. The main advantage of this method is the high accuracy of detecting known attacks. Signature-based IDS is, however, unable to detect zero-days, metamorphic and polymorphic threats . The second method, Anomaly-based detection, depends on identifying patterns and comparing them to normal traffic patterns. This method requires the system to be trained prior to deployment. The accuracy of anomaly-based systems against zero-days, metamorphic and polymorphic threats is better when compared to signature-based IDS. However, the false positive rate of anomaly-based detection is often higher. It is important to mention that benign/normal traffic patterns alone are not sufficient to detect attacks. For this reason, the features used to represent network traffic play an essential role in traffic representation. Intrusion detection (both signature-based and anomalybased) can be done on a stateless (per packet) or stateful (per flow) basis. Most recent IDSs are stateful, as the flow provides ''context'', while packet analysis (stateless) does not provide this context. It is the responsibility of the researcher to decide which method is best suited for their application. Anomaly-based IDS can be classified into subcategories based on the training method used. These categories are statistical, knowledge-based and Machine Learning (ML) based. Statistical includes univariate, multivariate and time series. Knowledge-based uses finite state machines and rules like case-based, N-based, expert systems and descriptor languages. Buczak and Guven provide recommendations on choosing the ML/Deep Learning (DL) algorithms based on the problem intended to be solved. Algorithms include Artificial Neural Networks (ANN), clustering, Genetic Algorithms (GA), etc. Specification-based combines the strength of both signature and anomaly based to form a hybrid model. Owezarski et al. summarize the approaches to validate networking models, which applies to IDS, into four categories; mathematical models, simulation, emulation and real experiments. Each of these approaches has their own pros and cons as discussed by Behal and Kumar .

1) METRICS FOR IDS EVALUATION In order for an IDS to be considered effective, high detection rate and low false positive rate are key aspects to consider. Multiple metrics could be used for an IDS evaluation. These metrics are discussed subsequently showing the significance and purpose of each. It is important to mention that depending only on detection rate as the only evaluation metric doesn't reflect an IDS performance. Other important evaluation factors including the transparency and safety of the overall system, memory requirements, power consumption and throughput should be considered. Moreover, adds to the aforementioned requirements, ease of use, interoperability, transparency and collaboration. IDS accuracy can be defined in terms of: • True Positive (TP): Number of intrusions correctly detected • True Negative (TN): Number of non-intrusions correctly detected • False Positive (FP): Number of non-intrusions incorrectly detected • False Negative (FN): Number of intrusions incorrectly detected Hodo et al. , Buse et al. and Aminanto et al. discuss the main metrics to consider for evaluation in their respective work. These include the overall accuracy, decision rates, precision, recall, F1 and Mcc. Equation 1 provides the overall accuracy. It returns the probability that an item is correctly classified by the IDS. Equation 2 calculates the Sensitivity, Specificity, Fallout, and Miss Rate detection rates, respectively. Stefan Axelsson stresses the fact that false positive rates (false alarms) highly limit the performance of an IDS due to the ''Base-rate fallacy problem''. Detection Rates: Sensitivity(aka Recall, True Positive Rate) = TP TP + FN Specificity (aka Selectivity, True Negative Rate) = TN TN + FP Fallout(aka False Positive Rate) = FP TN + FP Miss Rate(aka False Negative Rate) = FN TP + FN (2) Equation 3 provides the percentage of positively classified incidents that are truly positive. Precision = TP TP + FP (3) To visualize the performance of an IDS, i.e. the trade-off between sensitivity (true positive rate) and fallout (true negative rate), AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) also known as Area Under the Receiver Operating Characteristics (AUROC) curve is used [11]-[13] Equation 4 represents the harmonic mean of precision and recall. F1 is better suited to represent the performance of an IDS, specially when dealing with imbalanced classes. F1 = 2TP 2TP + FP + FN (4) Equation 5 provides Matthews correlation coefficient. It can only be used in binary IDS in which incidents are classified as either attack or normal. Mcc = (TP * TN ) -(FP * FN ) √ (TP + FP)(TP + FN )(TN + FP)(TN +FN ) Equation 6 addresses the problem of calculating accuracy in imbalanced datasets. Numerous datasets have a limited number of attacks' data compared to benign traffic, hence, the geometric mean of accuracy provides a more precise metric than overall accuracy measure . Space-Time aware evaluation is introduced by Feargus Pendlebury et al. to overcome both spatial and temporal biases. The authors introduced three constraints to be considered when splitting datasets. gAcc = √ a +ve .a -ve = Sensitivity (TPR) .Specificity (TNR) Additionally, CPU consumption, throughput and power consumption are important metrics for evaluating IDSs. Specifically, these metrics are important for IDSs running on different hardware or with specific settings such as high-speed networks, or on hardware with limited resources.

2) FEATURE SELECTION AND IDS ''Feature Learning'' or ''Feature Engineering'' plays an essential role in building any IDS in a way that chosen features highly affect the IDS performance. Features are obtained using one of three processes; construction, extraction and selection. Selection involves filter, wrapper and embedded techniques . A classification of the features used in recent datasets is provided in . Different features representations (i.e. abstractions) are used to address different areas of threat detection. Some of them could be considered naïve when they contain basic network information. Others are considered rich when they represent deeper details . As highlighted by Rezaei and Liu , there are four main categories of networking features; time series, header, payload and statistical. Unlike header and payload features, time series and statistical ones are available for both encrypted and unencrypted traffic. The authors further discuss the shortcomings of current encrypted traffic classification research. Packet-based and flow-based features have been used for intrusion detection purposes. However, with the advancement of network encryption, packet-based features are rendered impractical for complex communication networks.

B. RELATED WORK In the past decade, numerous IDSs were developed and evaluated against a range of published available datasets. Diverse review and comparative studies have been published tackling the design of IDS for various applications, as well as, the machine learning techniques used to build IDS, however, the dataset challenges are not discussed. Current Network IDS surveys often focus on a single aspect of IDS evaluation. Buczak and Guven focus on the different ML and DL algorithms used to build IDS. They explain the different algorithms, mention their time complexity and list notable papers that employ each algorithm to IDS. Hodo et al. extend the ML discussion, the authors focus on the role that feature selection plays in the overall training and performance evaluation of ML techniques. An extensive discussion of features and how they impact the design and accuracy of IDS is plotted by Varma et al. . IDS characteristics are discussed by Debar et al. , as well as, Amer and Hamilton . Hamed et al. presents an overview of IDS components, listing them as (a) pre-processing/feature extraction, (b) pattern analyzer, which involves knowledge representation and learning processes, and finally (c) decision making. They briefly discuss the benefits of each learning technique. Additional IDS aspects are considered, for example, Amit et al. list the various problems and challenges involved with using ML in building IDSs. The aforementioned manuscripts are further analyzed within Section III. Other perspectives included in recent studies focus on a single network architecture. For example, Ismail Butun et al. discusses Wireless Sensor Networks (WSN), Zhou et al. highlights IDS in industrial process automation while Ghaffarian and Shahriari study ML and Data Mining (DM) techniques for software vulnerability. While these surveys provide valuable information on the design and the accuracy, none provide a detailed overview of the shortcomings of available datasets nor do they provide information on tools used to carry out attacks. In this manuscript, we address these shortcomings and provide detailed complementary work to build datasets that reflect current network threats. This manuscript is complementary to prior surveys by highlighting the shortcomings of current datasets and the claims of numerous studies on their abilities to detect deprecated attacks.

III. IDS AND DATASETS SURVEY In this section, prominent datasets are summarized, and their limitations are highlighted. Furthermore, recent IDSs are analyzed, discussing the algorithms used and the datasets the IDSs were evaluated against. Moreover, trends observed in the algorithms used by research over the past decade are discussed, highlighting a clear shift in the use of specific algorithms.

A. DATASETS Researchers depended on benchmark datasets to evaluate their results. However, currently available datasets lack real-life characteristics of recent network traffic. This is the reason that made most of the anomaly IDSs not applicable for production environments . Furthermore, IDS is unable to adapt to constant changes in networks (i.e. new nodes, changing traffic loads, changing topology, etc.). Networks are constantly changing, for this reason depending solely on old datasets doesn't help the advancement of IDS. The process of generating new datasets should consider this constant change fact. For example, proposing a standard dataset generation platform with extendable functionality, would remove the burden of generating datasets from scratch and cope with concept drift in network patterns. This recommendation and others are further discussed in Section V. Datasets could either be real (i.e. recorded from a network set-up) or synthetic (i.e. simulated or injected traffic). Synthetic attack injection could be used to either introduce attacks to an existing dataset or balance the attack classes present in a dataset. Viegas et al. mentioned that for a dataset to be considered, it has to cover the following properties. (a) Real network traffic (similar to production ones), (b) valid, such that it has complete scenarios. (c) Labeled, classifying each record as normal or attack, (d) variant, (e) correct, (f) can be updated easily. (g) Reproducible in order to give researchers space to compare across different datasets, and finally, (h) shareable, hence it should not contain any confidential data. Additionally, Sharafaldin et al. mentions that (i) having an appropriate documentation for the feature and dataset collection environment is an important aspect of IDS dataset. Cordero et al. adds (j) having high quality normal and (k) excluding any disturbance or defects as further requirements for evaluation datasets. Furthermore, for NIDS evaluation dataset, functional and non-functional requirements are elaborated in . In this manuscript, we also identify two problems that impact research domains using datasets, whether they are synthetic or not. i) Sharing datasets is sometimes prohibited due to the data contained, hence, the research in the area is limited. ii) Simulating real-life scenarios and associated attacks is difficult due to the number of parameters required for the model to be viable. However, this manuscript provides a list of the most used and recent datasets. TABLE summarizes the available datasets and categorizes them based on the domain they belong to. Moreover, attacks found in each are presented. Extra remarks, including the publication year, institute and attack classes details are listed in TABLE . These datasets cover mobile applications, Virtual Private Networks (VPN), Tor Networks, IDS, Botnet, Network Flows and IoT. Some of the mentioned datasets are presented in . The evaluation includes DEF-CON , CAIDA , LBNL , CDX , Kyoto , Twente , UMASS and ADFA . Ring et al. comprehensively overview of NIDS datasets covering their main features, data format, anonymity, size, availability, recording environment, balancing, etc. . . The authors list the datasets and their corresponding values in each of the aforementioned criteria, leaving the choice for researchers to make based on their use-case and scenario. On the contrary, Gharib et al. propose datasets score based on the attacks' coverage, protocols' coverage, metadata availability, anonymity, heterogeneity and labeling. While the authors evaluate attacks in the datasets and present a scientific comparison, the authors fail to provide a detailed analysis of the broader impact of their analysis. Furthermore, due to the sparsity of the details supplementing the available datasets, the task of evaluating and ranking datasets would introduce unfair results. For example, a dataset that realistically represents background and attack traffic is better than a dataset that doesn't. However, there is no standard metric to evaluate how realistic the generation is, as well as, this information is not released with the dataset.

B. IDS AND ASSOCIATED DATASETS ANALYSIS In this section, a survey of recent ML IDS is provided, analyzing the associated datasets, and their shortcomings. IEEE Xplore and Google Scholar queries were made using ''Intrusion Detection System*'' OR ''IDS*'' filtering the dates to include manuscripts published in the last decade. The filtration was made to have a wide coverage of datasets, ML techniques and detected attacks. A total of 85 published manuscripts in the period of are analyzed. Analysis of older IDS ML techniques and used features for the period 2004 -2007 was previously conducted by Nguyen and Armitage . They discuss the limitations of port-based and payload-based classification and the emerging use of ML techniques to classify IP traffic. TABLE summarizes the pre-eminent (i.e., most cited) IDS research from the past decade. Each IDS is mentioned with a list of the algorithms used and the datasets that the IDS was evaluated against. Moreover, the attacks detected are also listed. The algorithmic trends are then discussed alongside the attacks included in the datasets used. FIGURE shows the distribution of datasets used for research in the last decade. Only 11% of the mentioned IDSs used generated or simulated datasets. It is also clear through this analysis that most datasets lack real-life properties, which were previously mentioned in Section III-A. FIGURE 1 also highlights the use of KDD-99 as the dataset of choice. Amjad Al Tobi and Ishbel Duncan provide a comprehensive analysis of the drawbacks of the KDD'99 dataset. Moreover, Siddique et al. provide a timeline for KDD datasets family. The provided timeline show both the different criticism points and the UCI Lab warning not to use KDD Cup'99 dataset, which further emphasizes the drawbacks of using KDD Cup'99 in the current IDS research. The second most used dataset is the DARPA datasets. DARPA datasets fail to accurately represent current attacks due to their age. Moreover, the use of the KDD'99 and DARPA datasets lead to an endemic situation, numerous results reported in literature claim detection results which are not applicable in real-world scenarios. The shortcomings of the DARPA dataset are analyzed by M. Mahoney and P. Chan and John McHugh . Alongside the limitations of each dataset, they are also deprecated, hence, demonstrating the inability of the IDSs presented in TABLE 2 to cope with the most recent attacks and threats. FIGURE 2. Covered attacks in discussed IDS (85 IDSs manuscripts listed in Table 2). FIGURE 2 visualizes the attacks detected by the different IDSs presented in TABLE 2. It is shown that the four attacks available in the KDD-99 dataset are the most covered, namely; DoS/DDoS, Probing, R2L, U2R. Moreover, only 12 attacks are listed in FIGURE which highlights potential limitations of these IDS to cope with the broad range of attacks and zero-day attacks. To tackle the detection of zero-day attacks, there is a need to build extendable datasets that could be used to train machine learning models used for anomaly detection. By employing extendable datasets and a standardized method for dataset generation, alongside the advancement in ML , , zero-day detection could be integrated into anomaly-based IDSs. Later in Section IV, our presented threat taxonomy highlights the percentage of attack coverage achieved by current IDSs. To further analyze the last decade research on IDSs, it is important to consider the algorithms used. Anomaly-based IDSs are based on identifying patterns that define normal and abnormal traffic. These IDSs can be classified into subcategories based on the training method used as aforementioned in Section II. These categories are identified respectively as statistical, knowledge-based and ML based. Statistical includes univariate, multivariate and time series. Knowledge-based uses finite state machines and rules like case-based, n-based, expert systems and descriptor languages. ML algorithms include artificial neural networks, clustering, genetic algorithms, Deep Learning (DL), etc. FIGURE (a) highlights the dominance of ML algorithms employed when building an IDS. As shown, both statistical and knowledge-based algorithms are less represented. This dominance is due to the significant use of ML techniques in various research domains. FIGURE (a) is organized by categories (Inner Circle), subcategories (Centre Circle) and finally, the percentage of the IDSs presented in TABLE 2 using these algorithms (Outer Circle). FIGURE 3 (b) on the other hand, provides a visualization of the distribution of the algorithms used by the IDSs presented in TABLE 2. The dominance of ANN, SVM and k-means as the most used algorithms is reasoned by their ability to discriminate between FIGURE 3. Algorithms usage distribution in the discussed IDS (85 IDSs manuscripts listed in Table 2) Such that: AdaBoost: Adaptive Boosting AIS: Artificial Immune System ANN: Artificial Neural Network CNN: Convolutional Neural Network CUSUM: Cumulative Sum FSM: Finite State Machine GA: Genetic Algorithms k-NN: k-Nearest Neighbors ML: Machine Learning PCA: Principal Component Analysis PSO: Particle Swarm Optimization RNN: Recurrent Neural Network SOM: Self-Organizing Map SVM: Support Vector Machine. benign and attack classes given a feature set. However, it is important to mention that leveraging new ML techniques and adapting ones from other domains will advance the development of the next decade's IDSs.

IV. THREATS TAXONOMY Building a generic and modular taxonomy for security threats is of high importance in order to help researchers and cyber-security practitioners build tools capable of detecting various attacks ranging from known to zero-day attacks. Kendall et al. proposes one of the earliest classifications of intrusions . Kendall classifies intrusions into four categories namely: Denial of Service (DoS), Remote to Local (R2L), User to Root (U2R) and Probing. In DoS, the attacker tends to prevent users from accessing a given service. When the attacker tried to gain authorized access to the target system, either by gaining local access or promoting the user to a root user, these attacks were classified as R2L and U2R respectively. Finally, probing was defined as an attacker actively footprinting a system for vulnerabilities. Donald Welch classifies common threats in wireless networks into seven attack techniques (Traffic Analysis, Passive Eavesdropping, Active Eavesdropping, Unauthorized Access, Man-in-the-middle, Session Hijacking and Replay) . In a paper by Sachin Babar et al. , the problem is addressed from a different perspective. Threats are classified according to the Internet of things security requirements (identification, communication, physical threat, embedded security and storage management). Specific domain taxonomies have also grabbed the attention of researchers. David Kotz discusses privacy threats in the mobile health (mHealth) domain. In the same manner, Keshnee Padayachee , shows the security threats targeting compliant information and Monjur Ahmed and Alan T. Litchfield works on threats from a cloud computing point of view. This section classifies network threats based on the layers of the OSI model, provides examples of attacks for different threat types and presents a taxonomy associating network threats and the tools used to carry out attacks. The taxonomies aim at helping researchers building IDSs, but more importantly by associating the threats to the OSI model and benchmarking the threats to the tools used to carry attack or take advantage of specific vulnerabilities, the taxonomies aim to achieve higher accuracies and reduce the number of false positives of current IDS and build better datasets. As shown, attacks can target a single layer of the OSI model, but it is important to highlight that other layers may also be affected. The taxonomy presented in this manuscript focuses on the main target layer of attack. An attack is also described to be active if it affects information, performance, VOLUME 8, 2020 104658 VOLUME 8, 2020 VOLUME 8, 2020

A. THREAT SOURCES or any aspect of the media on which it is running. In contrast to active attacks, during passive attacks the attacker is concerned with either gathering information or monitoring the network. These can be identified by their shape in FIGURE . Active attacks are represented by a rectangle shape, whilst passive attacks are represented by an oval shape. Attacks like adware (FIGURE 2) are forms of active attacks. However, some attacks cannot be considered active or passive until their usage is known. An example of this case is SQL-injection, if it is used for querying data from a database then it is passive. However, if it is used to alter data, drop tables or relations then the attack can be considered as active.

1) NETWORK THREATS Threats are initiated based on a flow of packets sent over a network. Two of the most common forms of network threats are Denial of Service (DoS) and Distributed Denial of Service (DDoS) (FIGURE .1), where an attacker floods the network with requests rendering the service unresponsive. During these attacks, legitimate users cannot access the services. Note that common anomalies known as 'Flash Crowds' are often mistaken with DoS and DDoS attacks . Flash Crowds happen when a high flow of traffic for a certain service or website occurs. This happens immediately upon the occurrence of a significant event. For example, breaking news, sales events, etc. DoS and DDoS can be divided into four categories including flood attacks (FIGURE Packet forging (FIGURE 4 -1.2) is another form of networking attack. Packet forging or injection is the action where the attacker generates packets that look the same as normal network traffic. These packets can be used to perform unauthorized actions and steal sensitive data like: login credentials, personal data, credit card details, Social Security Numbers (SSN) numbers, etc. When the attacker passively monitors or intercepts communications between two or more entities and starts to control the communication, this attack is referred to as a 'Man in the Middle' attack (FIGURE 4 -1.3). Unlike 'Man in the Middle' attack, a 'Man In The Browser' attack intercepts the browser to alter or add fields to a web page asking the user to enter confidential data. Impersonation (FIGURE 4 -1.5) or pretending to be another user can take different forms. The attacker may impersonate a user to gain higher security level and gain access to unauthorized data (FIGURE Scanning/enumeration are an essential step for initiating attacks. During scanning (FIGURE 4 -1.6), the attacker starts with searching the network for information such as: active nodes, running operating systems, software versions, etc. As defined in , scanning has many forms, using protocols such as TCP (FIGURE

2) HOST THREATS Host attacks target specific hosts or systems by running malicious software to compromise or corrupt system functionalities. Most host attacks are categorized under the malware (FIGURE .1) category. This includes worms, viruses, adware, spyware, Trojans and ransomware. Viruses are known to affect programs and files when shared with other users on the network, whilst worms are known to self-replicate and affect multiple systems. Adware is known for showing advertisements to users when surfing the Internet or installing software. Although adware is less likely to run malicious code, it can compromise the performance of a system. Spyware gathers information such as documents, user cookies, browsing history, emails, etc. or monitors and tracks user actions. Trojans often look like trusted applications, but allow an attacker to control a device. Furthermore, camouflage malware (FIGURE 4 -2.1.7) evolved over time reaching polymorphic and metamorphic techniques in 1990 and 1998 respectively , . For example, self-mutating malware could use numerous techniques, such as, instruction substitution or permutation, garbage insertion, variable substitutions and control-flow alteration . Last, ransomware is a relatively new type of malware where the system is kept under the control of the attacker -or a third entityby encrypting files until the user/organization pays a ransom .

3) SOFTWARE THREATS Code injection (FIGURE 4 -3.2) can include SQL Injection to query a database, resulting in obtaining confidential data, or deleting data by dropping columns, rows or tables. Cross-site scripting (XSS) is used to run malicious code to steal cookies or credentials. XSS has three main categories. The first is persistent/stored XSS (FIGURE 4 -3.2.2.1), in this case, a script is saved to a database and is executed every time the page is loaded. The second is Reflected XSS (FIGURE 4 -3.2.2.2), where the script is part of a HTTP request sent to the server. The last is DOM-based XSS (FIGURE 4 -3.2.2.3) which can be considered as an advanced type of XSS. The attacker changes values in the Document Object Model (DOM) e.g. document location, document URL, etc. DOM-based XSS is difficult to detect as the script is never transferred to the server. Driveby or download (FIGURE 4-3.6) is another software threat that requires no action from the user, however, the malicious code is automatically downloaded. It contributed to 48% of all web-based attacks in 2017 , and is considered one of the main threats in 2019 . Fingerprinting (FIGURE 4 -3.3) and misconfiguration are also forms of software threats. Fake server certificates (FIGURE 4 -3.5) are considered alarming and should be considered while analyzing communications as they could deceive the browser/user thinking that the connection is secure. This could result in phishing websites looking legitimate. Moreover, they could be used as a seed to perform other attacks like Man-in-the-Middle.

4) PHYSICAL THREATS Physical attacks are a result of a tempering attempt on the network hardware (edge, or other devices) or its configuration. This can include changing configurations (FIGURE 4 -4.2) and introducing backdoors (i.e. The Evil Maid).

5) HUMAN THREATS The last category of networking attacks is one based on human actions. These include user masquerade (FIGURE 4 -5.1). Phishing is another form of human attacks where the attacker uses emails or other electronic messaging services to obtain credentials or confidential data. When a user attempts to obtain higher privileges, it is considered a human attack like User to Root (FIGURE 4 -5.3) and Remote to Local R2L (FIGURE . Additionally, a user can be denied an action such as repudiation attack (FIGURE 4 -5.5). Human attacks can also include session hijacking or sniffing, these attacks are based on the attacker gaining access over an active session to access cookies and tokens. Based on the taxonomy discussed in FIGURE and the recent IDSs discussed in Section III-B, it can be seen that there are many threats that are not addressed by recent IDSs. FIGURE visualizes all the threats mentioned in the taxonomy. The associated percentage represents attacks covered by the IDSs discussed in TABLE . As shown a large number of attacks (72%) are not covered. Hence, the network threat taxonomy aims at addressing the following: • Help researchers generate datasets that cover nonaddressed attacks. • Provide an up-to-date taxonomy of attacks allowing to measure threats covered by datasets and the ability of IDSs to detect these threats • Provide a structured way to address and represent threats and attacks.

B. ATTACKING TOOLS Many tools , have been developed to initiate different attacks. FIGURE shows the main tools classified by the attacks they are used for. This can be used by researchers when building an IDS for a specific threat, then the associated tools are ones of interest. For example, for an IDS classifying impersonation attacks, Caffe-Latte, Hirte, EvilTwin and Cain and Abel are tools to check. Yaga and SQL attacks are tools used for U2R and so on.

V. CHALLENGES AND RECOMMENDATIONS In this section, our findings are outlined based on the discussion in Section III and Section IV. A list of limitations is reviewed then the recommendations are listed.

A. LIMITATIONS AND CHALLENGES The limitations and challenges in datasets used in IDSs can be summarized in the following: • Attacks Coverage: As shown in this work only 33.3% of known attacks are covered in publicly available datasets reviewed. This is considered one of the biggest challenges preventing IDSs to be used in real-life environments. • Real-life Simulation: Only 11% of the past decade IDSs use recent and/or real-life generated or simulated datasets. This demonstrates a flaw in the development of IDSs but highlights their limited ability to cope with the emerging needs. • Zero-Day Attacks Handling: Attacks evolve at a pace that datasets are not currently coping with. New dataset generation techniques are needed. If the process of generating datasets and making them publicly available is made more efficient, IDS models can be quickly updated and re-trained to cope with the changes. • Special Purpose Datasets: There are a limited number of available datasets serving special purpose IDSs. For example, publicly available datasets for IoT, SCADA and Tor networks are currently insufficient. • Dataset Outlook: Rapid advances in networking and associated technologies require a shift in dataset VOLUME 8, 2020 generation paradigm. Emerging technologies, such as Blockchain, Software Defined Network (SDN), Network Function Virtualisation (NFV), Big-Data, and their associated threats are currently not covered within available datasets. Yielding the dataset generation following trends in technologies [91]-[93].

B. RECOMMENDATIONS Guided by the critical impact of datasets on the evolvement of IDSs and the importance of robust and accurate IDS models, the following recommendations help build the next generation IDSs. The research direction should focus equally on building complex models for IDSs and gathering/generating data that represent benign and attack scenarios accurately. This will result in IDSs suitable for real-life deployments. • ML-First Vs Data-First: As discussed in Section III-A, obtaining valid, representative, and accurate data should be considered as the primary focus of research for the creation of IDSs. Building IDSs based on skewed and biased data only produces models unfit for exploitation, hence, Data-First models must be considered before ML-First. • Using precise evaluation metrics: As discussed in Section II, metrics -other than accuracy -should be considered to precisely reflect an IDS performance. For example, FP and Recall should be reported. Furthermore, the geometric mean should be used with imbalanced datasets, as well as, networking metrics such as throughput. Conventional ML models report loss and accuracy by default unless other parameters are defined. Relying on the recorded loss and accuracy without measuring proposed evaluation metrics may result in misleading assessments of the overall IDS efficiency. • Introduce modular and extendable datasets: As aforementioned, special purpose datasets are demanded, either to cover bespoke networks and architectures (e.g. IoT, SCADA, Tor, etc.) or to introduce new and zero-day attacks. To increase the impact of datasets, they are required to be easily extendable and capable of integrating with other datasets. As a result, datasets would be adaptable to the continuous network changes. Also, dataset generation could be rendered in the IDS pipeline, therefore, not requiring the generation of a new dataset with every introduced change. To this end, anomaly based IDSs could be trained to use advanced ML techniques to identify new and zero-day attacks. • Standardize attack dataset generation/collection method: One of the main challenges forcing researchers to work with outdated datasets is the lack of documentation associated with newly available datasets. Moreover, publishing raw packet data, not only the computed features, is needed to expand the use of datasets. One of the VOLUME 8, 2020 ways to generate datasets relies on α (using descriptive language to describe attacks) and β (using behavior and statistical measures to describe attacks) profiles, as described by Shiravi et al. . Ring et al. recommends being careful with anonymization and choosing which fields to be discarded. Privacy is depicted as one of the main obstacles against the collection of new attacks data. Furthermore, the lack of standard tools for data collection, anonymization, documentation and publication demand researchers to use their own tailored methods. • Introduce models to inject realistic attacks: Flow-Level Anomaly Modeling Engine FLAME was one of the first tools to inject attacks that leave traces into network flows. ID2T , , is a proposed flexible model to inject scenarios to existing datasets. The absence of thorough documentation of datasets makes it harder to map one dataset to another, rendering it impractical to add new attacks to existing datasets. Moreover, assuming that there exists a standard method to export realistic traffic, there isn't enough information about how to inject newly collected data to existing ones. Furthermore, the existing traffic injection proposals are limited to a single usage/prototype. • Generated dataset resilience: To ensure dataset resilience, variations of the dataset should be generated. This could include variation of attack scenarios, different attacks, diverse benign traffic load (different time of day load). This, with other measures, would guarantee an extended dataset lifetime. Moreover, the complexity of dataset variation generation should be kept minimal. It is key for a dataset to be provided in a raw state to allow researchers to make a choice between using stateless or stateful analysis. If a dataset is provided only in a pre-processed form, researchers may lose the ability to use stateless or stateful detection methods and hinder the detection and accuracy of their algorithms. • Leveraging network monitoring to create real traffic: Since most of the available benchmark datasets lack real-life properties, new datasets generation should benefit from network monitoring to generate realistic background traffic . Furthermore, if real traffic could not be included in the dataset due to privacy concerns, real traffic should act as the ground truth for further traffic generation/simulation. Moreover, for special purpose networks, relying on released IoT/Critical infrastructure network architecture case studies should act as a guidance for network simulation. This should reduce the gap in terms of accurate realistic datasets. Different validation approaches should be used for IDS, however, with the advancement of IDS research, realistic experiments should be the main focus as demonstrated in . • Dataset Validation: Newly generated datasets should be validated based on network traffic validation techniques. Molnár et al. list the various metrics that could be used for this purpose. Furthermore, the similarities between real and synthetic traffic should also be evaluated as proposed in , . • Updated Threats Taxonomy: The networking threat taxonomy presented at this work aims at helping create datasets that cover a wider range of attacks. Maintaining the taxonomy in a timely manner will keep it an up-to-date reference for future IDSs research. Furthermore, the taxonomy is made available for public contribution through a GitHub repository to encourage contributions from other researchers to extend, revise and update it. While these recommendations might appear trivial at first, the majority of recent and old datasets proposed online do not conform to these guidelines as demonstrated within the previous sections. Hence, through this section, we provided recommendations for future datasets to follow ensuring the creation/generation of usable/accurate datasets.

VI. CONCLUSION This research aims at tackling the problem of having a generic taxonomy for network threats. A proposed taxonomy is presented for categorizing network attacks based on the source, OSI model layer and whether the threat is active or passive. The prominent IDS research over the past decade (2008 -2020) is analyzed. The analysis results in three main findings. First, benchmark datasets lack real-world properties and fail to cope with constant changes in attacks and network architectures, thus, limiting the performance of IDS. Second, we present a taxonomy of tools and associated attacks, and demonstrate that current IDS research only covers around 33.3% of threats presented in the taxonomy. Third, we highlight that -whilst ML is used by 97.25% of the examined IDS -ANN, k-means and SVM represent the majority of the algorithms used. While these algorithms present outstanding results, we also highlight that these results are obtained on outdated datasets and, therefore, not representative of real-world architectures and attack scenarios. Finally, the network threat taxonomy and the attacks and associated tool taxonomy are open-sourced and available through GitHub, allowing both security and academic researchers to contribute to the taxonomy and ensure its relevance in the future. TABLE 2. Over a decade of intrusion detection systems (2008 -2020). VOLUME 8, 2020